<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: blog-post | Matt Aimonetti]]></title>
  <link href="http://matt.aimonetti.net/articles/categories/blog-post/atom.xml" rel="self"/>
  <link href="http://matt.aimonetti.net/"/>
  <updated>2014-10-11T12:32:54-07:00</updated>
  <id>http://matt.aimonetti.net/</id>
  <author>
    <name><![CDATA[Matt Aimonetti]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Go, Robots and code refactoring]]></title>
    <link href="http://matt.aimonetti.net/posts/2014/04/28/refactoring-go-code/"/>
    <updated>2014-04-28T10:45:00-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2014/04/28/refactoring-go-code</id>
    <content type="html"><![CDATA[<p><a href="http://golang.org/">Go</a> aka golang is an amazing language but also a language that
is really easy to learn due to its small scope.
If you have some coding experience, you will be able to have fully working code
in a matter of minutes otherwise you might want to read <a href="http://www.golangbootcamp.com/">my free book</a> (WIP).</p>

<div style="text-align:center; padding:2em 0">
  <a href="http://www.golangbootcamp.com/"><img src="http://matt.aimonetti.net/images/matt_aimonetti-go_bootcamp.png" alt="Go Bootcamp free book (golang)"></a>
</div>


<p>Very much like with many other programming languages, a challenging part
of Go is to learn how to write idiomatic code.
The good news is that Go makes refactoring easy (and already has a lot
of conventions).
I strongly recommend <a href="http://peter.bourgon.org/go-in-production/">this post</a> from Peter Bourgon about Go at SoundCloud and
the extra conventions they follow (<a href="https://splice.com">Splice</a> also
follows the same conventions).</p>

<p>One of my favorite Go projects is the <a href="http://gobot.io">gobot</a> project
by <a href="http://hybridgroup.com/">HybridGroup</a>.</p>

<div style="text-align:center; padding:2em 0">
<a href="http://gobot.io/"><img src="http://matt.aimonetti.net/images/gobotio.png" alt="Gobot"></a>
</div>


<p>The Gobot project is pretty young and I noticed a few things that
could be improved so I offered my help to <a href="https://twitter.com/deadprogram">Ron</a>,
<a href="https://twitter.com/adzankich">Adrian</a> and the rest of the team.
Our discussion quickly turned into a fun group refactoring
session (featuring <a href="https://twitter.com/kytrinyx">@kytrinyx</a>,
<a href="https://twitter.com/deadprogram">@deadprogram</a>,
<a href="https://twitter.com/codegangsta">@codegangsta</a>,
<a href="https://twitter.com/jnbeck">@jnbeck</a>,
<a href="https://twitter.com/adzankich">@adzankich</a> )</p>

<div style="text-align:center; padding:2em 0">
  <img src="http://matt.aimonetti.net/images/matt_aimonetti-go_refactoring.jpg" alt="Go refactoring at GopherCon">
</div>


<h2>Packages</h2>

<p>Gobot is split into multiple packages, a core and a few other packages.
The gobot team, out of habit chose to put a package per repo.
After further discussions, we chose to bring all official packages
inside the same repo to keep things easier and to keep the import paths
clean and logical.</p>

<p>So instead of having:</p>

<p><code>
github.com/hybridgroup/gobot
github.com/hybridgroup/gobot-sphero
github.com/hybridgroup/gobot-...
</code></p>

<p>All the none-core packages are moved to subdirectories:</p>

<p><code>
github.com/hybridgroup/gobot
github.com/hybridgroup/gobot/sphero
github.com/hybridgroup/gobot/...
</code></p>

<p>This also allowed us to fix the package names
<code>gobot-sphero</code> is now simply <code>sphero</code></p>

<p>Which also allowed us to simplify the following code:</p>

<p>From:
```go
type SpheroAdaptor struct {</p>

<pre><code>gobot.Adaptor
sp io.ReadWriteCloser
</code></pre>

<p>}
```</p>

<p>To</p>

<p><code>go
type Adaptor struct {
  gobot.Adaptor
  sp io.ReadWriteCloser
}
</code></p>

<p>We did that with a few other types and methods all over the packages.</p>

<p>We had a discussion about what lead to the multiple repos vs
one repo. There are legitimate cases for both approaches but in this
situation, the decision was based on a misunderstanding. The author
thought that by importing the top package, all sub packages would
also be somewhat included in the build, making the binary bigger than
needed. Since Go only compiles and links packages imported, moving all
packages within the same repo wouldn't change the binary output.
Note that this is not because in this specific case we have all packages
in the same repo that this is the right thing to do every single time.</p>

<h2>doc.go</h2>

<p>By conventions, package should contain a <code>doc.go</code> file that contains
an overview of the package and often some information so the developer
trying to use the library can find the right entry points.</p>

<p>As usual, the standard libraries are a good example,
<a href="http://golang.org/src/pkg/net/http/doc.go">here is the net/http <code>doc.go</code> file</a>.</p>

<h2>Using a constructor</h2>

<p>We spent some time refactoring <code>master.go</code> which is the file implementing
the code handling one or multiple robots (which can each have multiple devices).</p>

<p>The original function code looked like this:</p>

<p><code>go
func GobotMaster() *Master {
  m := new(Master)
  m.NumCPU = runtime.NumCPU()
  return m
}
</code></p>

<p>There are a few things that aren't really idiomatic in this code.
The first thing is that by convention, constructors are usually called <code>New&lt;Type&gt;</code>.
Secondly, the <a href="http://peter.bourgon.org/go-in-production/">community seems to follow</a> the following stylistic choice:
only use <code>new</code> and <code>make</code> when you need to set the capacity (<code>make([]string,3)</code>)
Finally we don't need to allocate a variable. Here is the refactored code:</p>

<p><code>go
func NewMaster() *Master {
  return &amp;Master{NumCPU: runtime.NumCPU()}
}
</code></p>

<h2>Cleanup package vars</h2>

<p>In the original code, we had a variable called <code>trap</code> which was
a function living at the top level of the package:</p>

<p><code>go
var trap = func(c chan os.Signal) {
  signal.Notify(c, os.Interrupt)
}
</code></p>

<p>The func was then used to handle signals. The author
chose to use a variable so he could mutate it in the test suite and
avoid sending an interrupt when testing.
We realized we could avoid having this function variable at the top of the package by moving
it as a field on the <code>Master</code> type and setting the default func in the constructor.</p>

<p>```go
func NewMaster() *Master {</p>

<pre><code>return &amp;Master{
    NumCPU: runtime.NumCPU(),
    trap: func(c chan os.Signal) {
        signal.Notify(c, os.Interrupt)
    },
}
</code></pre>

<p>}
```</p>

<p>The code still behaves the same and we can still overwrite the trap function in our tests
(since the tests are part of the same packge, the non exported field is available)
but we got rid of a top level var.</p>

<h2>Reading from a channel</h2>

<p>The following code was ranging over a predefined channel (<code>c</code>) of signals.
and when a signal would arrive, all robots belonging to the master
would be halted and disconnected.</p>

<p>```go
for _ = range c {
  for r := range m.Robots {</p>

<pre><code>m.Robots[r].haltDevices()
m.Robots[r].finalizeConnections()
</code></pre>

<p>  }
  break
}
```</p>

<p>The code above works well but could be cleaned up a little:</p>

<p>```go
// waiting on something coming on the channel
&lt;- c
for _, r := range m.Robots {</p>

<pre><code>r.haltDevices()
r.finalizeConnections()
</code></pre>

<p>}
```</p>

<p>This code does the same thing but simpler.
We are trying to read from the channel which will block
(we don't care about the result so we don't capture or could have used an underscore).
Then we loop through each robot and stop them.
We managed to remove a for loop on the channel (with an odd break)
and made the code intent clearer.</p>

<h2>Chainable functions and typed nils</h2>

<p>Next, we tackled the following method:</p>

<p>```go
func (m <em>Master) FindRobotDevice(name string, device string) </em>device {</p>

<pre><code>robot := m.FindRobot(name)
if robot != nil {
    return robot.GetDevice(device)
}
return nil
</code></pre>

<p>}
```</p>

<p>The funny thing about this method is that it's not needed.
We could get the same result by calling:</p>

<p><code>go
m.FindRobot("bot name").GetDevice("laser")
</code></p>

<p>When I said that, someone suggested that it might be a bad idea
since <code>FindRobot()</code> might return <code>nil</code> and now we would be calling
<code>GetDevice()</code> on <code>nil</code> and bad things would happen.
Looking at the code, it was actually easy to fix.</p>

<p>Here is the original code:</p>

<p>```go
func (r <em>Robot) GetDevice(name string) </em>device {</p>

<pre><code>for _, device := range r.devices {
    if device.Name == name {
        return device
    }
}
return nil
</code></pre>

<p>}
```</p>

<p>Here is the refactored version:</p>

<p>```go
func (r <em>Robot) GetDevice(name string) </em>device {</p>

<pre><code>if r == nil {
    return nil
}
for _, device := range r.devices {
    if device.Name == name {
        return device
    }
}
return nil
</code></pre>

<p>}
```</p>

<p>Did you spot the difference? We just added a check to see if the pointer (<code>r</code>)
was nil, if it is, we just return <code>nil</code>.
When I added the code above, the person who was worried
about calling <code>GetDevice()</code> on <code>nil</code> was scratching his head.</p>

<p>Golang does something very interesting (and a bit surprising if you come
from a dynamic language),
it returns a nil pointer of the type we defined as return type.
Let's walk through the code by rewriting it slightly differently:</p>

<p><code>go
var bot *Robot
bot = m.FindRobot("unknown name")
</code></p>

<p>At this point if <code>FindRobot()</code> didn't find a robot, <code>bot</code> is still
of type <code>*Robot</code> but the pointer is nil.
Because we defined a method <code>GetDevice()</code> on <code>*Robot</code>, we
can call:</p>

<p><code>go
bot.GetDevice("x-ray")
</code></p>

<p>The <code>GetDevice()</code> method will execute and will return <code>nil</code> right
away because we check if the pointer is <code>nil</code>.</p>

<p>The fact that nil pointers have types has 2 important implications,
the first one is that you can nicely chain methods without
checking at the caller site if the returned value is <code>nil</code>.
The second is that your methods should expect to be potentially
called on a nil pointer and should properly handle such cases.</p>

<p><strong>Note</strong>: Go team member <a href="https://twitter.com/enneff">Andrew Gerrand</a>
suggested on <a href="https://news.ycombinator.com/item?id=7667554">Hacker News</a>
to name the method <code>Device</code> instead of <code>GetDevice</code>. The word <code>Get</code> is almost always redundant.
In the same chain of thoughts, maybe we should rename <code>FindRobot</code> just <code>Robot</code>.</p>

<h2>Collection types / type aliasing</h2>

<p>I'm writing this post on my way back from GopherCon and there
was one more thing I wanted to clean up and share with you.
This is a nice pattern I use often to simplify my code.</p>

<p>Our <code>Robot</code> type has a <code>connections</code> field and a <code>devices</code> field:</p>

<p>```go
type Robot struct {
  // .. fields removed to simplify the example</p>

<pre><code>devices       []*device
</code></pre>

<p>}
```</p>

<p>To avoid always having to manually loop through the slice, a method is defined on
pointers to <code>Robot</code>. This method iterates over
the devices and halts them:</p>

<p>```go
func (r *Robot) haltDevices() {</p>

<pre><code>for _, device := range r.devices {
    device.Halt()
}
</code></pre>

<p>}
```</p>

<p>This code is totally fine but from an API design perspective, wouldn't it be nicer
to use?:</p>

<p><code>go
r.devices().Halt()
</code></p>

<p>One of the nice things with this approach is that the concept of halting, which
really belongs to the devices, doesn't need to leak into the <code>Robot</code> world.</p>

<p>To implement the suggested API change, we need to define a <a href="http://www.golangbootcamp.com/book/methods_and_interfaces#uid90">type alias</a>:</p>

<p><code>go
type DeviceCollection []*device
</code></p>

<p>We can now define methods on our new type:</p>

<p>```go
func (c DeviceCollection) Halt() {
  for _, device := range c {</p>

<pre><code>device.Halt()
</code></pre>

<p>  }
}
```</p>

<p>We then need to update our <code>Robot</code> type:</p>

<p><code>go
type Robot struct {
  // .. fields removed to simplify the example
  devices       DeviceCollection
}
</code></p>

<p>And we are done with our refactoring.</p>

<p>One last note, since we might need to call different methods on our collection
we could create an iterator method.</p>

<p>```go
func (c DeviceCollection) Each(f func(*device)) {
  for _, d := range c {</p>

<pre><code>f(d)
</code></pre>

<p>  }
}</p>

<p>// which can be called like so
r.devices.Each(func(d *device){
  d.Halt()
})
```</p>

<h2>Conclusion</h2>

<p>Needless to say that we had fun. The refactoring went much further
and we removed the use of reflections, some sleeps and much more.
The code is going through a nice cleanup before reaching 1.0 and
I can only encourage everybody to play with <a href="http://gobot.io">Gobot</a>,
there are very few things as fun as Go and Robots!
(The code is open sourced, look at it, add new drivers, send PRs!)</p>

<p>I'd like to thank <a href="https://twitter.com/deadprogram">Ron Evans</a> and the <a href="http://hybridgroup.com/">Hybrid Group</a>
for  open sourcing their code and sharing the fun with all of us.
I can't wait for the next LA Go + Robot hack night.</p>

<p>Finally, <a href="https://splice.com">Splice</a> is hiring, our stack uses a lot of
different technologies but our backend is all in Go and we are always
looking for talented engineers. Drop me a line if interested.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What technology should my startup use?]]></title>
    <link href="http://matt.aimonetti.net/posts/2013/08/27/what-technology-should-my-startup-use/"/>
    <updated>2013-08-27T22:10:00-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2013/08/27/what-technology-should-my-startup-use</id>
    <content type="html"><![CDATA[<p>Over the years many people have asked me the same question:</p>

<blockquote><p>I'm starting this new project, what technology do you think I should use?</p></blockquote>

<p>Often these people fit in one of two categories:</p>

<ul>
<li>Technologists who've already made up their mind</li>
<li>Non-technologist entrepreneurs who need to be reassured</li>
</ul>


<p>At the end of the day, I doubt that many of these people actually cared
about my answers. They probably just wanted to know if we were on the same page or wanted to be reassured.</p>

<p>To be honest, as an engineer, I believe <strong>a great idea can be built with almost any
technology</strong>. They all have their pros/cons. No matter what stack you choose, you'll pay a
certain price for whatever advantages it offers. But really, the success or failure of your project has more to do with vision, leadership, execution, and market than technological choices.</p>

<p>Now that I'm an entrepreneur, I make technical decisions daily. When I choose
a specific technology, I need to be able to justify the decision to myself, my
partners/employees and potential investors. I make technical choices based on the project and company's vision.</p>

<p>For a project to be successful you must have a strong vision.
If you can convert your <strong>vision</strong> into a set of <strong>values</strong> to benchmark every decision, your path will be clear and it'll be easier to find the right people to join you.</p>

<p>Besides the vision, a lot of startups focus on culture.
It is commonly said that the culture is defined by the founders, the first few employees, and
the product itself.
However, what isn't often mentioned is that <strong>the technical
decisions will have a direct effect on the company culture</strong>.</p>

<p>Whether your new startup is based on J2EE/Oracle, Perl, PHP, Rails, Node.js or
.NET, the team's engineers will have different expectations, different
values, and different concerns. None of these technologies are intrinsically bad. Great things have been built with each. But they do come with a culture.</p>

<p>A couple years ago, I met an entrepreneur who chose to
build his application in Node.js. Curious, I asked why he chose Node.
The response was simple:
* smart engineers are excited about it so I can more easily recruit
* people are willing to contribute for free because it builds their
  experience</p>

<p>This decision clearly set the engineering culture and defined the team of people
who could work or be interested in working on the project.</p>

<h2>Asking a Different Question</h2>

<p>So maybe instead of asking what technology I should use, we should ask ourselves:</p>

<blockquote><p>Does this technology fit my company's core values?</p></blockquote>

<p>That's a much harder question because you need to actually <em>understand</em> your
core values. That understanding is key to building a successful product.</p>

<p>You can't blindly copy a tech stack in the same way you can't copy a business plan. It's a part of your company's identity. Your core values, your objectives, your team and your
expectations are different.</p>

<p>The whole <em>"it worked for X"</em> argument is
rarely valid. Look, Facebook uses PHP, it "worked for them". Does that mean we should all use PHP?</p>

<h2>Technology-Culture Alignment</h2>

<p>Characterizing communities is difficult, but I'll share with you the impressions and perspectives that I have on various options. Feel free to use the comments to share your own perspective and cover other communities.</p>

<h3>Old School</h3>

<p>Here are some of the "classics": languages that have been used for a
while and have proven their values. They're widespread, but don't inspire much passion anymore.</p>

<p><em>Note</em>: I omitted Perl because I personally don't know any new startups building their core technology in Perl (6?).</p>

<h2>PHP</h2>

<p><strong>Philosophy:</strong></p>

<ul>
<li>Get stuff done, that's what matters</li>
<li>It's like Basic for the Web</li>
<li>As long as there is a way to do it, it ain't broken</li>
<li>It works and it's fast, anything else is pointless</li>
<li>Don't be too academic, our language is accessible and anyone can be
started in no time. Try to do the same thing with Java!</li>
<li>Object orientation as an afterthought</li>
</ul>


<p><strong>Common use case: (as of mid-2013)</strong></p>

<ul>
<li>Your first web app</li>
<li>Extending Wordpress/Drupal</li>
</ul>


<p><strong>Personal opinion:</strong></p>

<p>PHP had its days of glory. It really made web development easy and
accessible. However, probably due to the really large amount of new programmers who
started with PHP and a not so opinionated community, very few people can
write good PHP.</p>

<p>Good idiomatic code examples are hard to find and I'm not even sure there is such as as idiomatic PHP. The result is a community known for poor code quality, lack of
tests, security nightmares and an after taste of the early 2000s.</p>

<p>Strong PHP teams with well established conventions, processes and guidelines can accomplish great things,
but such teams are rare.</p>

<h2>Java</h2>

<p><strong>Philosophy:</strong></p>

<ul>
<li>Portability</li>
<li>The power &amp; performance of C/C++ but with automatic memory management</li>
<li>Cares a lot about object-orientation</li>
<li>IDE required</li>
<li>Memory is cheap so we consume it <em>ALL</em></li>
<li>Threading is the way to go!</li>
<li>Don't mention Java applets</li>
<li>Look at my pretty JVM!</li>
<li>Open source (but owned by Oracle)</li>
<li>Slower but safer development cycles</li>
</ul>


<p><strong>Personal Opinion:</strong></p>

<p>Java is quite interesting. A few years ago a lot of developers got tired of Java and
explored other lands. They often switched to interpreted languages
such as PHP, Python, Ruby or more esoteric languages like Erlang.</p>

<p>However, Google via Android was able to show that Java in itself isn't as terrible
as we remembered (as long as you don't have to use J2EE or Swing).
There is also a "hipsterish" trend that seems to indicate that Java is
actually cool again. A lot of that has to do with two things:</p>

<ul>
<li>the JVM</li>
<li>the incredible quantity of high quality libraries</li>
</ul>


<p>That said, for a lot of us, writing Java all day long doesn't sound
 appealing. If you are going to rely on the Java stack, there is <a href="http://en.wikipedia.org/wiki/List_of_JVM_languages">long list of other JVM languages</a>
which are mature and play well with Java
libs (i.e: Scala, Groovy, JRuby, Clojure).
You can always to mix and match.</p>

<p>Hiring Java developers isn't too hard since most students coming out of school learned Java,
but finding great early-stage startup engineers who want to write Java is quite challenging.</p>

<p><em>Side note: If you are targeting Android, keep it simple, stay with the official
stack even if you might fancy another JVM language better.</em></p>

<p>There are still many reasons to use Java's technology for your new
startup, but you might also consider using a more "rapid/flexible" solution in parallel (Ruby,
Python, Node...). A multilingual environment brings a lot of value to
both the company and the engineers, which is something the Java
community seems to be slowly but surely discovering.</p>

<p>Java mainly attracts more classically trained engineers looking for
comfortable, repetitive, well known patterns. They will be used to the language, its
tools and its natural rhythm. They might not be the most curious
developers but they are reliable (if you pick the right ones obviously).</p>

<h2>C#/.NET</h2>

<p><strong>Philosophy:</strong></p>

<ul>
<li>A better Java</li>
<li>Originally designed for desktop and embedded apps</li>
<li>We have a better IDE than the Java guys</li>
<li>We are enterprise serious but we can offer you most of Rails' cool
features</li>
<li>We have a conflicted vision of Open Source</li>
<li>Slower but safer development cycles</li>
</ul>


<p><strong>Personal Opinion:</strong></p>

<p>I went back and looked at C# when C# 5 was released and I have to say
that I was really impressed by some of the new language features. From a
purely language design perspective, C# is quite a bit ahead of Java. I was
also surprised by how pleasant it was to write Javascript in Visual
Studio (I really didn't expect that since my experience with VS was
mainly around C++).</p>

<p>Another thing that really impressed me: the quality level of the
available documentation is outstanding!
But the fact that C# isn't open source, that Visual Studio + MSDN is so expensive and
the whole environment reeks of licenses and costs, is bit of a turn off.</p>

<p>Microsoft is slowly opening up to open source and more open solutions like Azure. But as a
community, .NET is still quite Microsoft-centered.
As a startup entrepreneur, you should consider how you feel about open source vs enterprise backed cultures.</p>

<p>C# mainly attracts a variant of the Java crowd: engineers seeking stability and a support contract over open source. And they can tolerate IIS!</p>

<h3>Established Alternatives</h3>

<p>Over the years, two dynamic languages became cherished by startups:
Python and Ruby. The two languages are
actually quite similar. Nowadays Python is quite popular for backend apps
(NLP, biotech, APIs, SOA elements) while Ruby is more popular for
consumer-facing apps.
Both of these languages suffer from the same limitations (mainly
performance and concurrency) but their core
values and communities have different focuses.</p>

<h2>Python</h2>

<p><strong>Philosophy:</strong></p>

<ul>
<li>Only one obvious way to do things</li>
<li>Code has to be beautiful, simple and explicit</li>
<li>Documentation is critical</li>
<li>Strong language design leadership</li>
</ul>


<p><strong>Personal Opinion:</strong></p>

<p>As someone who chose Ruby over Python, I often envy the quality of
the documentation you find in Python projects.
I also have a love/hate relationship with the fact that Python is
designed to give you just one right way. This is
often great for teams, but it can also be frustrating.</p>

<p>In some areas, Python has some of the best libraries out there, and
depending on the problems you are tackling, Python might be the right
choice. Python developers know how to communicate about their code. They document what they do
and are process oriented while being pragmatic about their
approaches.</p>

<p>But Python was created way before the internet became
popular and if concurrency and high throughput is a concern for you, a
dynamic, interpreted language with poor concurrency might not be the right choice.</p>

<p>Python mainly attracts more pragmatic, experienced, full-stack developers
wanting a modern but well-proven language.</p>

<h2>Ruby/Ruby on Rails</h2>

<p><strong>Philosphy:</strong></p>

<ul>
<li>Designed for humans, not machines</li>
<li>Extreme flexibility: if you mess up, it's on you</li>
<li>Everything has to be easy, elegant and fun</li>
<li>DSL on top of DSLs on top of DSLs</li>
<li>Testing is critical</li>
<li>Things move quickly, learn to keep up</li>
<li>Passionate and vibrant community</li>
</ul>


<p><strong>Personal opinion:</strong></p>

<p>As far as I'm concerned, Ruby has been my go-to language for years.
You will find an incredible, sometimes overwhelming amount of Ruby open
source code. Rails is really an amazing web framework making most web
projects easy to implement if you know how to use the tool.</p>

<p>But the flexibility and rapid development cycle also have
downsides. Be ready to invest a large chunk of your time keeping your code
base up to date and migrating away from abandoned libraries.
If you can't rely on caching, the throughput of a successful app will often be limited
by the lack of good concurrency support.</p>

<p>Ruby developers are mainly Rails developers and a great majority might
have a hard time being able to identify core language features versus
framework features. They are often curious, opportunistic (in a good way),
somewhat pragmatic and care about code quality/structure and
test coverage. Rails developers are typically early adopters due to
the fact that the framework itself uses some new technologies by
default (coffeescript, turbolinks, CSS pre-processors...).</p>

<p>Ruby and Rails mainly attract developers wanting to get things done
quickly but elegantly. These developers are often
product-oriented and care more about the purpose and customer value  than the lower-level computational details.</p>

<h2>New Players</h2>

<p>These are the languages/technologies that get people excited. They
represent the new wave of programming languages designed to run
in "the cloud".</p>

<h2>Node.js (Javascript)</h2>

<p>Node.js isn't a programming language but it's the most popular way to
run JS server side. The same way most of my comments about Ruby were
about Rails, I'll focus on Node more than JS itself.</p>

<p><strong>Philosophy:</strong></p>

<ul>
<li>Designed for real-time driven apps with high throughput, low latency</li>
<li>DIY</li>
<li>Small core, the rest is up to the community</li>
<li>Coupling is a sin</li>
<li>Learned lessons from Ruby/Python</li>
</ul>


<p><strong>Personal Opinion:</strong></p>

<p>I find Node.js interesting. Technically there isn't much new with Node. Python has
Tornado/Twisted, Ruby has EventMachine, and C had libevent.</p>

<p>Event-driven frameworks have
been used for a while but Node has two major advantages:
* most JS libs are non-blocking
* most web developers have to write some JS anyway</p>

<p>The idea of using the same
programming language both in the front end and the back end appeals to many, but the value is still unproven.</p>

<p>Node offers great throughput (as long as you stick to IO operations),
is easy to get started, and is fun to write.</p>

<p>Due to the nature of event-based programming, debugging and testing is challenging. Dealing with callbacks can be maintenance hell. I hope that Node will adopt an official future/promise solution. And documentation is typically spotty making jumping on an existing project difficult.</p>

<p>Node developers are definitely early adopters and comfortable creating a custom structure/pattern rather than following convention.It attracts developers wanting to use a known language (JS)
to handle high levels of concurrency. Node as a framework is lower level than the classical MVCs which is a plus for hackers. Node developers also really like the idea of using the same programming language on both server and client.</p>

<h2>Clojure</h2>

<p><strong>Philosophy:</strong></p>

<ul>
<li>A pragmatic and modern Lisp</li>
<li>Everything is data</li>
<li>Concurrency, concurrency, concurrency</li>
<li>States are evil</li>
<li>Great Java interoperability</li>
<li>A bit on the academic side, but still being pragmatic</li>
</ul>


<p><strong>Personal Opinion:</strong></p>

<p>What I like the most about Clojure is the lisp
spirit.
Once you get past the parenthesis and the operator/argument order,
Clojure challenges you to entirely rethink the way you architect your code.
It's really good and efficient at processing data and pushes you to keep
your code short.</p>

<p>My problem with Clojure is that I'm not smart enough to write a lot of
it. My brain quickly stack overflows trying to follow the data.
Exceptions are often meaningless and trying to debug someone else's code is
challenging since the language itself is complex and it can be extended
by macros. Finally, the Clojure community isn't really web-oriented,
most of the work done in Clojure seems to be data-centric.</p>

<p>Clojure mainly attracts more fringe, language-curious, data-oriented programmers. If you are looking for data scientists with a programming language fetish,
Clojure is a good way to attract them.</p>

<h2>Scala</h2>

<p><strong>Philosophy:</strong></p>

<ul>
<li>Have the best of both object oriented and functional programming worlds</li>
<li>Let the compiler do some of the work for you</li>
<li>Concurrency matters</li>
<li>Less ceremony than Java, but aiming for same or better performance</li>
<li>Live in harmony with the Java ecosystem</li>
</ul>


<p><strong>Personal Opinion:</strong></p>

<p>Scala is currently my language of choice when targeting the JVM. The learning curve is steep. Knowing
when to use FP vs OOP can be tricky and so is dealing with the
language syntax itself.</p>

<p>That said, getting the benefits of using FP, while
still keeping OOP when needed, is very useful.
Once you "get" the language idioms, writing Scala is actually pleasant
and the community is quite nice.</p>

<p>The <a href="http://www.playframework.com/">Play</a>
framework is really good and offers a good alternative to Rails,
especially for API development. Twitter's engineering team offers a lot of resources and open source code.</p>

<p>Using Scala is a pretty safe bet at this point. Java developers feel
confortable and get to try a more "modern" language. Dynamic
language developers don't feel too far from home but get the Java
ecosystem, the performance boost, concurrency and immutability.
The tooling and convetions make using Scala on a
growing team quite nice, if the compilation time doesn't get you down.</p>

<p>Like Ruby, though, the Scala community isn't big on documentation.
I really hope <a href="http://www.scala-lang.org/api/current/">the API doc</a> will be rewritten to be more intuitive and overall more useful.
But to be fair there are a lot of great resources out there such as
<a href="http://twitter.github.io/scala_school/">Twitter's Scala school</a> and
<a href="https://www.coursera.org/course/progfun">Coursera's FP in Scala class</a> given
by Martin Odersky (Scala's creator).</p>

<p>Scala mainly attracts curious Java developers wanting
something more modern as well as Ruby/Python developers wanting a more scalable version of their language.
Scala is a good way to attract great developers who want to push
the boundaries of their existing dev environment as well as developers being able to leverage the duality of the language.</p>

<h2>Go</h2>

<ul>
<li>A better C</li>
<li>Memory management is handled for you, but don't be wreckless</li>
<li>Explicit is better than implicit</li>
<li>Rich built-in functionality</li>
<li>Fast.. everything (from compilation to execution)</li>
<li>Concurrency built-in and made easy</li>
<li>Documentation is critical</li>
</ul>


<p><strong>Personal Opinion:</strong></p>

<p>I really like Go (aka Golang). After playing with it for years, I chose to use it to
develop the APIs of my own startup. Go might sound boring to some, but
its simplicity and efficiency just work.</p>

<p>Go forces you to think a bit more about how you structure your
data/behavior because you can't just stick to the usual OO patterns. I've found that my code ends up being easier
to follow and simpler in structure, yet sometimes a bit more repetitive (ex: error handling).</p>

<p>Concurrency can't get much easier than Go. While it is compiled, your code compiles and boots in less time than a Rails server starts up. Go supports some form of duck typing making the transition from Ruby (for instance) quite easy. The production performance is quite amazing when coming from
a scripting language and the memory footprint stays small.</p>

<p>Go is designed so a single user or a big team can work on the same codebase and the tooling around the language is really great.</p>

<p>However, it's not a perfect language. 3rd party dependency management can be tricky at
times. The code can feel too low-level when you're used to high-level programming languages. And some of the language design decisions can cause confusion at times (ex: interacting with interfaces vs structs).</p>

<p>Go seems to become quite popular within the startup scene when
performance and concurrency matters. I've seen a good number of startups migrating from Node to Go and others simply extending their stack by adding small Go apps.</p>

<p>The Go community seems to be a mix of old school hackers coming from C/C++ and a younger crowd enjoying a lower-level language.
The language and the community leaders are opinionated which makes
understanding their vision and approach easy. It also allows you to
quickly evaluate how comfortable you are with their philosophy and see if it matches your expectations.</p>

<p>Go mainly attracts performance/architecture oriented developers.
They want easy concurrency, the execution speed of C with the development speed of
Python/Ruby. They don't look for a new fun language, they look for a
solid compromise.</p>

<h2>Technology Drives Culture</h2>

<p>Technical decisions have cultural impact. Think clearly and carefully about <strong>how your technologies align with your company's core values</strong>. Make the right choices and you'll spend less time fighting about technical details and more time building a great business.</p>

<p>And if you miss those arguments, there's always <a href="http://news.ycombinator.com/">hackernews</a>.</p>

<hr />

<br/>


<p><em>Update</em>: Speaking of HN, <a href="https://news.ycombinator.com/item?id=6285129">here is the thread for this post</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang multipart file upload example]]></title>
    <link href="http://matt.aimonetti.net/posts/2013/07/01/golang-multipart-file-upload-example/"/>
    <updated>2013-07-01T22:28:00-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2013/07/01/golang-multipart-file-upload-example</id>
    <content type="html"><![CDATA[<p>The Go language is one of my favorite programming languages. However,
sometimes doing simple things can seem a bit harder than it should.
However, most of the time, the problem is just to find out how to
do things the easy way. While Go's documention isn't bad, the real key
to finding out how to do things is often to look at the <a href="http://golang.org/src/pkg/mime/multipart/">source code</a> and
the <a href="http://golang.org/src/pkg/mime/multipart/multipart_test.go">test suite</a>.</p>

<p>I'm not yet super familiar with all the std lib packages, so when I
wanted to test my Go web services, I wrote a few lines of code to create
a multipart file upload function that was building the body from scratch.
Once I was done messing with the various headers, boundary protocol etc..
I started testing some edge cases, I found some bugs in my code.
Looking at Go's packages, I realized that all the tools were already
available for me to use. I was just lacking a good example. Walking
through the test suite I finally figured out how to write a simple
multipart file upload example with some extra query params.</p>

<p>Hopefully this example will be helpful to some of you.</p>

<p>```go
package main</p>

<p>import (</p>

<pre><code>"bytes"
"fmt"
"io"
"log"
"mime/multipart"
"net/http"
"os"
"path/filepath"
</code></pre>

<p>)</p>

<p>// Creates a new file upload http request with optional extra params
func newfileUploadRequest(uri string, params map[string]string, paramName, path string) (*http.Request, error) {</p>

<pre><code>file, err := os.Open(path)
if err != nil {
    return nil, err
}
defer file.Close()

body := &amp;bytes.Buffer{}
writer := multipart.NewWriter(body)
part, err := writer.CreateFormFile(paramName, filepath.Base(path))
if err != nil {
    return nil, err
}
_, err = io.Copy(part, file)

for key, val := range params {
    _ = writer.WriteField(key, val)
}
err = writer.Close()
if err != nil {
    return nil, err
}

return http.NewRequest("POST", uri, body)
</code></pre>

<p>}</p>

<p>func main() {</p>

<pre><code>path, _ := os.Getwd()
path += "/test.pdf"
extraParams := map[string]string{
    "title":       "My Document",
    "author":      "Matt Aimonetti",
    "description": "A document with all the Go programming language secrets",
}
request, err := newfileUploadRequest("https://google.com/upload", extraParams, "file", "/tmp/doc.pdf")
if err != nil {
    log.Fatal(err)
}
client := &amp;http.Client{}
resp, err := client.Do(request)
if err != nil {
    log.Fatal(err)
} else {
    body := &amp;bytes.Buffer{}
    _, err := body.ReadFrom(resp.Body)
if err != nil {
        log.Fatal(err)
    }
resp.Body.Close()
    fmt.Println(resp.StatusCode)
    fmt.Println(resp.Header)
    fmt.Println(body)
}
</code></pre>

<p>}
```</p>

<p><a href="https://gist.github.com/mattetti/5914158">Example's source code on GitHub</a></p>

<p>All the work is done in the <code>newfileUploadRequest</code> function and
really, the <code>mime/multipart</code> package hides all the complexity of
creating a multipart request.</p>

<p>The key is to set a new <code>multipart.Writer</code>:</p>

<p><code>go
writer := multipart.NewWriter(body)
</code></p>

<p>The writer will do all the work and will write directly to our body (which itself is a buffer of bytes).</p>

<p>We then create a part for the file form entry with the name of the file
param and the name of the file (that we extracted using the <code>path/filepath</code>
package).
We need to add the content of the file to the file part, we use the
<code>io.Copy()</code> to do so. In the first version of this article, I had used
<code>io/ioutil</code> <code>Readall</code> to read the content of the file (see code <a href="https://gist.github.com/mattetti/5914158/f4d1393d83ebedc682a3c8e7bdc6b49670083b84">here</a>).
However a few readers rightfully mentioned that I should instead copy
content from the file to the part instead of temporarily loading the content of
the file in memory. <a href="http://play.golang.org/p/eEFBMGMNTW">Here</a> is an
even more optimized version using goroutine to stream the data, and
<a href="https://github.com/gebi/go-fileupload-example/blob/master/main.go">here</a> is the full example using a pipe.</p>

<p><code>go
part, _ := writer.CreateFormFile(paramName, filepath.Base(path))
_, err = io.Copy(part, file)
</code></p>

<p>The <code>multipart.Writer</code> takes care of setting the boundary and formating
the form data for us, nice isn't it?!</p>

<p>Then for any extra params passed as a map of string keys to string
value, we use another function of the <code>multipart.Writer</code> type:</p>

<p><code>go
writer.WriteField(key, val)
</code></p>

<p>Once again, the writer takes care of creating the right headers, and to
add the passed value.</p>

<p>At this point, we just need to close our writer and use our body to
create a new request.</p>

<p><code>go
writer.Close()
req, _ := http.NewRequest("POST", uri, body)
</code></p>

<p>One last thing before triggering our request, we need to set the header
that contains the content type including the boundary being used.
Once again, the Go lib has us covered:</p>

<p><code>go
req.Header.Add("Content-Type", writer.FormDataContentType())
</code></p>

<p>As a reference, here is the generated body:</p>

<p>```
--0d940a1e725445cd9192c14c5a3f3d30ea9c90f1f5fb9c08813b3fc2adee
Content-Disposition: form-data; name="file"; filename="doc.pdf"
Content-Type: application/octet-stream</p>

<p>%PDF-1.4
%????
4 0 obj
&lt;&lt;/Type /Catalog
// removed for example
trailer
&lt;&lt;/Size 18
/Root 4 0 R</p>

<blockquote><blockquote><p>startxref
45054
%%EOF
--0d940a1e725445cd9192c14c5a3f3d30ea9c90f1f5fb9c08813b3fc2adee
Content-Disposition: form-data; name="title"</p></blockquote></blockquote>

<p>My Document
--0d940a1e725445cd9192c14c5a3f3d30ea9c90f1f5fb9c08813b3fc2adee
Content-Disposition: form-data; name="author"</p>

<p>Matt Aimonetti
--0d940a1e725445cd9192c14c5a3f3d30ea9c90f1f5fb9c08813b3fc2adee
Content-Disposition: form-data; name="description"</p>

<p>A document with all the Go programming language secrets
--0d940a1e725445cd9192c14c5a3f3d30ea9c90f1f5fb9c08813b3fc2adee--</p>

<p>```</p>

<p>Golang might not be as high level as Ruby or Python, but it's not too
far off and it certainly comes with some great std libs.
I know I recently caught myself writing a lot of small scripts in Go,
something I used to do in Ruby. I think this is mainly due to the
fact that Go is compiled, designed for concurrency, has great std libs and
is quite easy to write.</p>

<p><em>Hopefully this code sample illustrates how easy Go can be and can also
serve as a reference point if you are looking for a way to do multipart
upload.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Practical guide to StatsD/Graphite monitoring]]></title>
    <link href="http://matt.aimonetti.net/posts/2013/06/26/practical-guide-to-graphite-monitoring/"/>
    <updated>2013-06-26T10:26:00-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2013/06/26/practical-guide-to-graphite-monitoring</id>
    <content type="html"><![CDATA[<p>Engineers love to improve things. Refactoring and optimizations
drive us. There is just a slight problem: we often do that in a vacuum.</p>

<p>Before optimizing, we need to <strong>measure</strong>.</p>

<p>Without a solid baseline, how can you say that the time you invested in making things better wasn't a total waste?</p>

<p>True refactoring is done with a solid test suite in place. Developers know that their code behavior didn't change while they cleaned things up. Performance optimization is the same thing: we need a good set of metrics before changing anything.</p>

<p>There are plenty of monitoring tools out there, each with its own pros
and cons. The point of this article isn't to argue about which one <strong>you</strong> should use,
but instead to give you the some practical knowledge about <a href="http://graphite.readthedocs.org/en/latest/overview.html">Graphite</a>.</p>

<p><img src="/images/graphite_fullscreen_800.png" alt="Screenshot of the Graphite UI" /></p>

<p>Graphite is used to store and render time-series data. In other words,
you collect metrics and Graphite allows you to create pretty graphs easily.</p>

<p>During my time at LivingSocial, I relied on Graphite to
understand trends, issues and optimize performance. As my coworkers
and I were discussing my recently announced departure, I asked them how I
could help them during the transition period. Someone mentioned creating a
Graphite cheatsheet. The cheatsheet turned into something much bigger than I expected
and LivingSocial was nice enough to let me publicly publish this
short guide.</p>

<p><em>For a more in depth dive into the statsd/graphite features, look at
<a href="http://blog.pkhamre.com/2012/07/24/understanding-statsd-and-graphite/">this blog post</a></em></p>

<h2>Organizing metrics</h2>

<p>There are <a href="http://graphite.readthedocs.org/en/latest/tools.html">many ways</a> to feed Graphite,
I personally used <a href="https://github.com/etsy/statsd/">Etsy's statsd</a> (node.js daemon) which was being fed
via the <a href="https://github.com/reinh/statsd">statsd RubyGem</a>.
The gem allows developers to push recorded metrics to a statsd server
via UDP. Using UDP instead of TCP makes the metrics collection operation
non blocking which means that while you might theoretically lose a few samples, your
instrumented code performance shouldn't be affected. (Read <a href="http://codeascraft.com/2011/02/15/measure-anything-measure-everything/">Etsy's
blog post</a> to know more about
why they chose UDP).</p>

<p><strong> Tip </strong>: Doing DNS resolution on each call can be a bit expensive (a
few ms), target your statsd server using its ip or use Ruby's <a href="http://www.ruby-doc.org/stdlib-2.0/libdoc/resolv/rdoc/Resolv/DNS.html#method-i-getaddress">resolv</a>
standard library to only do the lookup once at initialization.</p>

<p><strong>Note</strong>: <em>I'm skipping the config settings about storage retention, resolution etc.. see the
<a href="http://graphite.readthedocs.org/en/latest/overview.html">manual</a> for more info.</em></p>

<h3>Namespacing</h3>

<p>Always namespace your collected data, even if you only have one app for
now. If your app does two things at the same time like serving HTML and
providing an API, you might want to create two clients which you would namespace
differently.</p>

<h3>Naming metrics</h3>

<p>Properly naming your metrics is critical to avoid conflicts,
confusing data and potentially wrong interpretation later on.
I like to organize metrics using the following schema:</p>

<p><code>
 &lt;namespace&gt;.&lt;instrumented section&gt;.&lt;target (noun)&gt;.&lt;action (past tense verb)&gt;
</code></p>

<p>Example:</p>

<p><code>
accounts.authentication.password.attempted
accounts.authentication.password.succeeded
accounts.authentication.password.failed
</code></p>

<p>I use nouns to define the target and past tense verbs to define
the action. This becomes a useful convention when you need to nest
metrics. In the above example, let's say I want to monitor the reasons for
the failed password authentications. Here is how I would organize the
extra stats:</p>

<p><code>
accounts.authentication.password.failure.no_email_found
accounts.authentication.password.failure.password_check_failed
accounts.authentication.password.failure.password_reset_required
</code></p>

<p>As you can see, I used <code>failure</code> instead of <code>failed</code> in the stat name.
The main reason is to avoid conflicting data. <code>failed</code> is an action and
already has a data series allocated, if I were to add nested data using
<code>failed</code>, the data would be collected but the result would be confusing.
The other reason is because when we will graph the data, we will often
want to use a wildcard <code>*</code> to collect all nested data in a series.</p>

<p>Graphite wild card usage example on counters:</p>

<p><code>
accounts.authentication.password.failure.*
</code></p>

<p>This should give us the same value as <code>accounts.authentication.password.failed</code>,
 so really, we should just collect the more detailed version and get rid
of <code>accounts.authentication.password.failed</code>.</p>

<p>Following this naming convention should really help your data stay clean and
easy to manage.</p>

<h2>Counters and metrics</h2>

<p>StatsD lets you record different types of metrics <a href="https://github.com/etsy/statsd/blob/master/docs/metric_types.md">as illustrated here</a>.</p>

<p>This article will focus on the 2 main types:</p>

<ul>
<li>counters</li>
<li>timers</li>
</ul>


<p>Use counters for metrics when you don't care about how long the code
your are instrumenting takes to run. Usually counters are used for data
that have more of a direct business value. Examples include sales,
authentication, signups, etc.</p>

<p>Timers are more powerful because they can be used to analyze the time
spent in a piece of code but also be used as a counters. Most of my work
involves timers because I want to detect system anomalies including performance
changes and trends in the way code is being used.</p>

<p>I usually use timers in a nested manner, starting when a request
comes into the system, through each of the various
datastores, and ending with the response.</p>

<h2>Monitoring response time</h2>

<p>It's a well known fact that the response time of your application will
both affect the user's emotional experience and their likelihood of completing a transactin.
However understanding where time is being spent within a request is
hard, especially when the problems aren't obvious. Tools like
<a href="http://newrelic.com/">NewRelic</a> will often get you a good overview of
how your system behave but they also lack the granularity you might
need. For instance NewRelic aggregates and averageses the data client side
before sending it to their servers. While this is fine in a lot of cases,
if you care about more than averages and want more detailed metrics, you probably need
to run your own solution such as statsd + graphite.</p>

<p>I build most of my web-based APIs on <a href="https://github.com/mattetti/wd-sinatra">wd_sinatra</a> which
has a <code>pre_dispatch_hook</code> method which method is executed before a
request is dispatched.</p>

<p>I use this hook to both set the "Stats context" in the current thread and extract the client name based on HTTP headers.
If you don't use WD, I'll show how to do the same thing in a
Rack middleware.</p>

<p><code>ruby
def pre_dispatch_hook
  api_client = extract_api_client_name(env)
  Thread.current[:stats_context] = "#{api_client}.http.#{env['wd.service'].verb}.#{env['wd.service'].url}".gsub('/', '.')
  # [...]
end
</code></p>

<p>Then using Sinatra's global before/after filters, we set a unique
request id and start a timer that we stop and report in the after filter. If we were using Rails we'd get the unique identifier generated automatically.</p>

<p>Before filter:</p>

<p>```ruby
require 'securerandom'</p>

<p>before do
  Thread.current[:request_id] = request.env['HTTP_X_REQUEST_ID'] || SecureRandom.hex(16)
  response['X-Request-Id'] = Thread.current[:request_id]
  @instrumentation_start = Time.now
end
```</p>

<p>After filter:</p>

<p><code>ruby
after do
  stat = (Thread.current[:stats_context] || "http.skipped.#{env["REQUEST_METHOD"]}.#{request.path_info}") + ".response_time"
  $statsd.timing(stat, ((Time.now - @instrumentation_start) * 1000).round, 1) if @instrumentation_start
end
</code></p>

<p>Note that this could, and probably <strong>should</strong>, be done in a Rack middleware like this (untested, YMMV):</p>

<p>```ruby</p>

<h1>require whatever is needed and set statsd</h1>

<p>class Stats
  class Middleware</p>

<pre><code>def initialize(app)
  @app = app
end

def call(env)
  request = Rack::Request.new(env)
  Thread.current[:request_id] = request.env['HTTP_X_REQUEST_ID'] || SecureRandom.hex(16)
  response['X-Request-Id'] = Thread.current[:request_id]
  api_client = extract_api_client_name(env)
  Thread.current[:stats_context] = "#{api_client}.http.#{request.request_method}.#{request.path_info}".gsub('/', '.')
  @instrumentation_start = Time.now

  response = @app.call(env)

  stat = (Thread.current[:stats_context] || "http.skipped.#{env["REQUEST_METHOD"]}.#{request.path_info}") + ".response_time"
  $statsd.timing(stat, ((Time.now - @instrumentation_start) * 1000).round, 1) if @instrumentation_start
  response
end
</code></pre>

<p>  end
end
```</p>

<p>Note that the stats are organized slightly differently and will read
like that:</p>

<p><code>
&lt;namespace&gt;.&lt;client name&gt;.http.&lt;http verb&gt;.&lt;path&gt;.&lt;segments&gt;.response_time
</code></p>

<p>The dots in the stats name will be used to create subfolders in graphite.
By using such a segmented stats name, we will be able to use <code>*</code>
wildcards to analyze how an old version of an API compares against a
newer one, which clients still talk to the old APIs, compare response
times, etc.</p>

<h2>Monitor time spent within a response</h2>

<p>We're collecting stats on every request so
we can see request counts and median average response times.
But wouldn't be better if we could measure the time spent in specific
parts of our code base and compare that to the overall time spent in the
request?</p>

<p>We could, for instance, compare the time spent in the DB vs Redis
vs Memcached vs the framework. And what's nice is that we could do that
per API endpoint and per API client. In a simpler case, you might decide to monitor mobile vs desktop. The principle is the same.</p>

<p>Let's hook into ActiveRecord's query generation to track the time spent
in AR within each request:</p>

<p>```ruby
module MysqlStats
  module Instrumentation</p>

<pre><code>SQL_INSERT_DELETE_PARSER_REGEXP = /^(\w+)\s(\w+)\s\W*(\w+)/
SQL_SELECT_REGEXP = /select .*? FROM \W*(\w+)/i
SQL_UPDATE_REGEXP = /update \W*(\w+)/i

# Returns the table and query type
def self.extract_from_sql_inserts_deletes(query)
  query =~ SQL_INSERT_DELETE_PARSER_REGEXP
  [$3, $1]
end

def self.extract_sql_selects(query)
  query =~ SQL_SELECT_REGEXP
  [$1, 'SELECT']
end

def self.guess_sql_content(query)
  if query =~ SQL_UPDATE_REGEXP 
    [$1, 'UPDATE']
  elsif query =~ SQL_SELECT_REGEXP
    extract_sql_selects(query)
  end
end
</code></pre>

<p>  end
end</p>

<p>ActiveSupport::Notifications.subscribe "sql.active_record" do |name, start, finish, id, payload|
  if payload[:name] == "SQL"</p>

<pre><code>table, action = MysqlStats::Instrumentation.extract_from_sql_inserts_deletes(payload[:sql])
</code></pre>

<p>  elsif payload[:name] =~ /.* Load$/</p>

<pre><code>table, action = MysqlStats::Instrumentation.extract_sql_selects(payload[:sql])
</code></pre>

<p>  elsif !payload[:name]</p>

<pre><code>table, action = MysqlStats::Instrumentation.guess_sql_content(payload[:sql])
</code></pre>

<p>  end</p>

<p>  if table</p>

<pre><code>$statsd.timing("#{Thread.current[:stats_context] || 'wild'}.sql.#{table}.#{action}.query_time",
                    (finish - start) * 1000, 1)
</code></pre>

<p>  end
end
```</p>

<p>This code might not be pretty but it works (<em>or should work</em>).
We subscribe to <code>ActiveSupport::Notifications</code> for <code>sql.active_record</code>
and we extract the info we need. Then we use the stats context set in
the thread and report the stats by appending
<code>.sql.#{table}.#{action}.query_time</code></p>

<p>The final stats entry could look like this:
<code>auth_api.ios.http.post.v1.accounts.sql.users.SELECT.query_time</code></p>

<ul>
<li><strong>auth_api</strong>: the name of the monitored app</li>
<li><strong>ios</strong>: the client name</li>
<li><strong>http</strong>: the protocol used (you might want to monitor thrift, spdy etc..</li>
<li><strong>post</strong>: HTTP verb</li>
<li><strong>v1.accounts</strong>: the converted uri: /v1/accounts</li>
<li><strong>sql</strong>: the key for the SQL metrics</li>
<li><strong>users</strong>: the table being queried</li>
<li><strong>SELECT</strong>: the SQL query type</li>
<li><strong>query_time</strong>: the kind of data being collected.</li>
</ul>


<p>As you can see, we are getting granular data. Depending on how you setup
statsd/graphite, you could have access to the following timer data for
each stat (and more):</p>

<ul>
<li>count</li>
<li>lower</li>
<li>mean</li>
<li>mean_5</li>
<li>mean_10</li>
<li>mean_90</li>
<li>mean_95</li>
<li>median</li>
<li>sum</li>
<li>upper</li>
<li>upper_5</li>
<li>upper_10</li>
<li>upper_90</li>
<li>upper_95</li>
</ul>


<p>Instrumenting Redis is easy too:</p>

<p>```ruby
::Redis::Client.class_eval do</p>

<p>  # Support older versions of Redis::Client that used the method
  # +raw_call_command+.
  call_method = ::Redis::Client.new.respond_to?(:call) ? :call : :raw_call_command</p>

<p>  def call_with_stats_trace(*args, &amp;blk)</p>

<pre><code>method_name = args[0].is_a?(Array) ? args[0][0] : args[0]
start = Time.now
begin
  call_without_stats_trace(*args, &amp;blk)
ensure
  if Thread.current[:stats_context]
    $statsd.timing("#{Thread.current[:stats_context]}.redis.#{method_name.to_s.upcase}.query_time", 
                     ((Time.now - start) * 1000).round, 1) rescue nil
  end
end
</code></pre>

<p>  end</p>

<p>  alias_method :call_without_stats_trace, call_method
  alias_method call_method, :call_with_stats_trace</p>

<p>end if defined?(::Redis::Client)
```</p>

<p>Using Ruby's alias method chain, we inject
our instrumentation into the Redis client so we can track the time spent
there.</p>

<p>Applying the same approach, we can instrument the Ruby <strong>memcached</strong> gem:</p>

<p>```ruby
::Memcached.class_eval do</p>

<p>  def get_with_stats_trace(keys, marshal=true)</p>

<pre><code>start = Time.now
begin
  get_without_stats_trace(keys, marshal)
ensure
  if Thread.current[:stats_context]
    type = keys.is_a?(Array) ? "multi_get" : "get"
    $statsd.timing("#{Thread.current[:stats_context]}.memcached.#{type}.query_time", 
                     ((Time.now - start) * 1000).round, 1) rescue nil
  end
end
</code></pre>

<p>  end</p>

<p>  alias_method :get_without_stats_trace, :get
  alias_method :get, :get_with_stats_trace</p>

<p>end if defined?(::Memcached)
```</p>

<h2>Dashboards</h2>

<p>We now have collected and organized our stats. Let's talk about how to
use Graphite to display all this data in a valuable way.</p>

<p>When looking at timer data series, the first thing we want to do is create an overall represention. Your first inclination is probably an <em>average</em>.</p>

<p>The problem with the mean is that it's the sum of all data
points divided by the number of data points. It can thus be significantly affected by a small number of outliers.</p>

<p>The median value is the number found in the center of the sorted list of
collected data points. The problem in this case is that based on your
data set, the median value might not well represent the real overall
experience.</p>

<p>Neither <strong>median</strong> nor <strong>mean</strong> can summarize the whole story of your system's behavior.
Instead I prefer to use a <strong>5-95 span</strong> (thanks <a href="http://steveakers.com/">Steve
Akers</a> for showing me this metric and most of what I
know about Graphite).
A 5-95 span means that we cut off the extreme outliers above 95% and below 5%.</p>

<h3>Span</h3>

<p>Here is a comparison showing how the graphs can be different for the same
data based on what metric you use:</p>

<p><img src="/images/graphite/graphite-median_vs_mean_vs_span.png" alt="Graphite comparing median vs mean vs span" /></p>

<p>Of course the span graph looks much worse than the other two, but it's
also more representative of the real user experience and thus more
valuable. Here is how you would write the graphite function to get this data.</p>

<p>Given that we are tracking the following data-series:</p>

<p><code>
stats.timers.accounts.ios.http.post.authenticate.response_time
</code></p>

<p>The function would be:</p>

<p>```
diffSeries(stats.timers.accounts.ios.http.post.authenticate.response_time.upper_95,</p>

<pre><code>       stats.timers.accounts.ios.http.post.authenticate.response_time.upper_5)
</code></pre>

<p>```</p>

<h3>Alias</h3>

<p>If you try that function, the graph legend will show the entire
function, which really doesn't look great. To simplify things, you can use an
alias like I did in the graph above:</p>

<p>```
alias(diffSeries(stats.timers.accounts.ios.http.post.authenticate.response_time.upper_95,</p>

<pre><code>             stats.timers.accounts.ios.http.post.authenticate.response_time.upper_5),
  "iOS authentication response time (span)")
</code></pre>

<p>```</p>

<p>Aliases are very useful, especially when you share your dashboards with
others.</p>

<h3>Threshold</h3>

<p>Another neat feature you might add to your graph is a <strong>threshold</strong>.
A threshold is a visual representation of expectations. Say, for example, that your web service shouldn't be slower than 60ms server side. Let's add a threshold for that:</p>

<p><code>
alias(threshold(60), "60ms threshold")
</code></p>

<p>and here's how it would look in a graph:</p>

<p><img src="/images/graphite/graphite-median_vs_mean_vs_span-with-threshold.png" alt="Graphite with a threshold" /></p>

<h3>Draw Null as Zero</h3>

<p>Another useful trick is to change the render options of a
graph to draw null values as zero.
Open the graph panel, click on <code>Render Options</code>, then <code>Line Mode</code> and check
the <code>Draw Null as Zero</code> box.</p>

<p>Here is a graph tracking a webservice that isn't getting a lot of
traffic:</p>

<p><img src="/images/graphite/nulls_not_drawn_as_zero.png" alt="graphite example" /></p>

<p>You can see that the line is discontinued, that's because the API
doesn't constantly receive traffic. If your data series gets only very
few entries, you might not even see a line. This is why you want to
enable the <code>Draw Null as Zero</code>.</p>

<h3>SumSeries &amp; Summarize or how to get RPMs</h3>

<p>By default graphite shows data at a 10 second interval. But often
you want to see less granular data, like the quantity of requests
per second.</p>

<p>Let's say we didn't use a counter for the amount of requests, but
because we used the middleware I described earlier, we are timing all
responses. Graphite keeps a count of the timers we used, so we can use
this count value with a wildcard:</p>

<p><code>
stats.timers.accounts.*.http.post.authenticate.response_time.count
</code></p>

<p>If we were to render a graph for this stat we would see a graph per
client. Right now we only care about showing the total amount of requests.
To do that, we'll use the <code>sumSeries</code> function:</p>

<p><code>
sumSeries(stats.timers.accounts.*.http.post.authenticate.response_time.count)
</code></p>

<p><img src="/images/graphite/graphite-not-summarized.png" alt="RPMs not summarized" /></p>

<p>The graph looks pretty but it's hard to understand what kind of request
volume we are getting. We can summarize this data to show 1 min
summaries instead:</p>

<p><code>
summarize(sumSeries(stats.timers.accounts.*.http.post.authenticate.response_time.count), "1min")
</code></p>

<p><img src="/images/graphite/graphite-summarize.png" alt="RPMs summarize" /></p>

<p>We can now see the quantity of requests per minute. You could do the same to resolve by hour, day, etc.</p>

<h3>Timeshift</h3>

<p>Graphite has the ability to compare a given metric across two different time spans. For instance, let's compare
today's quantity of logins vs those from last weeks.</p>

<p>To generate today's graph:</p>

<p><code>
alias(summarize(sumSeries(stats.timers.accounts.*.http.post.authenticate.response_time.count),"1min"), "today")
</code></p>

<p>Then we use the <code>timeShift</code> function to get last week's data:</p>

<p><code>
alias(timeShift(summarize(sumSeries(stats.timers.accounts.*.http.post.authenticate.response_time.count), "1min"),"1w"), "last week")
</code></p>

<p>Graphing both series in the same graph will give us that:</p>

<p><img src="/images/graphite/graphite-timeshift.png" alt="graphite timeshift example" /></p>

<p>Wow, it looks like last week we had an authentication peek for a few
hours. Why? It would be interesting to graph our promos and sales in the same
graph to see if we can find any correlations.</p>

<p>Depending on your domain, you might want to compare against different
time slices. Just change the second <code>timeShift</code> argument.</p>

<h3>As percent</h3>

<p>Another technique is to compare the percentage growth since last week.
Let's imagine we are looking at sales or signup numbers.
We could graph today's sales per minute vs those from last week.</p>

<p>To do that, Graphite has the <code>asPercent</code> function. This function
takes a series representing <em>100%</em> and second to compare against.
The function call looks a bit scary so let me try to break it down over
multiple lines:</p>

<p><code>
asPercent(
  summarize(sumSeries(stats.timers.accounts.*.http.post.accounts.response_time.count),"1min")
  ,timeShift(summarize(sumSeries(stats.timers.accounts.*.http.post.accounts.response_time.count), "1min"),"1w")
)
</code></p>

<p>The first argument is the summarized RPMs (requests per minute) and the
second is last week's summarized RPMs.</p>

<p>Here is how the graph looks:</p>

<p><img src="/images/graphite/graphite-compare-as-percent.png" alt="graphite as percent" /></p>

<p>Based on all the data we collect, we can now graph something like that:</p>

<p><img src="/images/graphite/graphite-as-percent.png" alt="graphite as percent with multiple series" /></p>

<p>This graph is basically the same as the one above, but we used the
overall response time as the 100% value and we graphed all the different
monitored sections of our code base.</p>

<p>You can now build some really advanced tools that look at trends,
check pre- and post-deployment measurements, trigger alerts, and help you refactor your
code.</p>

<p>Maybe you suspect that your app has a chokepoint at the database level.
You can track the query types and the targeted tables per API
endpoint. You can see where you spend most of the time and which code path
is responsible for it. You can quickly see if adding indicies or other database-level techniques actually make a difference.</p>

<h2>Other tips</h2>

<h3>Share a url into campfire/irc and see a preview</h3>

<p>Campfire and many other chat tools offer image preview as long as they
detect that the url has an image extension. Unfortunately, Graphite's
graph urls look more like this:</p>

<p><code>
http://graphite.awesome.graphs.com/render?width=400&amp;from=-4hours&amp;until=-&amp;height=400&amp;target=summarize(sumSeries(stats.timers.accounts.*.http.post.accounts.response_time.count))&amp;drawNullAsZero=true&amp;title=Example&amp;_uniq=0.11944825737737119
</code></p>

<p>To get a preview, just append the with: <code>&amp;.jpg</code></p>

<h3>Get the graph data in JSON format</h3>

<p>You might want to do something fancy with the data like
create alerts. For that you can ask Graphite for a json representation
of the data by adding <code>&amp;format=json</code> to the URL.</p>

<p>```json
[
 {"target":
  "summarize(sumSeries(stats.timers.accounts.*.http.post.accounts.response_time.count))",
  "datapoints": [</p>

<pre><code>[20260.0, 137256960],[19513, 1372357020] //[...]
</code></pre>

<p>   ]
  }
]
```</p>

<p>The data points are the timestamped value of each graphed point.
Note that you can also ask for the CSV version of the data then pass it on to some poor bastard using Excel.</p>

<h3>Only show top graphs</h3>

<p>Let say that you are graphing the response time of all your APIs. The
amount of displayed graphs can be overwhelming.</p>

<p>To limit the displayed graphs, use one of the filters. For instance the <code>currentAbove</code> or
<code>averageAbove</code> filters that can help you only display web services with
more than X RPMs for instance. Using filters can be very useful to find
outliers.</p>

<h2>Get going with Graphite!</h2>

<p>Hopefully this guide will help and inspire you to start using Graphite to easily collect and analyze your metrics.
I'm sure there are great tricks I forgot to mention, please add your favorites in the comments.</p>

<p><em>Thanks to <a href="https://twitter.com/j3">Jeff Casimir</a> for reviewing this post
before its publication!</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Go vs Ruby for web APIs]]></title>
    <link href="http://matt.aimonetti.net/posts/2013/06/23/using-go-vs-ruby-for-web-apis/"/>
    <updated>2013-06-23T09:50:00-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2013/06/23/using-go-vs-ruby-for-web-apis</id>
    <content type="html"><![CDATA[<p>A few days ago, I was wondering if using <a href="http://golang.org/">Go</a> would be worth it when developing new web APIs.
I obviously knew that Go would be faster than Ruby, but I wasn't sure
how much faster. I also wondering about the amount of work required to
write get a full API implemented.</p>

<p>I therefore wrote the same web API in Ruby (using Rails) and in Go (at
first using Revel and then rewriting it without a framework since Go's
std lib have everything one might need).
The API spec was simple:
* extract an authorization token contained in the request header
* use the token to query a MySQL database
* respond by sending back the MySQL row in json format
* return 401 if the token isn't value</p>

<p>I didn't try to optimize the Ruby code, nor the Go code. The idea wasn't
to get precise benchmark results, the goal was to get an idea of how
much faster Go was in a real life situation. The other goal was to
evaluate the amount of work needed to write web APIs in Go for someone
who already knows the language.</p>

<p>At the end of the day the API implemented in Go is more than 50x faster than
the Ruby version. Interesting enough, writing the code and tests for the
Go API was pretty close to the Ruby experience (more on that later).
50X performance gain, including high concurrency support might be a very
good argument to start using some Go when it makes sense.</p>

<p>I documented my experiment on <a href="https://plus.google.com/101114877505962271216/posts/PeZk8FY3PWY">Google+</a>, click the following screenshot to read more.</p>

<p><a href="https://plus.google.com/101114877505962271216/posts/PeZk8FY3PWY"><img src="/images/matt_aimonetti-golang_vs_ruby_api_exp.png" alt="Matt Aimonetti's Go vs Ruby post on Google+" /></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Inspecting Rails 4 using Ruby 2.0]]></title>
    <link href="http://matt.aimonetti.net/posts/2013/03/05/inspecting-rails-4-request-dispatch-using-ruby-2-dot-0/"/>
    <updated>2013-03-05T22:18:00-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2013/03/05/inspecting-rails-4-request-dispatch-using-ruby-2-dot-0</id>
    <content type="html"><![CDATA[<p>Ruby 2.0 has a cool new feature that many people talk about:
<a href="http://ruby-doc.org/core-2.0/TracePoint.html">TracePoint</a>.</p>

<p><code>TracePoint</code> essentially allows you to hook into Ruby's events and
listen for events.</p>

<p>Being curious and since I just started a brand new Rails 4/Ruby 2 app, I
decided to write a little middleware and see what Rails is up to when
handling incoming requests.</p>

<p>Here is my <a href="https://gist.github.com/mattetti/5097206">TracePoint Rack Middleware</a>.</p>

<p>```ruby
class TracePoint
  class Middleware</p>

<pre><code>def initialize(app)
  @app = app
end

def call(env)
  stats = {}
  trace = TracePoint.new(:call) do |tp|
    stats[tp.defined_class] ||= {}
    stats[tp.defined_class][tp.method_id] ||= 0
    stats[tp.defined_class][tp.method_id] += 1
  end
  trace.enable
  response = @app.call(env)
  trace.disable

  puts "#{stats.keys.size} classes used"
  puts "#{stats.map{|k,v| v.keys}.flatten.size} methods used"
  puts "#{stats.map{|k,v| v.values}.flatten.sum} methods dispatched"
  response
end
</code></pre>

<p>  end
end
```
(the gist shows a modified version so I could dump to disk the json
representation of the calls)</p>

<p>I then inserted the middleware in Rails:</p>

<p>```ruby</p>

<h1>in application.rb</h1>

<p>config.middleware.insert_before(ActionDispatch::Static, TracePoint::Middleware)
```</p>

<p>I saved the output in json format for the curious: <a href="https://gist.github.com/mattetti/5097178">click here</a></p>

<p>On average, in production mode, using Ruby 2.0 and Puma on my laptop, my hello world index page takes 5ms.</p>

<p>To render my page, Rails uses (more or less):</p>

<ul>
<li>250 classes</li>
<li>750 methods (not including C functions)</li>
<li>and dispatches 2704 methods (not including calls to C functions)</li>
</ul>


<p>Here is a small selection of some of the methods dispatched:</p>

<p>```json
"String": {</p>

<pre><code>"underscore": 1,
"blank?": 14,
"html_safe": 78
</code></pre>

<p>  },
"ActiveSupport::Inflector": {
  "underscore": 2,
  "inflections": 2
},
"Hash": {
  "with_indifferent_access": 2,
  "except": 1,
  "except!": 1,
  "stringify_keys": 5,
  "transform_keys": 13,
  "stringify_keys!": 1,
  "transform_keys!": 3,
  "extractable_options?": 4,
  "extract!": 2,
  "symbolize_keys": 8,
  "reverse_merge": 1,
  "slice": 2,
  "symbolize_keys!": 2
},
"ActionView::CompiledTemplates": {
  "<em>app_views_welcome_index_html_erb__4177595130715791755_70209827438920": 1,
  "</em>app_views_layouts_application_html_erb___652124533295419796_70209827456500": 1
},
"ActiveSupport::Notifications::Fanout": {
  "start": 4,
  "listeners_for": 12,
  "listening?": 5,
  "finish": 3
}
```</p>

<p><code>TracePoint</code> is a great new addition and I hope to see some new crazy
tools being developed (production dead-code analyzer, deprecation code path
finder anyone?)</p>

<p>To end, this short post, here is an interesting quote from <a href="http://chadfowler.com/">Chad
Fowler</a> Berliner by adoption:</p>

<blockquote><p>Abstractions are expensive. The cost increases exponentially as you add them to a codebase.
<a href="https://twitter.com/chadfowler/status/308959527217270786">Chad Fowler</a></p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OmniAuth and Google Apps]]></title>
    <link href="http://matt.aimonetti.net/posts/2013/01/30/omniauth-and-google-apps/"/>
    <updated>2013-01-30T19:11:00-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2013/01/30/omniauth-and-google-apps</id>
    <content type="html"><![CDATA[<p>Today I struggled to get <a href="https://github.com/intridea/omniauth">OmniAuth</a> and <a href="https://developers.google.com/accounts/docs/OpenID">Google apps</a> to work properly together.
I just wanted to add authentication to my application and restrict access to only my Google Apps domain users.
I was hoping it would be straight forward since I could use Google's OpenID service.</p>

<p>Turns out it wasn't that hard, but the lack of documentation made me
lost a couple hours.
I therefore updated <a href="https://github.com/intridea/omniauth/wiki">OmniAuth's wiki</a> and wrote this quick post so hopefully you won't waste time looking for simple details.</p>

<h2>Requirements</h2>

<p>You actually only need to add 2 gems to your Gemfile:</p>

<p><code>ruby
gem 'omniauth-openid'
gem 'ruby-openid-apps-discovery'
</code></p>

<p>Now, the second gem is the one I didn't know about.
The gem is actually provided by <a href="https://github.com/google/ruby-openid-apps-discovery">Google itself</a>. It turns out, Google Apps use a custom discovery protocol.
They monkey patched the popular OpenID Ruby libraries so you can just drop in
their gem and their discovery system will magically work.</p>

<h2>Setup</h2>

<p>You need to require 4 files to get everything setup properly:</p>

<p><code>ruby
require 'omniauth-openid'
require 'openid'
require 'openid/store/filesystem'
require 'gapps_openid'
</code></p>

<p>The first one is the omniauth extension for OpenID, the second one is
the main Ruby OpenID library (needed so we can set our SSL cert).
The third one allows us to store temporary data on disk instead of
keeping it in memory (optional).
And finally, the last one is Google's magical gem to get their discovery
system working.</p>

<p>Because we are going to communicate via SSL, we want to make sure that
the OpenID library uses our certs to verify the SSL communications:</p>

<p><code>ruby
OpenID.fetcher.ca_file = "/absolute/path/to/ssl_cacert.pem"
</code>
(Obviously, you need to change the path to your own cert)</p>

<p>We are almost done with the setup, we just need two more things:</p>

<ul>
<li>make sure you are using a session.</li>
<li>setup OmniAuth</li>
</ul>


<p>I'm using Sinatra, so I'll load the <code>Rack::Session</code> middleware before I
set Omniauth:</p>

<p><code>ruby
use Rack::Session::Cookie, :secret =&gt; 'supers3cr3t'
</code></p>

<p>(Rails turns that option by default, so you don't need to worry about
it)</p>

<p>Then I can finally setup OmniAuth:</p>

<p>```ruby
use OmniAuth::Builder do
  provider :open_id,  :name => 'admin',</p>

<pre><code>                  :identifier =&gt; 'https://www.google.com/accounts/o8/site-xrds?hd=aimonetti.net',
                  :store =&gt; OpenID::Store::Filesystem.new('/tmp')
</code></pre>

<p>end
```</p>

<p>There are two important things to notice. First, because I set the
provider's name to be 'admin', the magical paths provided by OmiAuth
will use that name (<code>/auth/admin</code>). Secondly, and more importantly, notice how I added
the name of my Google Apps domain at the end of the identifier:</p>

<p><code>ruby
'https://www.google.com/accounts/o8/site-xrds?hd=' + your_domain_name
</code></p>

<h2>Sinatra</h2>

<p>In Sinatra, your just need to define the routes OmniAuth would use (same
goes for Rails, just use the router for that).</p>

<p>By default, omniauth now offers you a <code>/auth/admin</code> endpoint that will
push the user through Google Apps authentication.
Once the authentication is over, the user will be redirected to the
following endpoint:</p>

<p>```ruby</p>

<h1>Callback URL used when the authentication is done</h1>

<p>post '/auth/admin/callback' do
  auth_details = request.env['omniauth.auth']
  session[:email] = auth_details.info['email']
  redirect '/auth/admin/welcome'
end
```</p>

<p>You can access the authentication details from <code>request.env['omniauth.auth']</code>
and redirect the user to another page, like the admin landing page for
instance.</p>

<p>```ruby
get '/auth/admin/welcome' do
  if session[:email]</p>

<pre><code>erb :welcome_boss
</code></pre>

<p>  else</p>

<pre><code>redirect '/auth/admin'
</code></pre>

<p>  end
end
```</p>

<p>On the landing page, you need to verify that the user is logged in, in
this case, during the previous step, we added the email of the user to
her session. We can therefore verify the presence of that information to
confirm the authentication status. If the user is authenticated, then we'll render an ERB
template otherwise we'll redirect her back to the login page.</p>

<p>We should also provide an endpoint in case the authentication failed:</p>

<p><code>ruby
get '/auth/failure' do
  params[:message]
  # do whatever you want here.
end
</code></p>

<p>Note that by default, in dev mode, Omniauth won't redirect the user
there. To enable this behavior, use the following snippet (works with any rack app,
Rails, Sinatra or whatever):</p>

<p><code>ruby
OmniAuth.config.on_failure = Proc.new { |env|
  OmniAuth::FailureEndpoint.new(env).redirect_to_failure
}
</code></p>

<h2>Conclusion</h2>

<p>Using Google Apps for authentication with OmniAuth is trivial as long
you know two things:</p>

<ul>
<li>the identifier url: <code>'https://www.google.com/accounts/o8/site-xrds?hd=' + your_domain_name</code></li>
<li>Google's discovery service gem</li>
</ul>


<p>This blog post was written using <code>omniauth 1.1.1</code>, <code>omniauth-openid 1.0.1</code>, <code>rack-openid 1.3.1</code> and <code>ruby-openid-apps-discovery 1.2.0</code>. This might not apply to you if you come from the future :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Real life concurrency in Go]]></title>
    <link href="http://matt.aimonetti.net/posts/2012/11/27/real-life-concurrency-in-go/"/>
    <updated>2012-11-27T10:08:00-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2012/11/27/real-life-concurrency-in-go</id>
    <content type="html"><![CDATA[<p>The structure of a programming language reflects the challenges and solutions the
designers decided to address. Each designer coming with his/her own background
decides to tackle some specific issues in a novel way and/or often
decides to borrow existing paradigms from other languages.
We can't, then, fairly judge a language without understanding
what problem the language designer was trying to address.</p>

<p>Today we are going to look at <a href="http://golang.org/">Google's Go language</a>.
Go approaches concurrency from an interesting view point. But instead of digging
into the history and reasoning which led to this approach, I'd like to
show you the language constructs by actually writing real life code.</p>

<h2>Fetching web resources concurrently</h2>

<p>The following example is taken from my recent presentation <a href="/posts/2012/11/02/rubyconf-2012-ruby-vs-the-world/">Ruby vs. the World</a>. I explored a few programming languages and
showed how they changed my Ruby.</p>

<p>To show how <a href="http://golang.org/">Go</a> addresses concurrency, I decided to build a
program which would concurrently fetch various web resources, wait for all of
them to be fetched, then process them all at once. In other
programming languages, we could have used <a href="http://en.wikipedia.org/wiki/Thread_(computing">threads</a>) and a <a href="http://en.wikipedia.org/wiki/Semaphore_(programming">semaphore</a>), <a href="http://en.wikipedia.org/wiki/Actor_model">actors</a> or
<a href="http://en.wikipedia.org/wiki/Callbacks">callbacks</a>. Go's approach is <a href="http://en.wikipedia.org/wiki/Communicating_sequential_processes">slightly different</a>, let's walk through the
code together.</p>

<p>The first part of our code gets us setup:</p>

<p>```go
package main</p>

<p>import (</p>

<pre><code>"fmt"
"net/http"
"time"
</code></pre>

<p>)</p>

<p>var urls = []string{</p>

<pre><code>"http://www.rubyconf.com/",
"http://golang.org/",
"http://matt.aimonetti.net/",
</code></pre>

<p>}
```</p>

<p>The code above names our package then imports a few standard libraries that we are going to need. It then defines an array/slice of strings representing the urls we are going to fetch.</p>

<p>Next we define a type we will use a bit later:</p>

<p>```go
type HttpResponse struct {</p>

<pre><code>url      string
response *http.Response
err      error
</code></pre>

<p>}
```</p>

<p>You can think of a struct type as a simple representation of a class. Technically, we are defining a structure with some typed attributes. We will later on, create instances of this defined type.</p>

<p>Go implements OOP <a href="http://golang.org/doc/go_faq.html#Is_Go_an_object-oriented_language">slightly differently</a> than other languages.</p>

<blockquote><p>Methods in Go are more general than in C++, Java: they can be defined for any sort of data, even built-in types such as plain, “unboxed” integers. They are not restricted to structs (classes).</p></blockquote>

<p>We can therefore define methods/functions for any type of data,
including "any/all" types.
This approach to types is called <a href="http://en.wikipedia.org/wiki/Structural_type_system">structural typing</a>.</p>

<p>Here is the code:</p>

<p>```go
func asyncHttpGets(urls []string) []*HttpResponse {</p>

<pre><code>ch := make(chan *HttpResponse)
responses := []*HttpResponse{}
for _, url := range urls {
    go func(url string) {
        fmt.Printf("Fetching %s \n", url)
        resp, err := http.Get(url)
        ch &lt;- &amp;HttpResponse{url, resp, err}
    }(url)
}

for {
    select {
    case r := &lt;-ch:
        fmt.Printf("%s was fetched\n", r.url)
        responses = append(responses, r)
        if len(responses) == len(urls) {
            return responses
        }
    case &lt;-time.After(50 * time.Millisecond):
        fmt.Printf(".")
    }
}
return responses
</code></pre>

<p>}
```</p>

<p>This is the meat of our application. And there is quite a lot of going
on in just a few lines. Assuming you aren't familiar
with Go, I'll walk though the code.</p>

<p>Let's start with the signature:</p>

<ul>
<li>the function is named <code>asyncHttpGets</code></li>
<li>it takes an argument named<code>urls</code> which is an "array" of strings (I used quotes around the word
array because it's technically what Go calls a slice)</li>
<li>it returns an "array" of <code>HttpResponse</code> pointers</li>
</ul>


<p>Then in the function body:</p>

<p>We start by creating an instance of a <code>channel</code> and assigning it to the
<code>ch</code> variable name. Think of a channel as a pipe like in unix.  We can write to and read from that channel.</p>

<p>In the next line we create an empty instance of a slice containing pointers to
<code>HttpResponse</code> objects.</p>

<p>Then, using the <code>for range</code> language construct, we iterate through our <code>urls</code>, storing the current value being used into the scoped variable <code>url</code>. The <code>url</code> is then available within the block/lambda/closure marked by the curly braces.</p>

<p>Now this is where the async construct comes in. Using the <code>go</code>
keyword, we define an anonymous function that takes a string argument representing a
url.</p>

<p>The function prints this string, then uses the <code>net/http</code>
library to fetch the web resource. We use the returned data to create an
instance of our <code>HttpResponse</code> type and send it to the channel.</p>

<p>This part gets a bit confusing because I reused the name <code>url</code>. We call this
anonymous function right away passing it the <code>url</code> variable set
by the loop.</p>

<p>You might wonder why we bother to create an anonymous function and
call it right away instead of just executing the code directly.
The <code>go</code> keyword executes the code that is passed in as a <em>goroutine</em> which is well explained <a href="http://golang.org/doc/effective_go.html#goroutines">here</a></p>

<blockquote><p>A goroutine is a function executing concurrently with other goroutines in the same address space. It is lightweight, costing little more than the allocation of stack space. And the stacks start small, so they are cheap, and grow by allocating (and freeing) heap storage as required.</p></blockquote>

<p>In other words, you start a <em>goroutine</em> and you let the "system" handle
how it wants to deal with the low level details. Technically, goroutines
might run in one or multiple threads, but you don't need to know.
We trigger each http fetch in a separate goroutine
and then each response is pushed down the channel.</p>

<p>The second block of code begins with another <code>for</code> loop containing a switch/case statement.
The case statement checks if something is
in the channel. If there is something, we...</p>

<ul>
<li>allocate the data to the <code>r</code> variable</li>
<li>print the resource's url</li>
<li>append the resource to the slice we created at the beginning of the function.</li>
</ul>


<p>If the length of the array is the same as the length of all urls we want to fetch, we are done
fetching all our resources and can return.
While still waiting for responses, we print a dot every 50ms.</p>

<p><strong>Update:</strong>
In the first version of this blog post I had used a 'default' case
statement to print the dot and sleep for 50ms so the loop wouldn't be
too tight and the concurrency effect was more obvious. But some
<a href="http://news.ycombinator.com/item?id=4837919">HN comments</a> pointed out that it wasn't needed and I shouldn't block.
For reference here is what I had before (don't use this code):</p>

<p>```go</p>

<pre><code>for {
    select {
    case r := &lt;-ch:
        fmt.Printf("%s was fetched\n", r.url)
        responses = append(responses, r)
        if len(responses) == len(urls) {
            return responses
        }
    default:
        fmt.Printf(".")
        time.Sleep(50 * time.Millisecond)
    }
}
</code></pre>

<p>```
Thank you HackerNews.</p>

<p>With that code constructed, our <code>main</code> can make use of it like this:</p>

<p>```go
func main() {</p>

<pre><code>results := asyncHttpGets(urls)
for _, result := range results {
    fmt.Printf("%s status: %s\n", result.url,
             result.response.Status)
}
</code></pre>

<p>}
```</p>

<p>Compiling and running the code look like this:</p>

<p><code>bash
$ go build concurrency_example.go &amp;&amp; ./a.out
.Fetching http://www.rubyconf.com/
Fetching http://golang.org/
Fetching http://matt.aimonetti.net/
.....http://golang.org/ was fetched
.......http://www.rubyconf.com/ was fetched
.http://matt.aimonetti.net/ was fetched
http://golang.org/ status: 200 OK
http://www.rubyconf.com/ status: 200 OK
http://matt.aimonetti.net/ status: 200 OK
</code></p>

<p>As you can see from the print statements, the 3 urls are triggered in a
sequential way, but the responses come back in different orders due to different server latencies and response transfer time.</p>

<h2>Conclusion</h2>

<p>Go was designed to make concurrency easy for developers.
It is a very well documented language and you will find <a href="http://golang.org/doc/effective_go.html#concurrency">on this page
a lot of information about its concurrency philosophy</a> and details about each available constructs works.</p>

<p>I like that the language is very simple and the constructs
explicit. If you want to write concurrent code, Go pushes you to do it
in a specific style. That style is clear and comfortable for me. My code stays simple, I don't go crazy with callbacks, and the
conventions make it simple for everyone else to understand my code.</p>

<p>Whether or not Go appeals to you stylistically, but clearly the designers
stayed close to the goal of developing to a 21st century C
with a special focus on concurrency with the unix approach.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Engineers suck at finding the right jobs]]></title>
    <link href="http://matt.aimonetti.net/posts/2012/11/14/engineers-suck-at-finding-right-jobs/"/>
    <updated>2012-11-14T18:53:00-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2012/11/14/engineers-suck-at-finding-right-jobs</id>
    <content type="html"><![CDATA[<p>If you are currently a software engineer you need to realize two things:</p>

<ul>
<li><strong>Now is an awesome time to be a software engineer</strong> (probably the best time ever).</li>
<li><strong>Your job might not be well suited for you</strong>.</li>
</ul>


<p>I'll show you why we are lucky bastards, why we aren't so good at
picking the right jobs and some hints on how to solve this issue.</p>

<br>


<p>I remember a family friend telling me when I was a kid that computers
are going to be the future and that there will be a lot of jobs in this
field. I also remember that the idea of sitting all day, alone, in front of a
<a href="http://en.wikipedia.org/wiki/Minitel">minitel</a>-like computer scared the hell out of me.
But he was right and I now work from home, spending 12+ hours
in front of a monitor. I get emails and phone calls from many people
reaching out to me to help them find software engineers.</p>

<p>At least three things make "now" the best time to be a software
engineer:</p>

<ul>
<li><strong>demand</strong></li>
<li><strong>projects</strong></li>
<li><strong>prestige</strong></li>
</ul>


<h2>Good time</h2>

<p>There is a huge demand for engineers. There are many more job openings
than candidates. But this is much better than in late 90s/early 2000
when anyone who could write a line of HTML would get a job.
Now the projects people are building
are way more interesting and have a real potential to change lives.
Before, you had to work for a giant company to
have a chance to do that. But now, with internet and smart mobile
devices everywhere, almost any startup (fancy name for small company) can
have a huge impact -- look at Twitter for instance.</p>

<p>Lastly, being a geek is cool. Movies, cartoons, TV Shows now have
geek heroes (granted they usually don't represent real geeks, but hey
it's better than nothing).</p>

<h2>The problem</h2>

<p><strong>Most software engineers</strong> I know, are really bad
at choosing the right job for themselves. They <strong>don't design a career</strong>.
Engineers are good at solving technical problems in an objective way, but <strong>when it comes
to our jobs and future, we seem to struggle.</strong></p>

<h2>Why?</h2>

<p>I'm not an expert but I have a few guesses I'd like to share with you:</p>

<ul>
<li>We don't know our real worth.</li>
<li>We don't make long term plans.</li>
<li>We get paid well, so why bother changing?</li>
<li>Changing job feels like betrayal.</li>
<li>The system is broken.</li>
</ul>


<h2>Self worth</h2>

<p>Most modern companies need solid engineers to be relevant in the
short/medium term and they know it. <strong>Most engineers have no idea how
their talent and dedication converts into real business value</strong>.
Without that appreciation, they
can't easily estimate how much they are worth. The
salary scale for software engineers is dramatically different from other jobs/industries.
To your business, you might be worth twice or three times the salary of someone like a teacher.
This is probably not fair because of the social value a teacher offers, but that's the way the <a href="http://en.wikipedia.org/wiki/Law_of_demand">law of
demand</a> works in our society.
Knowing how much you are worth to a company and how much to ask is
critical to properly negotiate or renegotiate a contract.</p>

<p>I remember when I moved to America and was thankful to have a job.
I had no idea that at $45k/year with basically no health coverage and no
vacation, I was grossly underpaid and could have been paid twice that amount
down the street. (Note: the average software engineer salary in the US
is at <a href="http://www.indeed.com/salary/Software-Engineer.html">$89,000 according to indeed.com</a>).
The average salary for a high school teacher is <a href="http://www.indeed.com/salary?q1=high+school+teacher&amp;l1=">$47k/year</a>
so I wasn't complaining. As a matter of fact, I didn't leave this job because of the salary.
I truly believe that <strong>"Money doesn't buy happiness"</strong> and <strong>it shouldn't be
your primary reason to accept or leave a job</strong>. Money is nice and
often makes life easier. But the point is that you have to understand
how much you're worth, so you can get paid and
focus on your work.</p>

<h2>Defining a vector</h2>

<p><a href="http://www.kitchensoap.com/about-me/">John Allspaw</a> wrote a great blog
post about <a href="http://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/">what it means to be a senior engineer</a>.
I strongly recommend you read it. I often look back at it
and pick up a couple points I need to focus on myself.
John wrote a book which is a collection of essays and interviews
regarding tech/web ops.</p>

<p><a href="http://www.amazon.com/gp/product/1449377440/ref=as_li_ss_il?ie=UTF8&camp=1789&creative=390957&creativeASIN=1449377440&linkCode=as2&tag=merbist-20" style="text-align:center; display:block;"><img border="0" src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&ASIN=1449377440&Format=_SL110_&ID=AsinImage&MarketPlace=US&ServiceVersion=20070822&WS=1&tag=merbist-20" ></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&l=as2&o=1&a=1449377440" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /></p>

<p>Here is a very interesting quote:</p>

<blockquote><p>Not everyone can be senior. If, after five years, you are senior, are you at the peak of your game? After five more years will you not have accrued more invaluable experience? What then? “Super engineer”? Five more years? “Super-duper engineer.” I blame the youth of our discipline for this affliction. [...] Given the dynamics of our industry many elected to move on to managerial positions or risk an entrepreneurial run at things.”</p></blockquote>

<p>There are two very strong points in this quote:</p>

<ul>
<li>we don't quite know what it means to be a senior engineer (and John's post does a great
job explaining his take on that).</li>
<li>many of us end up in managerial positions or leading startups.</li>
</ul>


<p>I might be a bit radical -- but the day I stop learning/improving
will be the day that I will quit, change jobs or careers. John's post has great pointers
to help us improve our skills. But the question I'm trying to raise is:</p>

<p><strong>what do we want from our career?</strong></p>

<p>"Career" sounds like a dirty word to many of us. It has a corporate,
sleazy, back stabbing connotation. When I hear it, I picture a
cliché stock photography of a bunch of smiling people wearing 80's suits.
In the context on this post, let's take the Oxford English Dictionary
definition: "course or progress through life (or a distinct portion of life)".
The word comes from from French via the Old Occitan word: "carriera" which means "street".</p>

<p><strong>A better word for career might be "path".</strong></p>

<p>I think we have a hard time knowing what kind of path we want to be on.
When faced with the question, a lot of us answer:
"solving problems", "having fun", "changing the world".
All these answers sound good, but they aren't paths, they are just attributes.</p>

<p>I have to admit that I'm still struggling with this question and
probably will for a while. I'm pretty good at defining short term goals but I
have a hard time seeing the long term path.
As a matter of fact, a little while back I was seated in front of <a href="http://www.chadfowler.com/">Chad
Fowler</a> in his office in Washington, DC.
Chad wrote a great book called <a href="http://www.amazon.com/gp/product/1934356344/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1934356344&amp;linkCode=as2&amp;tag=merbist-20">"The Passionate Programmer: Creating a Remarkable Career in Software Development"</a>.</p>

<p><a href="http://www.amazon.com/gp/product/1934356344/ref=as_li_ss_il?ie=UTF8&camp=1789&creative=390957&creativeASIN=1934356344&linkCode=as2&tag=merbist-20" style="text-align:center; display:block;"><img border="0" src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&ASIN=1934356344&Format=_SL110_&ID=AsinImage&MarketPlace=US&ServiceVersion=20070822&WS=1&tag=merbist-20" ></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&l=as2&o=1&a=1934356344" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /></p>

<p>I've read Chad's book (which inspired me in many ways) and have known Chad
for years. The point of our meeting was to decide what I was going
to work on next. <strong>Unconsciously, I expected Chad to just tell me what I
should be doing. I trusted him to pick the right "path" for me.</strong>
But I was surprised when Chad told me: <em>"you're the
kind of engineer who can do anything. You're a generalist who can pick
a topic and become a specialist. So what do you want to do?"</em></p>

<p>I wasn't sure how to take it, it sounded like a compliment but, at the
same time, <strong>the fact that Chad didn't have a solution to my problem bothered me.</strong>
I remember thinking, wait, he's the expert and he's deflecting the
situation by asking me the question I came to ask him. Sure, the
compliment was nice but that wouldn't solve anything. What does that
mean about me? If an expert can't figure out what I should do, I might
be screwed.</p>

<p>Then on my way back home, I realized that <strong>it didn't matter how well Chad knew me,
he couldn't guess what I even didn't know about myself.</strong></p>

<p><strong>My long term happiness depends on me finding a direction I want my
professional life to take.</strong>
In Chad's book, there is a strong focus on finding a market,
understanding it, developing skills and marketing yourself.
However there was something I had missed.</p>

<blockquote><p>The goal-oriented, destination-focused thinking that you usually do
leads only from one goal to the next. It has no logical end. What most
of us fail to realize is that <em>the path</em> is the end.</p></blockquote>

<p>I've always known that the journey is more important than the destination in itself,
but what I had missed is that you still need to define a destination or
maybe more precisely a direction, a vector.
My problem is that my path was just a bunch of scattered dots. Hopping from one
to the other, I was hoping it was going to make a pretty drawing. The challenge is
when I got to a spot, I was stuck not knowing what to do next. I ended up picking another
short term goal/destination based on the opportunities available at that
time.</p>

<p>What I should do instead was to <strong>define a general direction and then
learn through the process.</strong> I believe this will help me enjoy my job more
than running after goals. It will allow me to see the world differently
and will help me make the right career choices when the time is right.
To be honest, I think that's the only way I can build endurance and not
burn out in 5 years. That said, I'll still have goals,
deadlines and the usual -- but they won't define my own personal progress.</p>

<h2>Why bother?</h2>

<p>Changing jobs is a pain. As an engineer I weigh the pros and cons and try
to logically pick the right choice -- at least in theory. In practice I
avoid dealing with questions that might result in challenging
consequences.</p>

<p>Quiting a job is tough. You have to tell your current employer and your
colleagues that you are leaving them for something you think is better
for you. <strong>The nicer the people you work with, the harder it is. The better
you are paid, the harder it is.</strong> If you work with nice people and
you're well paid, leaving is <em>really</em> hard (take note if you run a team).</p>

<p>In our profession, changing jobs isn't usually seen as something
bad. Recruiters might pressure you to take a new, better job.
Beware impulsive changes though. Recruiters want their commissions so
they'll do anything they can do make you switch. They'll try to convince
you that the grass is greener on the other side. Maybe that's only "bad" recruiters.</p>

<p>There are some recruiters who care about people and companies. Recruiters
who will help you find the right job for you. However, they
won't be able to help you if you don't know what direction you want to
go to.</p>

<p>I remember being stuck in a pretty terrible work environment, being
underpaid and the projects I was working on weren't going anywhere.
A friend gave me a Seth Godin's book called <a href="http://www.amazon.com/gp/product/1591841666/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1591841666&amp;linkCode=as2&amp;tag=merbist-20">"The Dip: A Little Book That Teaches You When to Quit (and When to Stick)"</a>.</p>

<p><a href="http://www.amazon.com/gp/product/1591841666/ref=as_li_ss_il?ie=UTF8&camp=1789&creative=390957&creativeASIN=1591841666&linkCode=as2&tag=merbist-20" style="text-align:center; display:block;"><img border="0" src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&ASIN=1591841666&Format=_SL110_&ID=AsinImage&MarketPlace=US&ServiceVersion=20070822&WS=1&tag=merbist-20" ></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&l=as2&o=1&a=1591841666" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /></p>

<p>I'm not a big fan of self-help/business books, but this book raised a very good and simple question:
how do the efforts compare to the returns?
Which situation are you in:</p>

<p><img src="/images/dip.jpg" alt="" /></p>

<p><img src="/images/cliff-dip.jpg" alt="" /></p>

<p>Think about it. <strong>Will the effort you put into your work pay off?</strong>
If you don't think it will, then you should quit right away.</p>

<p>The logic is pretty simple but requires you to forecast. For that you need
some sort of metrics helping you to see if you are getting closer or
further from the direction you set for yourself.</p>

<h2>Trust</h2>

<p>Trust is the key element of any relationship.
In <a href="http://www.amazon.com/gp/product/B000UCUX0K/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B000UCUX0K&amp;linkCode=as2&amp;tag=merbist-20">The Five Dysfunctions of a Team</a>, Patrick Lencioni explains that the base of management dysfunctions is absence of trust:</p>

<p><img src="/images/fivedysfunctions.gif" alt="" /></p>

<p>Turns out it's the same thing for our careers. We need a team of people
to help us define a vision/direction and keep us honest and accountable.</p>

<p>Find people who you can trust to talk to about your professional goals,
your progress, failures and doubts. People who will be honest with you
and tell you things you might not want to hear. Find mentors and honest
people. These people don't have to be working in the industry. They just
have to be able to listen and care.</p>

<p>People like that are extremely hard to find, but so are good executives.
<strong>I believe that having trustworthy friends (partners/family members..) who care is a big part of what
makes someone successful.</strong></p>

<h2>My small contribution</h2>

<p>As I explained earlier, I'm no expert and I also struggle with the issues I described.
However, I'd be glad to provide a bit of my free time to help you think
through these issues.</p>

<p><strong>A lot of you are doing a great job without the rest
of us noticing.</strong> If you don't have a popular twitter account, blog, open
source projects, published books or given talks at conferences, it might
be hard to get yourself noticed or even know how much you're worth.
Trust is a big deal and if you are considering moving on, you probably
don't want your boss and your colleagues to know. You probably also
don't know good recruiters you can trust. You might not even be sure
it's worth investing too much time.</p>

<p>Most of you probably won't consider it, but <strong>I'd like to offer my
help</strong>
if you'd like it. <strong>I promise full anonymity and no strings
attached</strong>. Just</p>

<ul>
<li><del>email me</del></li>
<li><del>tell me about yourself and what you do</del></li>
<li><del>what direction you'd like your career to take</del></li>
<li><del>ask any questions you might have </del></li>
</ul>


<p>After exchanging a few emails , <strong>I'll try to make good use of my network</strong>
to find you a way to move in your desired direction.
Or, if you work for an interesting company with current openings, feel free to contact
me too.</p>

<p><strong> Update: My inbox is overflowing with emails and I already spent
literally days replying to as many people as possible. I'm sorry but at
this time I can't reply to any new enquiries. I'll write a follow up
blog post that covers what I learned from my interactions with so many
readers.
</strong></p>

<p>I have no idea how this will turn out. Maybe I'll get a couple of emails,
zero, or way too many to handle -- but it's worth a try. I do have a full time job,
so please don't expect me to reply to your emails within the hour.</p>

<p>I finally took the time to enable the comments in this blog. Feel free
to leave advice or feedback.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What is Scala's pattern matching]]></title>
    <link href="http://matt.aimonetti.net/posts/2012/09/20/what-is-scala-pattern-matching/"/>
    <updated>2012-09-20T21:18:00-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2012/09/20/what-is-scala-pattern-matching</id>
    <content type="html"><![CDATA[<p><a href="http://www.scala-lang.org/">Scala</a> is a very interesting programming
language. It has for goal to provide
both <a href="http://en.wikipedia.org/wiki/Object-oriented_programming">Object Oriented</a> and <a href="http://en.wikipedia.org/wiki/Functional_programming">Functional Programming</a> paradigms.
Now <a href="http://www.scala-lang.org/">Scala</a> isn't the only recent programming language out there mixing the two paradigms.
<a href="http://www.ruby-lang.org/">Ruby</a>, <a href="http://en.wikipedia.org/wiki/JavaScript">JavaScript</a> and <a href="http://clojure.org/">Clojure</a> are other examples of popular
languages implementing both functional and OO programming patterns. Of
course, they each have a different take on the problem and that is what
is interesting.</p>

<p>Instead of arguing the pros and cons of OOP vs FP and how each of the
previously mentioned languages handle being OOP and FP, I'd like to introduce
a very powerful <a href="http://www.scala-lang.org/">Scala</a> idiom: <a href="http://en.wikipedia.org/wiki/Pattern_matching">pattern
matching</a>. Note that
pattern matching isn't something Scala invented nor that it only exists in
Scala. Pattern matching can be achieved many different ways. However,
the majority of the popular languages don't put this concept at the
center of their language. A few languages way before Scala rested
heavily on pattern matching such as <a href="http://www.erlang.org/doc/reference_manual/patterns.html">Erlang</a>,
<a href="http://www.haskell.org/haskellwiki/Haskell">Haskell</a> but that's a different story.
How does Scala offers Pattern Matching, what is it and finally why is it
valuable?</p>

<h2>Scala pattern matching by examples</h2>

<p>As its name indicates, pattern matching is used to detect patterns.
Here is an example that covers a few interesting cases:</p>

<p><code>scala
def listAnalysis(list: List[Any]) = list match {
   case Nil =&gt; "empty"
   case 'a' :: tail =&gt; "starting by 'a'"
   case (head:Int) :: _ if head &gt; 3 =&gt; "starting by an int greater than 3"
   case (head:Int) :: _ =&gt; "starting by an int"
   case _ =&gt; "whatever"
}
</code></p>

<p>If you've never seen any Scala that probably looks like gibberish to
you. Let me break it down:</p>

<p><code>
def listAnalysis(list: List[Any]) = list match {}
</code></p>

<p>I define a new function called <code>listAnalysis</code> which takes an argument
named <code>list</code> which is of type <code>List</code> (this list could contain any kind
of elements).
The implementation of this function is a pattern match on the list
argument.
The body of this 'pattern match' looks like a classical switch statement.
But it's actually much more than a simple switch statement. Surely it
could be used like one, but as we will see, it can do much more.</p>

<p>Note that you can apply a pattern match against more than one object at
once as shown a bit later.</p>

<p>Let's look at the statements inside the function.</p>

<p><code>scala
case Nil =&gt; "empty"
</code></p>

<p>In this case we are checking that the list is empty or nil. If that's
the case, the statement on the other side of the "fat arrow" is
executed. In this case, we return a string but we could have called
another function or so whatever.</p>

<p>Now the second statement is much more complex and much more powerful:</p>

<p><code>scala
case 'a' :: tail =&gt; "starting by 'a'"
</code></p>

<p>Remember that we are doing pattern matching against our list object.
What we are doing here is use the <code>::</code> operator (aka cons operator) to
extract the head and the rest of the list and then we match the head
against the <code>'a'</code> character.</p>

<p>This statement could have been written different ways:</p>

<p><code>scala
case 'a' :: rest =&gt; "starting by 'a'"
</code></p>

<p>In that case we named the <code>tail</code> of the list <code>rest</code>, but really we don't
care how it's called or its value, so the sensitive thing to do is to
rewrite that statement like that:</p>

<p><code>scala
case 'a' :: _ =&gt; "starting by 'a'"
</code></p>

<p>This basically says we are looking for a list that starts by <code>'a'</code> (and we
don't care about the rest).</p>

<p>Another statement:</p>

<p><code>scala
case (head:Int) :: _ =&gt; "starting by an int"
</code></p>

<p>In this case we type match the first element of the list and check that
we have an integer. Note that using the cons operator in the match cases
doesn't seem to affect performance. It would seem that at compilation,
the statement are rewritten to avoid creating uneeded objects (List also implements structural sharing of the tail list).
I'm not a Scala expert so someone with more experience might be able to
confirm/clarify.</p>

<p>Now let's look at a variant of this statement:</p>

<p><code>scala
case (head:Int) :: _ if head &gt; 3 =&gt; "starting by an int greater than 3"
</code></p>

<p>This is the same statement as above, but we are adding an extra
condition after the match. This is quite useful when simple matching
doesn't cut it.</p>

<p>Finally we have a fallback statement:</p>

<p><code>scala
case _ =&gt; "whatever"
</code></p>

<p>For more information about the cons operator, <a href="http://www.scala-lang.org/node/112">read about the extractor objects</a> and what they can do.</p>

<p>Here is the result of calling our function with different lists:</p>

<p><code>scala
listAnalysis(List())                             //&gt; java.lang.String = empty
listAnalysis("This is a test".toList)            //&gt; java.lang.String = whatever
listAnalysis("abcde".toList)                     //&gt; java.lang.String = starting by 'a'
listAnalysis(List(1,2,3))                        //&gt; java.lang.String = starting by an int
listAnalysis(List(42,24,36))                     //&gt; java.lang.String = starting by an int greater than 3
listAnalysis("a".toList)                         //&gt; java.lang.String = starting by 'a'
</code></p>

<p>Here is another example using 2 items for the match:</p>

<p>```scala
def doubleMatch(foo: Any, bar: Any) = (foo, bar) match {
  case ('a', 'b') => "a and b"
  case (1, 'b') => "1 and b"
  case (1, <em>) => "1 and "+ bar
  case (a:Float, </em>) => "foo float"
  case _ => "unknown case"
}</p>

<p>doubleMatch(1, "test")                           //> java.lang.String = 1 and test
doubleMatch(1, 'b')                              //> java.lang.String = 1 and b
doubleMatch(42, Nil)                             //> java.lang.String = unknown case
doubleMatch('a', 'b')                            //> java.lang.String = a and b
doubleMatch(4.2f, 42)                            //> java.lang.String = foo float
```</p>

<h1>Why is pattern matching valuable?</h1>

<p>In short, pattern matching allows the developer to deconstruct a structure to find specific
elements, in other words the pattern, needed to then constuct an
object/structure or trigger a function.</p>

<p>It's the opposite process of calling a method on an object. Here we
start from a structure (instead of the instance of an object), this structure is just a basic struct and
based on a found pattern, we then trigger a function (with access to the data if we need it).
When you have a stable and known data structure, it's often very interesting to
use the pattern matching approach because you can easily expand the
operations you can execute. However, if your operations are stable but the data changes,
then the Object Oriented approach seems more adequate.</p>

<p>Besides that, pattern matching will often make your code clearer than
using if/else statements. Especially in a language like Scala where you
can define pattern matching function within a function and you can also
pass pattern matching functions around. Like eveything else, it needs to be used with caution so the intend of
the code is still understandable. That said it's a great tool to have handy and I've
had a lot of fun rewriting my newbie Scala code using a more idiomatic
approach based on pattern matching.</p>

<p>I hope you enjoyed this quick introduction. You can read more about pattern matching in Scala in the following articles:
 <em>(note: <a href="http://ikaisays.com">Ikai</a>'s post on how he uses regexps with pattern matching is a fun read.)</em></p>

<ul>
<li><a href="http://www.scala-lang.org/node/120">http://www.scala-lang.org/node/120</a></li>
<li><a href="http://pragprog.com/magazines/2012-03/scala-for-the-intrigued">http://pragprog.com/magazines/2012-03/scala-for-the-intrigued</a></li>
<li><a href="http://kerflyn.wordpress.com/2011/02/14/playing-with-scalas-pattern-matching/">http://kerflyn.wordpress.com/2011/02/14/playing-with-scalas-pattern-matching/</a></li>
<li><a href="http://ikaisays.com/2009/04/04/using-pattern-matching-with-regular-expressions-in-scala/">http://ikaisays.com/2009/04/04/using-pattern-matching-with-regular-expressions-in-scala/</a></li>
<li><a href="http://www.artima.com/scalazine/articles/pattern_matching.html">http://www.artima.com/scalazine/articles/pattern_matching.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby constructs: class, module and mixin]]></title>
    <link href="http://matt.aimonetti.net/posts/2012/07/30/ruby-class-module-mixins/"/>
    <updated>2012-07-30T14:46:00-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2012/07/30/ruby-class-module-mixins</id>
    <content type="html"><![CDATA[<p>When you first get started with the Ruby programming and you come from a different
language, the only tricky piece is often Ruby's approach to block/closure/anonymous functions.
Sure the metaprogramming seems a bit odd, but you don't have to use it.
That's why a lot of developers think that Ruby is a simple language.
Turns out that when you dig a bit further, you realize that Ruby is
actually quite a complex language. Ask any developer who worked on a
Ruby implementation, they'll all tell you the same thing: Ruby is full of
small little things that makes it complicated.</p>

<p>An example of something that might seem simple is inheritance. Ruby,
unlike C++, doesn't support multiple inheritance. What that means is
that a Ruby class can only have 1 parent class (superclass). However
multiple inheritance can be achieved via modules used as a mixins.
That's a very common pattern, people put some code in a module and then
mix it in/include it in a bunch of classes.
The problem I see though, is that people abuse these concepts and don't
respect the difference between a class, a module and a module used a
mixin.</p>

<h2>The Class</h2>

<p>Object Oriented Programming 101:</p>

<blockquote><p>"In object-oriented programming, a class is a construct that is used to create instances of itself – referred to as class instances, class objects, instance objects or simply objects. A class defines constituent members which enable its instances to have state and behavior."</p></blockquote>

<p>So if you create a class and you don't create instances, you are using
the wrong construct. Here is an example of what I often see:</p>

<p>```ruby
class Settings</p>

<p>  @settings = {}
  def self.all</p>

<pre><code>@settings
</code></pre>

<p>  end</p>

<p>  def self.<a href="key"></a></p>

<pre><code>all[key]
</code></pre>

<p>  end</p>

<p>  def self.[]=(key, value)</p>

<pre><code>all[key] = value
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>Which can be used as such:</p>

<p>```ruby
Settings[:secret] = 42 * Math::PI * Time.now.to_f
p Settings[:secret]</p>

<h1>=> 177243152913.2707</h1>

<p>```</p>

<p><em>(granted this isn't a great example since we could have used a subclass
of <code>Hash</code> but just bear with me)</em></p>

<p>Actually, the developer who wrote the code above would probably also use
some Ruby magic like <code>method_missing</code> to provide a more laxed API and allow for "nicer" getters
such as <code>Settings.secret</code> and <code>Settings['secret']</code>. I have my
own thoughts on the topic but it's
an entirely different subject.</p>

<p>Note also that the way class level methods are defined
can also be different depending on who wrote the code, you might see the
following variations (and other more esoteric ones):</p>

<p>```ruby
class Settings</p>

<p>  def Settings.all; end</p>

<p>  # or
  class &lt;&lt; self</p>

<pre><code>def all; end
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>The <code>Settings</code> code above works, the code is simple, yet I will argue one thing: <strong>it's
an abuse of the class construct</strong>. We're breaking the #1 rule of classes:
<em>"create instances of self"</em>.</p>

<p><strong>It's easy, whenever you don't create instances of a class,
please don't use a class.</strong></p>

<p>That's also true for slightly different examples such as:</p>

<p>```ruby
class API</p>

<p>  def fetch(id)</p>

<pre><code>HTTP.get('http://matt.aimonetti.net/article/:id', :id =&gt; id)
</code></pre>

<p>  end</p>

<p>end
```</p>

<p><code>ruby
resource = API.new.fetch(42)
</code></p>

<p>There is no need whatsoever to create an instance of <code>API</code>, using a class is
picking the wrong construct. Also, I don't care if you use the <code>Singleton</code>
module to only allow 1 instance of the class, you still shouldn't use a
class in the above example.</p>

<h2>The Module</h2>

<p>In Ruby's object hierarchy, the Class object actually inherits from the
Module object.</p>

<p><code>
ruby -v -e "p Class.ancestors"
ruby 1.9.3p194 (2012-04-20 revision 35410) [x86_64-darwin11.3.0]
[Class, Module, Object, Kernel, BasicObject]
</code></p>

<p>As per Ruby's source code defintion:</p>

<blockquote><p>"A Module is a collection of methods and constants."</p></blockquote>

<p>I like to think of modules as namespaced methods and constants. Whenever
you want code that logically belongs together but that
won't require that you create instances of a 'model', then a module is
the right construct to use.</p>

<p>As a matter of fact, the two examples above are great cases where a
module should have been used.</p>

<p>The confusing bit is that modules can have module level methods but also
instance level methods. Here is an example:</p>

<p>```ruby
module API</p>

<p>  def self.fetch(id)</p>

<pre><code>HTTP.get('http://matt.aimonetti.net/article/:id', :id =&gt; id)
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>This is a module level function, it could also be written like that:</p>

<p>```ruby
module API</p>

<p>  module_function</p>

<p>  def fetch(id)</p>

<pre><code>HTTP.get('http://matt.aimonetti.net/article/:id', :id =&gt; id)
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>And be used like that:
<code>ruby
resource = API.fetch(42)
</code></p>

<p>Until now, it makes sense. The weird thing is that even though, modules
unlike classes aren't meant to create instances, we have the possibility
to define module instance methods.</p>

<p>```ruby
module Settings</p>

<p>  DATA = {repo: 'http://github.com/mattetti'}</p>

<p>  def repository</p>

<pre><code>DATA[:repo]
</code></pre>

<p>  end</p>

<p>  def secret_key</p>

<pre><code>DATA[:key] ||= 42*Math::PI
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>Great, but we can't actually use these methods since they are instance
methods and we don't create instances of modules. Well, that isn't quite
true, there is a way to access them and that's by using a module as a
mixin. What that means is that we inject/copy the module code inside a
class or an(other) object. Example in code:</p>

<p>```ruby
a = Object.new
a.extend(Settings)
a.repository</p>

<h1>=> "http://github.com/mattetti"</h1>

<p>```</p>

<p>Or we can add the code to a class so the instances of this class can
access our module instance methods:</p>

<p>```ruby
class Foo
  include Settings
end</p>

<p>Foo.new.repository</p>

<h1>=> "http://github.com/mattetti"</h1>

<p>```</p>

<h2>The mixin modules</h2>

<p>There a plenty of resources online about the many ways to use mixins in Ruby to achieve multiple inheritance and do cool stuff.
But the point of this article is to try to demonstrate that mixins
shouldn't be abused.</p>

<p>My problem with the above example is that by mixing in the <code>Settings</code>
module inside our <code>Foo</code> class, we created an uneeded, confusing extra
level of abstraction. Instances of <code>Foo</code> now have access to two
methods/objects: <code>repository</code> and <code>secret_key</code>. These methods or the
objects they refer to don't belong to the <code>Foo</code> class, but it seems
convenient to not have to type <code>Settings.repository</code> so we mixed things
in. Plus, a lot of Ruby developers seem to dislike adding class/module
level methods so they feel that this approach 'feels better'.</p>

<p>Here is the thing, the convenience of typing a few less characters isn't
worth it. Next time you or someone else will look at an instance of the
<code>Foo</code> class calling <code>repository</code>, finding where it is defined is going
to be a pain. That's especially true if you have many mixins in your
class. <code>Settings</code> will also probably grow and you will end up with a
bunch of methods that have nothing to do with your class instances.
In this case, I will call the use of a mixin, an abuse of construct.
Sure, Ruby allows you to do it, but that doesn't mean it's the right
thing to do. In Ruby, unlike in Python, there are 101 ways to do a
simple thing. It doesn't mean that the 101 ways are good, it just means
that Matz wasn't sure how people would use his programming language and
chose to give us more freedom to messup/doing it our own way.</p>

<h3>When to use mixins?</h3>

<p>I have my own rule: use mixins whenever you need to <em>share behaviors</em> between
different classes.</p>

<p>In the above example, we weren't sharing behaviors, we were sharing
objects, there was no need to actually use a mixin.</p>

<p>That said, rules aren't rules without exceptions. A good example of this
exception would be the <code>Math</code> module from the standard library.
This module offers trigonometric and transcendental functions. You might
think that this module would be designed to be a mixin so you can get
<code>log</code>, <code>cos</code>, <code>exp</code> and friends available in your math related classes.
It turns out, all Math's methods are defined a module functions meaning
that they are meant to be called from the <code>Math</code> module directly.</p>

<p>However, Ruby allows you to mixin module functions, but these functions
become private. If you do include the module inside your class, your instance methods
will be able to call <code>hypot(x,y)</code> directly, but these methods won't be
available from the outside (<code>Foo.new.log(42)</code> would raise an
exception).</p>

<p>To conclude with mixins: mixins are great but don't abuse them or you
will endup with so much abstraction that your coworkers will secretely
call you <a href="http://en.wikipedia.org/wiki/Wassily_Kandinsky">Kandinsky</a>.
Stick to simple mixins allowing you to share behaviors between at least
a couple classes. See <code>DataMapper</code> for a great way to use mixins.</p>

<h2>Modules: your secret functional programming weapon</h2>

<p>I have to say that I do like functional programming. The idea of having
functions not mutating the states of things around them pleases me. It
just seems clean, you feed data to a function and you get another piece
of data. No states were changed, maybe some temporary variables were
allocated to process the data, but the only thing that matters is the
input and the output. Easy to grasp, easy to follow, no magical states
being changed by some code fairies.</p>

<p>The good news is that Ruby allows us to write code like that. And this
is where modules are great. Very much like the <code>Math</code> module we
discussed above, there are many cases where you want to have a bunch of
functions that process an input and provide an output without keeping
any states. A good example of such a module would be a param
verification filter. The filter takes an input, takes some rules and
verifies that the input matches the rules.
Surely, we could create an instance for each verification, this would
allow to keep states in our class and do the usual OOP things. But we
could also simply use a module with a bunch of module (level) functions
that would pass to each other the input they need to not need to keep
states. The end result will be faster, nicer on the GC and easy to
follow.</p>

<p>Mixing OOP and functional programming isn't new, ask <a href="http://www.scala-lang.org/">Scala</a> developers!
If done right, by adopting this approach we can simply our code base,
make it faster, easier to maintain and not losing the chance to also use
OOP paradigms when needed.</p>

<h2>Compromise</h2>

<p>As shown earlier, modules and classes have pros and cons. Classes are
however much more natural to use for Object Oriented Programming. A
compromise about the <code>Settings</code> examples was suggested by Evan Phoenix.
The solution is elegant and simple. Use a class and an instance.
Here is an implementation based on his suggestion:</p>

<p>```ruby
class AppSettings &lt; Hash</p>

<p>  def custom_method
  end</p>

<p>end</p>

<p>SETTINGS = AppSettings.new
```</p>

<p>The point here is not about the class implementation but that fact that we use
a class and associate an instance of this class to a constant so it can
be shared all over the place. Wow, a constant, this is so nasty you
might think. Classes are constants too and so are modules, here we just
allocate an instance of a class to a constant. Surpisingly simple and efficient.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby: the differences between dup &amp; clone]]></title>
    <link href="http://matt.aimonetti.net/posts/2012/07/28/ruby-the-differences-between-dup-and-clone/"/>
    <updated>2012-07-28T12:20:00-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2012/07/28/ruby-the-differences-between-dup-and-clone</id>
    <content type="html"><![CDATA[<p>Have you ever wondered what the differences are between <strong>#dup</strong> and <strong>#clone</strong> in Ruby?</p>

<p>They both create a shallow copy of an object (meaning that they don't copy the objects that might be referenced within the copied object). However, <strong>#clone</strong> does two things that <strong>#dup</strong> doesn't:</p>

<ul>
<li>copy the singleton class of the copied object</li>
<li>maintain the frozen status of the copied object</li>
</ul>


<p>Examples of the singleton methods not being copied.</p>

<p>dup:</p>

<p>```ruby
a = Object.new
def a.foo; :foo end
p a.foo</p>

<h1>=> :foo</h1>

<p>b = a.dup
p b.foo</p>

<h1>=> undefined method `foo' for #&lt;Object:0x007f8bc395ff00> (NoMethodError)</h1>

<p>```</p>

<p>vs clone:</p>

<p>```ruby
a = Object.new
def a.foo; :foo end
p a.foo</p>

<h1>=> :foo</h1>

<p>b = a.clone
p b.foo</p>

<h1>=> :foo</h1>

<p>```</p>

<p>Frozen state:</p>

<p>```ruby
a = Object.new
a.freeze
p a.frozen?</p>

<h1>=> true</h1>

<p>b = a.dup
p b.frozen?</p>

<h1>=> false</h1>

<p>c = a.clone
p c.frozen?</p>

<h1>=> true</h1>

<p>```</p>

<p>Looking at the <a href="https://github.com/rubinius/rubinius/blob/master/kernel/alpha.rb#L230">Rubinius source code</a> makes the difference extremely obvious.</p>

<p>Because of the extra steps, <strong>clone</strong> is a bit slower than <strong>dup</strong> but that's probably <strong>not</strong> what will make your app too slow.</p>

<p>Just a quick note about shallow copies (true for <strong>clone</strong> and <strong>dupe</strong>). Notice how the array referenced by the bar attribute doesn't get copied but shared between the original and the copied instances:</p>

<p>```ruby
class Foo
  attr_accessor :bar
  def initialize</p>

<pre><code>self.bar = [1,2,3]
</code></pre>

<p>  end
end</p>

<p>a = Foo.new
b = a.clone
p a.bar</p>

<h1>=> [1, 2, 3]</h1>

<p>p b.bar</p>

<h1>=> [1, 2, 3]</h1>

<p>a.bar.clear # clearing the array #bar points to
p a.bar</p>

<h1>=> []</h1>

<p>p b.bar</p>

<h1>=> []</h1>

<p>```</p>

<p>Both objects, <strong>a</strong> and <strong>b</strong> share the same reference to the array instance created when <strong>a</strong> is initiated. There are a few ways to do a deep copy of an object, but that's a different matter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rethinking web service development]]></title>
    <link href="http://matt.aimonetti.net/posts/2012/06/13/rethinking-web-service-development/"/>
    <updated>2012-06-13T18:19:00-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2012/06/13/rethinking-web-service-development</id>
    <content type="html"><![CDATA[<p>While it's true that there are still a lot of places where software isn't
leveraged and many places where software needs to evolve, software is nearly everywhere!.
The type of software we write today needs to interact
with other software via some sort of network.
Any web developer out there is used to that, (s)he writes software that
runs on a server somewhere on the internet and users via a local software
(browser) consume their web applications using an internet connection.</p>

<p>What has changed in the last few years is that web applications start
providing more than just dynamically rendered HTML templates.
JavaScript is used to run more and more logic on the client side and JS
usually talks to some backends via JSON.
But web APIs are also more and more used to expose raw data to other
software. <strong>The challenge though, is that we haven't changed the way we
write web applications to adapt to this new way of providing data.</strong>
In this article, I'd like to explore why and how we need to rethink web API development
and focus on communication and interaction.</p>

<h2>Unlearning</h2>

<p><a href="/images/matt_aimonetti-unlearn.jpeg"><img src="/images/matt_aimonetti-unlearn.jpeg"
  style="width:250px;display:block;margin:auto"/></a></p>

<p>Many are used to doing certain
things a certain way and it's really hard to unlearn old habits. The more
concerning part of this fact is that it makes it <strong>hard for someone to step
back and evaluate honestly if a technical decision is due to comfort or
if it's truly the right choice to achieve a given goal.</strong>
Ruby on Rails revolutionized the way we wrote web applications almost 10
years ago and since then, many web frameworks have adopted the Rails philosophy.
As a matter of fact, I personally think that when it comes to writing
front end applications, Rails is still one if not the best web
frameworks out there. But in its current state, I'm far from convinced that it's a great tool to write
web APIs mainly because it was not designed for that and because it
comes with a lot of baggage.</p>

<h2>Focusing on the API</h2>

<p>Let's take a step back and consider what is critical when developing a web
API:</p>

<ul>
<li><strong>Documentation</strong> for end users to know how to consume your services.</li>
<li><strong>Consistent and reliable</strong> output so you don't break client applications
relying on your services.</li>
<li><strong>Maintainability</strong></li>
</ul>


<p>Note that I didn't mention performance because I consider performance
almost always being important.
I also didn't mention the whole
<a href="http://en.wikipedia.org/wiki/Representational_state_transfer">REST</a>/<a href="http://en.wikipedia.org/wiki/Remote_procedure_call">RPC</a>/<a href="http://en.wikipedia.org/wiki/Hypermedia">Hypstermedia</a> debate
since I consider it being an implementation detail and a totally orthogonal
discussion. But for the record, I personally don't like solutions forcing you into a specific way of
providing your data (I'm looking at you <a href="http://wiki.basho.com/Webmachine.html">webmachine</a>).</p>

<h3>Documentation</h3>

<p>Documentation isn't as important when you consume your own APIs because
you can look at your source code. However it gets much more tricky when
you start working with other teams. They might not know the
language/framework you use. They might not have time to go dig into your
source code to figure out what your <strong>meta-magical piece of clever
code</strong> does.</p>

<p>Lately more and more applications provide their raw data to the
outside world via web APIs. The developers who will consume your
resources don't have access to your source code, probably don't use the same
programming language and don't have much time to guess how your API
work. Also your test suite won't help communicate how your API works so
we need to find a different approach.
Also note that in this scenario, TDD/BDD won't help us communicate
better and tests can't be used as documentation since your tests aren't
exposed.</p>

<p><em>Documentation is your #1 way to communicate with your human audience.</em>
Communication is key and even if as engineers we love to focus on code, if we
can't communicate about it, end users will have a hard time using our
code and might just not even do it. <strong>The key is to communicate what your API does,
why someone might want to use it and how to use it.</strong></p>

<h3>Consistent and reliable output</h3>

<p>This point seems obvious but what we realize in reality is that
for many, API's consistency and reliability doesn't include
documentation. You find a lot of APIs out there poorly documented or out
of sync with the actual implementation.</p>

<p><strong>Documentation is a contract between
you: the developer and the other developers consuming your APIs.</strong>
As a developer, when you write any type of tests, they become some sort of quality contract.
If someone changes your code and break your tests, they break the implicit contract.
However, when talking about consuming data via an API, things get a bit more complicated.
We need a way to ensure that the end user expectations are matching our
implementation/documentation. Unit testing simply can't guarantee that. Unit testing will
guarantee that the logic of your units of code is intact but it can't
easily guarantee that the API output matches the documentation, however
this is something that has to be done.</p>

<h3>Maintainability</h3>

<p>This is a tricky point since maintainability is very subjective. But I
think we can agree that <a href="http://en.wikipedia.org/wiki/Decoupling#Software_development">decoupling</a>/<a href="http://en.wikipedia.org/wiki/Separation_of_concerns">separating concerns</a>
will make our code more maintainable.</p>

<p>That's why I personally don't think it's a good idea to mix HTML
rendering code and web API code. Consider using different controllers or
different files depending on the way your code is structured.</p>

<p>I also strongly believe that the implementation details shouldn't define
the way you design your web APIs. Don't just slap a CRUD API on top of your
model and call it done. In most cases, you will pay a high price later
on if you take this approach because whenever you will need to change your
web API or your model, you will be stuck. This is because your interface
is now used by a lot of people and you can't easily change it.
There are many ways to avoid API/model coupling, I don't advocate one particularly, but whatever you do,
be sure you can make your models and APIs can evolve separately.</p>

<br><br>


<h2>My approach</h2>

<p>I've been designing and developing web APIs for many years and I've been
struggling with everything I mentioned until now.
I don't claim that I've found <strong>the</strong> solution but I'd like to think that I
found one own way of addressing what are for me some of the most important parts
of API design.</p>

<h2>Being explicit</h2>

<p>I believe that there is value in being explicit in the way we describe
web APIs. Sometimes people get confused between being <a href="http://en.wiktionary.org/wiki/verbose">verbose</a> and being
<a href="http://en.wiktionary.org/wiki/explicit">explicit</a>. These are two different concepts.
Being explicit can sometimes seem verbose, but we need to evaluate the
value that can be extracted from the provided information. If there isn't any clear value and too many words are used, then we
aren't explicit, we are verbose.</p>

<p>When designing a web API, I don't write it for myself, I do it for someone
else. <strong>It's crucial to consider who you are writing for
and to expose what's important for them.</strong>
A "small" problem is that we don't show our code to our end users, so we
need to find a way to explicitly provide the important information and
to have this information provided to our end users.</p>

<h2>DSL</h2>

<p>For that I use a Domain Specific Language (DSL) which is a fancy way to
say that I have some specific code allowing me to explicitly define my
web services. These services exist as objects that can then be used to
<em>process requests</em> but also to <em>validate inputs</em>, and even more importantly
to <em>generate documentation</em>.</p>

<p>The DSL allows me to define the following:</p>

<ul>
<li>details about consuming the service (uri, HTTP verb, authentication details,
other service details...)</li>
<li>incoming params (which ones are allowed, the type, are they required,
optional?, what are they for)</li>
<li>service output</li>
</ul>


<p>The input details is really important to validate incoming requests and
reject them before even dispatching them. This is done for data sanity
and for security reason. It also defines a strong interface that is
easier to develop against and to maintain.</p>

<p>The output details might sound quite surprising and redundant. After all, isn't that a
duplication of effort since we already have this information in the
"view"? Well, if we consider the important points I highlighted in the
first part of this article, we need a way to enforce a "contract"
between the end users and our implementation. To do that, we can't
simply rely on our code since we can't trust it. The output is important
to document the expected output but also to validate that our services
match our documentation and therefore our "contract".</p>

<p>Here is an example of a Ruby <a href="https://github.com/mattetti/Weasel-Diesel">DSL</a> use to describe a hello world service:</p>

<p>```ruby
describe_service "hello_world" do |service|
  service.formats   :json
  service.http_verb :get
  service.disable_auth # on by default</p>

<p>  # INPUT
  service.param.string  :name, :default => 'World', :doc => "The name of the person to greet."</p>

<p>  # OUTPUT
  service.response do |response|</p>

<pre><code>response.object do |obj|
  obj.string :message, :doc =&gt; "The greeting message sent back. Defaults to 'World'"
  obj.datetime :at, :doc =&gt; "The timestamp of when the message was dispatched"
end
</code></pre>

<p>  end</p>

<p>  # DOCUMENTATION
  service.documentation do |doc|</p>

<pre><code>doc.overall "This service provides a simple hello world implementation example."
doc.example "&lt;code&gt;curl -I 'http://localhost:9292/hello_world?name=Matt'&lt;/code&gt;"
</code></pre>

<p>  end
end
```</p>

<p>The DSL style isn't really important, what's important is that it allows
us to address some of the concerns we discussed earlier such as clearly
defined interface that can be communicated as documentation but also
acts as code. The focus is really on the API and everything fits in one
page. Because everything is an object and can be inspected, proper
and up to date documentation can be generated. And the implementation
can be tested against the documentation since everything is maintained
as code.</p>

<h2>Being agnostic</h2>

<p>While I like Ruby for many reasons, I don't think that it's the only
good language to implement great web services. It actually has its pros
and cons and so have all the web frameworks out there.
That's why I wrote my DSL as a <a href="https://github.com/mattetti/Weasel-Diesel">standalone library</a> that could virtually
run on top of any web engine since it only outputs a representation of services.</p>

<p>While I hope to one day create an interesting interop solution across
programming language (by exporting the objects in a shared data
structure for instance), I started by focusing on the various Ruby web
frameworks.</p>

<p>The best starting point for me was to use <a href="http://www.sinatrarb.com/">Sinatra</a>.
I almost started just using <a href="http://rack.github.com/">rack</a>, but <a href="http://www.sinatrarb.com/">Sinatra</a> was providing me with a bit more feature for very
little headache and little code to grasp. I wrote <a href="https://github.com/mattetti/wd-sinatra">wd-sinatra</a> which
is a Ruby gem providing the <a href="https://github.com/mattetti/Weasel-Diesel">WeaselDiesel DSL</a> on top of a Sinatra app.
It comes with a generator and all the needed hooks to design, implement, test and
generate documentation for modern web APIs.</p>

<p>Using a simple rake command (Ruby's version of make) one can generate
documentation or test the APIs against the implementations.
The "mini framework" is still very free form and should let you do
whatever you want. I don't even set a default ORM for you to use since
this choice is highly personal. I do however leave you places to set
these things.</p>

<p><a href="/images/matt_aimonetti-WeaselDiesel_doc_generation.jpeg"><img src="/images/matt_aimonetti-WeaselDiesel_doc_generation.jpeg" style="width:200px;display:block;margin:auto" title="Matt Aimonetti - WeaselDiesel documentation generation example" alt="Matt Aimonetti - WeaselDiesel documentation generation example"></a></p>

<p>Sinatra and my "freedom framework" might seem too free form for
you. So I'm currently working on getting the DSL to run on top of Rails,
and by goal is to actually get it to run with a normal Rails app.</p>

<h2>Reconsidering Rails' MVC</h2>

<p>The Rails code base is very deeply marked with its own concept of MVC and having controllers and actions.
The challenge I have is that I like my service to be self contained. I
want my services to be simple and easy to grasp. I like having 1 service
per file. Models, libraries and other optional presenters/decorators live separately
but I like to have my service implementation code with the rest of my
service description. I honestly don't like telling developers that they
need to go check a route file and that my simple service requires that
you open 12 files to understand what's going on. Simpler is often better
and that's why in <a href="https://github.com/mattetti/wd-sinatra">wd-sinatra</a>
the DSL and the implementation live together which is quite harder to do
with Rails.</p>

<p>```ruby
describe_service "hello_world" do |service|</p>

<p>  # [...] see the DSL section to see how the
  # service is described. The block below is being
  # being called in the context of the request
  # after the request was validated.</p>

<p>  # SERVICE IMPLEMENTATION
  # the returned value is used as the response body, all the Sinatra helpers
  # are available.
  service.implementation do</p>

<pre><code>{:message =&gt; "Hello #{params[:name]}", :at =&gt; Time.now}.to_json
</code></pre>

<p>  end
end
```</p>

<h2>Learning from experience</h2>

<p>While the DSL fits most of my needs, we all have different use cases.
While it's critical for a library to have a clearly defined objective, it's also important to
have many people help improve it. Part of the learning/vetting
excercise is to test an approach against different needs to define when
and why it works well in some cases and why sometinmes it doesn't. This
allows us to define a sweet spot that should match the clearly defined
objective. However to be able to do that, a design needs to be tested by
many people. So far my approach seems to work very well when an
API needs to live outside an application and that 3rd parties need to
consume the resources. It also seems to work well with edge cases that
many API designers seem to encounter sooner or later.</p>

<h2>Conclusion</h2>

<p>At the end of the day, we have to remember that API stands for
<em>Application Programming Interface</em> and that these interfaces have to be
programmed so humans can write to comsume them. One of Ruby's main design points has always
been to try to address human needs more than computer's. As API
designers/implementers, it seems important to adopt the same approach and
consider who will use our interfaces.
I think the discussion should focus more on what to value when
defining web APIs, instead of arguing about how to implement APIs.
Standardization is a great concept but a really hard to implement. And
even with standards, we have to find a way to communicate with the API
users to express what standards we follow and where to find the various
entry points.
Think about your API, <strong>how well does it
communicate with your future API users</strong>, is it good enough for them to get
excited? Is it good enough for them to create something amazing with it?
If not, why not?</p>

<h3>Discussion</h3>

<p>Comments are available on <a href="http://news.ycombinator.com/item?id=4107126">this HackerNews thread</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MacRuby on iOS - RubyMotion review]]></title>
    <link href="http://matt.aimonetti.net/posts/2012/05/04/macruby-on-ios-rubymotion-review/"/>
    <updated>2012-05-04T07:17:47-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2012/05/04/macruby-on-ios-rubymotion-review</id>
    <content type="html"><![CDATA[<p>Yesterday, <a href="http://www.rubymotion.com/">RubyMotion</a> was released and let's be honest, it is one the best alternatives to Objective-C out there (if not the best).</p>

<p>RubyMotion is a commercial, proprietary fork of MacRuby that targets iOS. This is not a small achievement, MacRuby relies on Objective C's Garbage Collector (libauto) which is not available on iOS. Static compilation and new memory management solution was required to target the iOS platform . The new runtime had to be small and efficient. Furthermore, being able to run code on iOS isn't enough, you need tools to interact with the compiler, to debug, to packages applications etc...</p>

<p>I don't think anyone will contest the fact that RubyMotion is a well done product. The question however is, "<strong>is it worth for you to invest some money, time and energy in this product instead of using Apple's language and tools</strong>". In this article, I'll try to balance the pros and cons of RubyMotion so you can have a better understanding of what RubyMotion could mean for you. As a disclaimer I should say that I was beta testing RubyMotion, that they are strong ties between RubyMotion and the MacRuby project I'm part of and finally that having MacRuby on iOS has been something I've been looking forward for a very long time.</p>

<p>Over the last few months I've seen RubyMotion take shape and finally hit the big 1.0. As you can see from <a href="http://twitter.com/#!/search/rubymotion?q=rubymotion">Twitter</a> and <a href="http://news.ycombinator.com/item?id=3924657">HackerNews</a>, the Ruby community is excited about being able to use their language to write statically compiled, native iOS apps. Spoiler alert, they are right, it's a lot of fun.</p>

<p> </p>

<hr />

<p> </p>

<h2>What I like about RubyMotion:</h2>

<h3>Ruby Language</h3>

<p>I don't mind Objective-C, I think it's a fine superset of C, with the arrival of blocks, new literals and automatic memory management via ARC, Objective-C is actually getting better over time. But frankly, it's not Ruby. You still have to deal with headers, you always have to compile your code via some weird Xcode voodoo settings, testing is a pain, the language, even with the new literals is quite verbose. On the other hand, using Ruby syntax I can get much more flexibility, reuse my code via mixins, easily reopen existing classes etc... At the end of the day, I end up with some code that seems cleaner, easier to understand and maintain even though I'm calling the same underlying APIs. Ruby's flexibility also allows developers to make their own higher level APIs, take a look at some of the <a href="https://github.com/mattetti/BubbleWrap">wrappers/helpers</a> I wrote while playing with RubyMotion.</p>

<p><a href="http://www.ruby-lang.org/en/"><img src="http://merbist.com/wp-content/uploads/2012/05/matt_aimonetti-Ruby_logo-150x150.jpg" alt="Matt Aimonetti - Ruby Logo" /></a></p>

<h3>MacRuby</h3>

<p>RubyMotion is based on MacRuby, meaning that all the time and energy invested in the project will benefit RubyMotion's users. All the concepts I explain in my <a href="http://shop.oreilly.com/product/0636920000723.do">MacRuby book</a> apply to RubyMotion. You don't have to find workarounds to work with native APIs, Ruby objects are Objective-C objects and performance is great. I do regret Apple didn't decide to embrace MacRuby for iOS but at the same time, even though we lost the Open Source aspect of the project and Apple's backing, we gained much more flexibility and freedom on Laurent's part.</p>

<p><a href="https://www.amazon.com/dp/1449380379?tag=merbist-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=1449380379&amp;adid=1SKHT7ABMG1YJZ3136WQ&amp;"><img src="http://merbist.com/wp-content/uploads/matt_aimonetti/matt_aimonetti_macruby_book.gif" alt="" /></a></p>

<h3>REPL/Interactive shell</h3>

<p>RubyMotion doesn't currently have a debugger, but it does have something Objective-C developers don't have, a <a href="http://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop">REPL</a> working with the simulator. This feature is quite handy when debugging your application or learning the Cocoa APIs. You can click on a visual element in the simulator and start modifying the objects in real time in a terminal window and see the modifications in the simulator. It reminds me of the first time I used firebug to edit the html/css of a web page and saw the changes in real time.</p>

<p><a href="http://www.youtube.com/watch?feature=player_embedded&amp;v=rejYKzLglSE#!"><img src="http://merbist.com/wp-content/uploads/2012/05/matt_aimonetti-RubyMotion-REPL-150x150.jpg" alt="Matt Aimonetti - RubyMotion REPL" /></a></p>

<h3>Not dependent on Xcode</h3>

<p>Xcode is fine when you write Objective-C code, but it crashes often, it has a complicated UI and never really worked well for MacRuby due to the fact that Objective-C and Ruby have different requirements and the that Xcode is not open source. It's also fully controlled by Apple and doesn't provide APIs for 3rd party developers. (That said, the Xcode team has often helped out when a new released of Xcode broke MacRuby, so thank you guys).</p>

<p>Being able to use simple rake tasks to compile, simulate and deploy applications is just really really nice. I'm sure we'll end up with better IDE integration, nice GUIs for some who like that, but in the meantime, as a "hacker", I really enjoy the simplicity of the Rake tasks and not being forced in using a specific IDE.</p>

<p> </p>

<h3>Memory management</h3>

<p>Even though ARC made memory management much easier for Objective-C developers, when using RubyMotion you don't have to worry about memory (well at least not explicitly, don't be dumb and create a bazillion objects and hold references to them either). This includes the CoreFoundation objects that you still have to manually manage in Objective-C. Memory management is transparent and in most cases it's really nice.</p>

<p> </p>

<hr />

<p> </p>

<h2>What I like less about RubyMotion</h2>

<p>Here is a list of things that are cons to using RubyMotion, note that while the list is longer than my list of "pros", I listed a lot of small things. I also think that most of these issues will get solved in the next few months.</p>

<p> </p>

<h3>Ruby language</h3>

<p>There are some cases where Ruby just isn't that great or is not an option. Examples include dealing with API relying heavily on pointers, when using some of the lower level APIs or when you have to interact with C++ (video game engines for instance). The good news is that within the same project, you can write part of your code in Objective-C and the rest in RubyMotion. The other thing that bothers me a little bit with writing Ruby code for iOS is that you can't easily enforce argument types and therefore you are losing a lot of the features provided by Clang to the Objective-C developers. I dream of an optionally typed Ruby -- but that's a different topic.</p>

<p>Another downside of using Ruby is that Ruby developers will assume all standard libraries and gems will be compatible with RubyMotion. This isn't the case. You need to think of RubyMotion as only offering the Ruby syntax (modulo a few differences). To be honest, most of the std libs and gems aren't that useful when writing iOS apps. Even when I write MacRuby apps, I rarely rely on them and pick libraries designed to work in a non-blocking, multi-threaded environment (usually ObjC libs that I wrap).</p>

<p> </p>

<h3>Cocoa Touch</h3>

<p>If you're already an iOS/OS X developer, you know that most of the hurdles aren't the language syntax but the Cocoa APIs. These APIs are what you need to interact with to create your application. Cocoa APIs are usually much lower-level compared to what you usually see in Python, Ruby or even Java. While they are quite consistent, the APIs still have a stiff learning curve and currently,  if you want to write iOS applications, even if you know Ruby, you still have to learn Cocoa.</p>

<p>However, I do think that with RubyMotion now building a userbase, we will start seeing more and more <a href="https://github.com/mattetti/BubbleWrap">wrappers</a> around these sometimes <a href="https://github.com/HipByte/RubyMotionSamples/blob/master/GestureTable/app/gesture_recognizer.rb">hideous APIs</a>.</p>

<p> </p>

<h3>No Xcode/IDE</h3>

<p>There are cases where an IDE is really practical, especially when learning new APIs. Being able to have code completion, quick access to the documentation, instrumentation, debugging, interface builder, refactoring tools are things that Objective-C developers might have a hard time with when switching to RubyMotion. If you don't know either Ruby or Cocoa, getting started with RubyMotion might be quite hard and you are probably not currently in the target audience.</p>

<p> </p>

<h3>Writing UI code by hand</h3>

<p>In some cases, it makes sense, in other, it should be much easier. I know that Laurent is working on a DSL to make that easier and I'm looking forward to it. But in the mean time, this is quite a painful exercise, especially due to the complexity of the Cocoa UI APIs. Using Xcode's interface builder and Storyboards is something I know a lot of us wish we could do with RubyMotion when developing specific types of applications.</p>

<p><a href="http://kurrytran.blogspot.fr/2011/07/simple-ios-5-tutorial-using-storyboard.html"><img src="http://merbist.com/wp-content/uploads/2012/05/matt_aimonetti_storyboard-1.jpg" alt="Matt Aimonetti - Xcode iOS storyboard" /></a></p>

<h3>No debugger</h3>

<p>Again, this is eventually coming but the current lack of debugger can be problematic at times, especially when the problem isn't obvious.</p>

<p> </p>

<h3>Lack of clear target audience</h3>

<p>It's hard to blame a brand new product for not having clearly defined a target audience. But as a developer I find myself wondering "when should I use RubyMotion and for what kinds of problems?" Is RubyMotion great for quick prototypes I can then turn into production code? Or is good for throw away prototypes? Is it reserved for "fart and flash light" applications? Is it ready for prime time and should I invest and write my new awesome apps using it? Should I convert over my existing code base over from Titanium (or whatever other alternatives you used)? Should I use RubyMotion every time I would use Objective-C?</p>

<p>I guess we will see when the first applications start hitting the app store and people start reporting on their experience.</p>

<h3>Documentation</h3>

<p>I'm partially to blame here since I could have moved my butt and start writing a book but the point is nonetheless valid. All the iOS documentation out there is for Objective-C, all the APIs and samples provided by Apple are obviously only for Objective-C. Thankfully, you can use the 2 MacRuby books available out there to understand how to convert this existing documentation into something useful, but RubyMotion will need to provide better and more adapted documentation for beginners. I have no doubt that this is coming sooner than later.</p>

<p> </p>

<h3>Proprietary solution</h3>

<p>RubyMotion isn't open source and currently fully relies on the shoulders of a single man. If unfortunately, Laurent goes out of business or decides to do something else then we will have to rewrite our apps in Objective-C.  Using RubyMotion for a professional product represents a significant business risk, which is exactly the same as using proprietary technology from any vendor. Apple could also decide to switch to JavaScript or rewrite iOS in Java and deprecate Objective-C. Let's just say that it is unlikely.</p>

<p>I usually favor open source solutions, from the programming language I use to the OS I deploy on. This isn't always possible and if you want to write iOS applications, you don't currently have a choice. I do wish Laurent had found a way to make money while keeping the source code open. But who knows -- after he makes his first million(s), he might change his mind.</p>

<p><a href="http://merbist.com/wp-content/uploads/2012/05/matt_aimonetti-rms.jpg"><img src="http://merbist.com/wp-content/uploads/2012/05/matt_aimonetti-rms-150x150.jpg" alt="Matt Aimonetti - RMS" /></a></p>

<h2>Conclusion</h2>

<p>I would strongly suggest you consider giving RubyMotion a try. I can assure you that it will provide at least a few hours of 'hacking fun' (and you will be able to brag about havng written your own iPhone app).  It will also help support financially someone who's taking a risk in trying to push mobile development to the next level.</p>

<p>RubyMotion is, by far, my favorite alternative to Objective-C. But it is hard to tell, just 48 hours after its release, what people will do with it. Can it transcend the programming language barriers and attract Python, PHP, Java, ObjC and JavaScript developers? What is the sweet spot for RubyMotion applications? Will it affect the native vs web app battle? Can it make iOS development more accessible to the masses? Only time will tell.</p>

<br/>


<hr />

<h3>Update:</h3>

<p>Since RubyMotion 1.0 was released, I spent quite a lot of my free time leading the
development of <a href="http://bubblewrap.io/">BubbleWrap</a>, a free and open
source 3rd party library for <a href="http://www.rubymotion.com/">RubyMotion</a>.
Unfortunately, as of July 2011 <strong>I took a break from this project and
RubyMotion in general</strong>. I explained my motivations in <a href="https://groups.google.com/d/topic/rubymotion/XIE673vnuQk/discussion">this mailing list
post</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building and implementing a Single Sign-On solution]]></title>
    <link href="http://matt.aimonetti.net/posts/2012/04/04/building-and-implementing-a-single-sign-on-solution/"/>
    <updated>2012-04-04T07:29:16-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2012/04/04/building-and-implementing-a-single-sign-on-solution</id>
    <content type="html"><![CDATA[<p>Most modern web applications start as a monolithic code base and, as complexity increases, the once small app gets split apart into many "modules". In other cases, engineers opt for a <a href="http://en.wikipedia.org/wiki/Service-oriented_architecture">SOA</a> design approach from the beginning. One way or another, we start running multiple separate applications that need to interact seamlessly. My goal will be to describe some of the high-level challenges and solutions found in implementing a Single-Sign-On service.</p>

<h2>Authentication vs Authorization</h2>

<p>I wish these two words didn't share the same root because it surely confuses a lot of people. My most frequently-discussed example is <a href="http://en.wikipedia.org/wiki/OAuth">OAuth</a>. Every time I start talking about implementing a centralized/unified authentication system, someone jumps in and suggests that we use <a href="http://en.wikipedia.org/wiki/OAuth">OAuth</a>. The challenge is that <a href="http://en.wikipedia.org/wiki/OAuth">OAuth</a> is an authorization system, not an authentication system.</p>

<p>It's tricky, because you might actually be "authenticating" yourself to website X using OAuth. What you are really doing is allowing website X to use your information stored by the OAuth provider. It is true that OAuth offers a pseudo-authentication approach via its provider but that is not the main goal of <a href="http://en.wikipedia.org/wiki/OAuth">OAuth</a>: the Auth in OAuth stands for Authorization, not Authentication.</p>

<p>Here is how we could briefly describe each role:</p>

<ul>
<li><p><strong>Authentication</strong>: recognizes who you are.</p></li>
<li><p><strong>Authorization</strong>: know what you are allowed to do, or what you allow others to do.</p></li>
</ul>


<p>If you are feel stuck in your design and something seems wrong, ask yourself if you might be confused by the 2 auth words. This article will only focus on <strong>authentication</strong>.</p>

<h2>A Common Scenario</h2>

<p><a href="http://merbist.com/wp-content/uploads/2012/04/SSO-simplescenario.png"><img src="http://merbist.com/wp-content/uploads/2012/04/SSO-simplescenario.png" alt="SSO diagram with 3 top applications connecting to an authorization service." /></a></p>

<p>This is probably the most common structure, though I made it slightly more complex by drawing the three main apps in different programming languages. We have three web applications running on different subdomains and sharing account data via a centralized authentication service.</p>

<p><strong>Goals:</strong></p>

<ul>
<li><p>Keep authentication and basic account data isolated.</p></li>
<li><p>Allow users to stay logged in while browsing different apps.</p></li>
</ul>


<p>Implementing such a system should be easy. That said, if you migrate an existing app to an architecture like that, you will spend 80% of your time decoupling your legacy code from authentication and wondering what data should be centralized and what should be distributed. Unfortunately, I can't tell you what to do there since this is very domain specific. Instead, let's see how to do the "easy part."</p>

<h2>Centralizing and Isolating Shared Account Data</h2>

<p>At this point, you more than likely have each of your apps talk directly to shared database tables that contain user account data. The first step is to migrate away from doing that. We need a single interface that is the only entry point to create or update shared account data. Some of the data we have in the database might be app specific and therefore should stay within each app, anything that is shared across apps should be moved behind the new interface.</p>

<p>Often your centralized authentication system will store the following information:</p>

<ul>
<li><p>ID</p></li>
<li><p>first name</p></li>
<li><p>last name</p></li>
<li><p>login/nickname</p></li>
<li><p>email</p></li>
<li><p>hashed password</p></li>
<li><p>salt</p></li>
<li><p>creation timestamp</p></li>
<li><p>update timestamp</p></li>
<li><p>account state (verified, disabled ...)</p></li>
</ul>


<p>Do not duplicate this data in each app, instead have each app rely on the account ID to query data that is specific to a given account in the app. Technically that means that instead of using SQL joins, you will query your database using the ID as part of the condition.</p>

<p>My suggestion is to do things slowly but surely. Migrate your database schema piece by piece assuring that everything works fine. Once the other pieces will be in place, you can migrate one code API a time until your entire code base is moved over. You might want to change your DB credentials to only have read access, then no access at all.</p>

<h2>Login workflow</h2>

<p>Each of our apps already has a way for users to login. We don't want to change the user experience, instead we want to make a transparent modification so the authentication check is done in a centralized way instead of a local way. To do that, the easiest way is to keep your current login forms but instead of POSTing them to your local apps, we'll POST them to a centralized authentication API. (SSL is strongly recommended)</p>

<p><a href="http://merbist.com/wp-content/uploads/2012/04/SSO-login.png"><img src="http://merbist.com/wp-content/uploads/2012/04/SSO-login.png" alt="diagram showing the login workflow" /></a></p>

<p>As shown above, the login form now submits to an endpoint in the authentication application. The form will more than likely include a login or email and a clear text password as well as a hidden callback/redirect url so that the authentication API can redirect the user's browser to the original app. For security reasons, you might want to white list the domains you allow your authentication app to redirect to.</p>

<p>Internally, the Authentication app will validate the identifier (email or login) using a hashed version of the clear password against the matching record in the account data. If the verification is successful, a token will be generated containing some user data (for instance: id, first name, last name, email, created date, authentication timestamp). If the verification failed, the token isn't generated. Finally the user's browser is redirected to the callback/redirect URL provided in the request with the token being passed.</p>

<p>You might want to safely encrypt the data in a way that allows the clients to verify and trust that the token comes from a trusted source. A great solution for that would be to use <a href="http://en.wikipedia.org/wiki/RSA_(algorithm">RSA encryption</a>) with the public key available in all your client apps but the private key only available on the auth server(s). Other strong encryption solutions would also work. For instance, another appropriate approach would be to add a signature to the params sent back. This way the clients could check the authenticity of the params. <a href="http://en.wikipedia.org/wiki/HMAC">HMAC</a> or <a href="http://en.wikipedia.org/wiki/Digital_Signature_Algorithm">DSA</a> signature are great for that but in some cases, you don't want people to see the content of the data you send back. That's especially true if you are sending back a 'mobile' token for instance. But that's a different story. What's important to consider is that we need a way to ensure that the data sent back to the client can't be tampered with. You might also make sure you prevent replay attacks.</p>

<p>On the other side, the application receives a GET request with a token param. If the token is empty or can't be decrypted, authentication failed. At that point, we need to show the user the login page again and let him/her try again. If on the other hand, the token can be decrypted, the content should be saved in the session so future requests can reuse the data.</p>

<p>We described the authentication workflow, but if a user logins in application X, (s)he won't be logged-in in application Y or Z. The trick here, is to set a top level domain cookie that can be seen by all applications running on subdomains. Certainly, this solution only works for apps being on the same domain, but we'll see later how to handle apps on different domains.</p>

<p><a href="http://merbist.com/wp-content/uploads/2012/04/SSO-login-cookie.png"><img src="http://merbist.com/wp-content/uploads/2012/04/SSO-login-cookie.png" alt="" /></a></p>

<p>The cookie doesn't need to contain a lot of data, its value can contain the account id, a timestamp (to know when authentication happened and a trusted signature) and a signature. The signature is critical here since this cookie will allow users to be automatically logged in other sites. I'd recommend the  <a href="http://en.wikipedia.org/wiki/HMAC">HMAC</a> or <a href="http://en.wikipedia.org/wiki/Digital_Signature_Algorithm">DSA</a> encryptions to generate the signature. The DSA encryption, very much like the RSA encryption is an asymmetrical encryption relying on a public/private key. This approach offers more security than having something based a shared secret like HMAC does. But that's really up to you.</p>

<p>Finally, we need to set a filter in your application. This auto-login filter will check the presence of an auth cookie on the top level domain and the absence of local session. If that's the case, a session is automatically created using the user id from the cookie value after the cookie integrity is verified. We could also share the session between all our apps, but in most cases, the data stored by each app is very specific and it's safer/cleaner to keep the sessions isolated. The integration with an app running on a different service will also be easier if the sessions are isolated.</p>

<p> </p>

<h2>Registration</h2>

<p>For registration, as for login, we can take one of two approaches: point the user's browser to the auth API or make S2S (server to server) calls from within our apps to the Authentication app. POSTing a form directly to the API is a great way to reduce duplicated logic and traffic on each client app so I'll demonstrate this approach.</p>

<p><a href="http://merbist.com/wp-content/uploads/2012/04/CopyofSSO-register.png"><img src="http://merbist.com/wp-content/uploads/2012/04/CopyofSSO-register.png" alt="" /></a></p>

<p>As you can see, the approach is the same we used to login. The difference is that instead of returning a token, we just return some params (id, email and potential errors). The redirect/callback url will also obviously be different than for login. You could decide to encrypt the data you send back, but in this scenario, what I would do is set an auth cookie at the .domain.com level when the account is created so the "client" application can auto-login the user. The information sent back in the redirect is used to re-display the register form with the error information and the email entered by the user.</p>

<p>At this point, our implementation is almost complete. We can create an account and login using the defined credentials. Users can switch from one app to another without having to re login because we are using a shared signed cookie that can only be created by the authentication app and can be verified by all "client" apps. Our code is simple, safe and efficient.</p>

<h2>Updating or deleting an account</h2>

<p>The next thing we will need is to update or delete an account. In this case, this is something that needs to be done between a "client" app and the authentication/accounts app. We'll make S2S (server to server) calls. To ensure the security of our apps and to offer a nice way to log requests, API tokens/keys will be used by each client to communicate with the authentication/accounts app. The API key can be passed using a <a href="http://en.wikipedia.org/wiki/List_of_HTTP_header_fields">X-header</a> so this concern stays out of the request params and our code can process separately the authentication via X-header and the actual service implementation. S2S services should have a filter verifying and logging the API requests based on the key sent with the request. The rest is straight forward.</p>

<h2>Using different domains</h2>

<p>Until now, we assumed all our apps were on the same top domain. In reality, you will often find yourself with apps on different domains. This means that you can't use the shared signed cookie approach anymore. However, there is a simple trick that will allow you to avoid requiring your users to re-login as they switch apps.</p>

<p><a href="http://merbist.com/wp-content/uploads/2012/04/SSO-differentdomains-1.png"><img src="http://merbist.com/wp-content/uploads/2012/04/SSO-differentdomains-1.png" alt="" /></a></p>

<p> </p>

<p>The trick consists, when a local session isn't present, of using an iframe in the application using the different domain. The iframe loads a page from the authentication/accounts app which verifies that a valid cookie was set on the main top domain. If that is the case, we can tell the application that the user is already globally logged in and we can tell the iframe host to redirect to an application end point passing an auth token the same way we did during the authentication. The app would then create a session and redirect the user back to where (s)he started. The next requests will see the local session and this process will be ignored.</p>

<p>If the authentication application doesn't find a signed cookie, the iframe can display a login form or redirect the iframe host to a login form depending on the required behavior.</p>

<p>Something to keep in mind when using multiple apps and domains is that you need to keep the shared cookies/sessions in sync, meaning that if you log out from an app, you need to also delete the auth cookie to ensure that users are globally logged out. (It also means that you might always want to use an iframe to check the login status and auto-logoff users).</p>

<p> </p>

<h2>Mobile clients</h2>

<p>Another part of implementing a SSO solution is to handle mobile clients. Mobile clients need to be able to register/login and update accounts. However, unlike S2S service clients, mobile clients should only allow calls to modify data on the behalf of a given user. To do that, I recommend providing opaque mobile tokens during the login process. This token can then be sent with each request in a X-header so the service can authenticate the user making the request. Again, SSL is strongly recommended.</p>

<p>In this approach, we don't use a cookie and we actually don't need a SSO solution, but an unified authentication system.</p>

<p> </p>

<h2>Writing web services</h2>

<p>Our Authentication/Accounts application turns out to be a pure web API app.</p>

<p>We also have 3 sets of APIs:</p>

<ul>
<li><p>Public APIs: can be accessed from anywhere, no authentication required</p></li>
<li><p>S2S APIs: authenticated via API keys and only available to trusted clients</p></li>
<li><p>Mobile APIs: authenticated via a mobile token and limited in scope.</p></li>
</ul>


<p>We don't need dynamic HTML views, just simple web service related code. While this is a little bit off topic, I'd like to take a minute to show you how I personally like writing web service applications.</p>

<p>Something that I care a lot about when I implement web APIs is to validate incoming params. This is an opinionated approach that I picked up while at Sony and that I think should be used every time you implement a web API. As a matter of fact, I wrote a Ruby <a href="https://github.com/mattetti/Weasel-Diesel">DSL library (Weasel Diesel)</a> allowing you <a href="https://github.com/mattetti/sinatra-web-api-example/blob/master/api/hello_world.rb">describe a given service</a>, its <a href="https://github.com/mattetti/sinatra-web-api-example/blob/master/api/hello_world.rb#L7">incoming params</a>, and the <a href="https://github.com/mattetti/sinatra-web-api-example/blob/master/api/hello_world.rb#L10-15">expected output</a>. This DSL is hooked into a web backend so you can implement services using a web engine such as <a href="http://www.sinatrarb.com/">Sinatra</a> or maybe Rails3. Based on the DSL usage, incoming parameters are be verified before being processed. The other advantage is that you can generate documentation based on the API description as well as automated tests.</p>

<p>You might be familiar with <a href="https://github.com/intridea/grape">Grape</a>, another DSL for web services. Besides the obvious style difference <a href="https://github.com/mattetti/Weasel-Diesel">Weasel Diesel </a>offers the following advantages:</p>

<ul>
<li><p>input validation/sanitization</p></li>
<li><p>service isolation</p></li>
<li><p>generated documentation</p></li>
<li><p>contract based design</p></li>
</ul>


<p>Here is a hello world webservice being implemented using Weasel Diesel and Sinatra:</p>

<p><div><script src='https://gist.github.com/2300131.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>
</p>

<p>Basis test validating the contract defined in the DSL and the actual output when the service is called:</p>

<p><div><script src='https://gist.github.com/2300440.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>
</p>

<p>Generated documentation:</p>

<p><img src="https://img.skitch.com/20120404-t1j93b73tef5pmd5idfqqa61td.jpg" alt="" /></p>

<p>If the DSL and its features seem appealing to you and you are interested in digging more into it, the easiest way is to fork <a href="https://github.com/mattetti/sinatra-web-api-example/">this demo repo</a> and start writing your own services.</p>

<p>The DSL has been used in production for more than a year, but there certainly are tweaks and small changes that can make the user experience even better. Feel free to fork the <a href="https://github.com/mattetti/Weasel-Diesel">DSL repo</a> and send me Pull Requests.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Learning from Rails' failures]]></title>
    <link href="http://matt.aimonetti.net/posts/2012/02/29/learning-from-rails-failures/"/>
    <updated>2012-02-29T07:48:08-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2012/02/29/learning-from-rails-failures</id>
    <content type="html"><![CDATA[<p>Ruby on Rails undisputedly changed the way web frameworks are designed. Rails became a reference when it comes to leveraging conventions, easy baked in feature set and a rich ecosystem. However, I think that Rails did and still does a lot of things pretty poorly.  By writing this post, I'm not trying to denigrate Rails, there are many other people out there already doing that. My hope is that by listing what I think didn't and still doesn't go well, we can learn from our mistakes and improve existing solutions or create better new ones.</p>

<p><a href="http://merbist.com/2012/02/29/learning-from-rails-failures/train_fail/"><img src="http://merbist.com/wp-content/uploads/2012/02/train_fail-300x188.jpg" alt="" /></a></p>

<h2>Migration/upgrades</h2>

<p>Migrating a Rails App from a version to the other is very much like playing the lottery, you are almost sure you will lose. To be more correct, you know things will break, you just don't know what, when and how. The Rails team seems to think that everybody is always running on the cutting edge version and don't consider people who prefer to stay a few version behind for stability reasons. What's worse is that plugins/gems might or might not compatible with the version you are updating to, but you will only know that by trying yourself and letting others try and report potential issues.</p>

<p>This is for me, by far, the biggest issue with Rails and something that should have been fixed a long time ago. If you're using the WordPress blog engine, you know how easy and safe it is to upgrade the engine or the plugins. Granted WordPress isn't a web dev framework, but it gives you an idea of what kind of experience we should be striving for.</p>

<p> </p>

<h2>Stability vs playground zone</h2>

<p>New features are cool and they help make the platform more appealing to new comers. They also help shape the future of a framework. But from my perspective, that shouldn't come to the cost of stability. Rails 3's new asset pipeline is a good example of a half-baked solution shoved in a release at the last minute and creating a nightmare for a lot of us trying to upgrade. I know, I know, you can turn off the asset pipeline and it got better since it was first released. But shouldn't that be the other way around? Shouldn't fun new ideas risking the stability of an app or making migration harder, be off by default and turned on only by people wanting to experiment? When your framework is young, it's normal that you move fast and sometimes break, but once it matures, these things shouldn't happen.</p>

<p> </p>

<h2>Public/private/plugin APIs</h2>

<p>This is more of a recommendation than anything else. When you write a framework in a very dynamic language like Ruby, people will "monkey patch" your code to inject features. Sometimes it is due to software design challenges, sometimes it's because people don't know better. However,  by not explicitly specifying what APIs are private (they can change at anytime, don't touch), what APIs are public (stable, will be slowly deprecated when they need to be changed) and which ones are for plugin devs only (APIs meant for instrumentation, extension etc..), you are making migration to newer versions much harder. You see, if you have a small, clean public API, then it's easy to see what could break, warn developers and avoid migration nightmares. However, you need to start doing that early on in your project, otherwise you will end up like Rails where all code can potentially change anytime.</p>

<p> </p>

<h2>Rails/Merb merge was a mistake</h2>

<p>This is my personal opinion and well, feel free to disagree, nobody will ever be able to know to for sure. Without explaining what happened behind closed doors and the various personal motivations, looking at the end result, I agree with the group of people thinking that the merge didn't turn up to be a good thing. For me, Rails 3 isn't significantly better than Rails 2 and it took forever to be released. You still can't really run a mini Rails stack like promised. I did hear that Strobe (company who was hiring Carl Lerche, Yehuda Katz and contracted Jose Valim) used to have an ActionPack based, mini stack but it was never released and apparently only Rails core members really knew what was going on there. Performance in vanilla Rails 3 are only now getting close to what you had with Rails 2 (and therefore far from the perf you were getting with Merb). Thread-safety is still OFF by default meaning that by default your app uses a giant lock only allowing a process to handle 1 request at a time. For me, the flexibility and performance focus of Merb were mainly lost in the merge with Rails. (Granted, some important things such as ActiveModel, cleaner internals and others have made their way into Rails 3)</p>

<p>But what's worse than everything listed so far is that the lack of competition and the internal rewrites made Rails lose its headstart.  Rails is very much HTML/view focused, its primarily strength is to make server side views trivial and it does an amazing job at that. But let's be honest, that's not the future for web dev. The future is more and more logic pushed to run on the client side (in JS) and the server side being used as an API serving data for the view layer. I'm sorry but adding support for CoffeeScript doesn't really do much to making Rails evolve ahead of what it currently is. Don't get me wrong, I'm a big fan of CoffeeScript, that said I still find that Rails is far from being optimized to developer web APIs in Rails. You can certainly do it, but you are basically using a tool that wasn't designed to write APIs and you pay the overhead for that. If there is one thing I wish Rails will get better at is to make writing pure web APIs better (thankfully there is Sinatra). But at the end of the day, I think that two projects with different philosophies and different approaches are really hard to merge, especially in the open source world. I wouldn't go as far as saying like others that Rails lost its sexiness to node.js because of the wasted time, but I do think that things would have been better for all if that didn't happen. However, I also have to admit that I'm not sure how much of a big deal that is. I prefer to leave the past behind, learn from my own mistake and move on.</p>

<p> </p>

<h2>Technical debts</h2>

<p>Here I'd like to stop to give a huge props to Aaron "<a href="http://twitter.com/tenderlove">@tenderlove</a>" Patterson, the man who's actively working to reduce the <a href="http://en.wikipedia.org/wiki/Technical_debt">technical debts</a> in the Rails code base. This is a really hard job and definitely not a very glamorous one. He's been working on various parts of Rails including its router and its ORM (ActiveRecord). Technical debts are unfortunately normal in most project, but sometimes they are overwhelming to the point that nobody dares touching the code base to clean it up. This is a hard problem, especially when projects move fast like Rails did. But looking back, I think that you want to start tackling technical debts on the side as you move on so you avoid getting to the point that you need a hero to come up and clean the piled errors made in the past. But don't pause your entire project to clean things up otherwise you will lose market, momentum and excitement. I feel that this is also very much true for any legacy project you might pick up as a developer.</p>

<p> </p>

<h2>Keep the cost of entry level low</h2>

<p>Getting started with Rails used to be easier. This can obviously argued since it's very subjective, but from my perspective I think we forgot where we come from and we involuntary expect new comers to come with unrealistic knowledge. Sure, Rails does much more than it used to do, but it's also much harder to get started. I'm not going to argue how harder  it is now or why we got there. Let's just keep in mind that it is a critical thing that should always be re-evaluated. Sure, it's harder when you have an open source project, but it's also up to the leadership to show that they care and to encourage and mentor volunteers to  focus on this important part of a project.</p>

<p> </p>

<h2>Documentation</h2>

<p>Rails documentation isn't bad, but it's far from being great. Documentation certainly isn't one of the Ruby's community strength, especially compared with the Python community, but what saddens me is to see the state of <a href="http://guides.rubyonrails.org/">the official documentation</a> which, should, in theory be the reference. Note that the Rails guides are usually well written and provide value, but they too often seem too light and not useful when you try to do something not totally basic (for instance use an ActiveModel compliant object). That's probably why most people don't refer to them or don't spend too much time there. I'm not trying to blame anyone there. I think that the people who contributed theses guides did an amazing job, but if you want to build a strong and easy to access community, great documentation is key. Look at the <a href="https://docs.djangoproject.com/en/1.3/">Django</a> documentation as a good example. That said, I also need to acknowledge the amazing job done by many community members such as <a href="http://railscasts.com/">Ryan Bates</a> and <a href="http://ruby.railstutorial.org/">Michael Hartl</a> consistently providing high value external documentation via the <a href="http://railscasts.com/">railscasts</a> and the intro to <a href="http://ruby.railstutorial.org/">Rails tutorial</a> available for free.</p>

<p> </p>

<p>In conclusion, I think that there is a lot to learn from Rails, lots of great things as well as lots of things you would want to avoid. We can certainly argue on Hacker News or via comments about whether or not I'm right about Rails failures, my point will still be that the mentioned issues should be avoided in any projects, Rails here is just an example. Many of these issues are currently being addressed by the Rails team but wouldn't it be great if new projects learn from older ones and avoid making the same mistakes? So what other mistakes do you think I forgot to mention and that one should be very careful of avoiding?</p>

<p> </p>

<h3>Updates:</h3>

<ol>
<li><p>Rails 4 had an API centric app generator but it <a href="https://github.com/rails/rails/commit/6db930cb5bbff9ad824590b5844e04768de240b1">was quickly reverted</a> and will live as gem until it's mature enough.</p></li>
<li><p>Rails 4 improved the ActiveModel API to be simpler to get started with. See <a href="http://blog.plataformatec.com.br/2012/03/barebone-models-to-use-with-actionpack-in-rails-4-0/">this blog</a> post for more info.</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Quick dive into Ruby ORM object initialization]]></title>
    <link href="http://matt.aimonetti.net/posts/2012/02/23/quick-dive-into-ruby-orm-object-initialization/"/>
    <updated>2012-02-23T09:46:49-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2012/02/23/quick-dive-into-ruby-orm-object-initialization</id>
    <content type="html"><![CDATA[<p>Yesterday I did some quick digging into how ORM objects are initialized and the performance cost associated to that. In other words, I wanted to see what's going on when you initialize an ActiveRecord object.</p>

<p>Before I show you the benchmark numbers and you jump to conclusions, it's important to realize that in the grand scheme of things, the performance cost we are talking is small enough that it is certainly not the main reason why your application is slow. Spoiler alert: ActiveRecord is slow but the cost of initialization isn't by far the worse part of ActiveRecord. Also, even though this article doesn't make activeRecord look good, and I'm not trying to diss it. It's a decent ORM that does a great job in most cases.</p>

<p>Let's get started by the benchmarks number to give us an idea of the damage (using Ruby 1.9.3 p125):</p>

<p> </p>

<pre><code>                                                             | Class | Hash  | AR 3.2.1 | AR no protection | Datamapper | Sequel |
--------------------------------------------------------------------------------------------------------------------------------------
.new() x100000                                               | 0.037 | 0.049 | 1.557    | 1.536            | 0.027      | 0.209  |
.new({:id=&gt;1, :title=&gt;"Foo", :text=&gt;"Bar"}) x100000          | 0.327 | 0.038 | 6.784    | 5.972            | 4.226      | 1.986  |
</code></pre>

<p> </p>

<p>You can see that I am comparing the allocation of a Class instance, a Hash and some ORM models. The benchmark suite tests the allocation of an empty object and one with passed attributes. The benchmark in question is available <a href="https://github.com/mattetti/benchmarks/blob/master/init_objects.rb">here</a>.</p>

<p>As you can see there seems to be a huge performance difference between allocating a basic class and an ORM class. Instantiating an ActiveRecord class is 20x slower than instantiating a normal class, while ActiveRecord offers some extra features, why is it so much slower, especially at initialization time?</p>

<p>The best way to figure it out is to profile the initialization. For that, I used <a href="https://github.com/tmm1/perftools.rb">perftools.rb</a> and I generated a graph of the call stack.</p>

<p>Here is what Ruby does (and spends its time) when you initialize a new Model instance (click to download the PDF version):</p>

<p> </p>

<p><a href="http://github.com/mattetti/benchmarks/blob/master/ar_init_profile.pdf?raw=true"><img src="http://merbist.com/wp-content/uploads/2012/02/AR-model-instantation-by-Matt-Aimonetti.jpg" alt="Profiler diagram of AR model instantiation by Matt Aimonetti" /></a></p>

<p> </p>

<p>This is quite a scary graph but it shows nicely the features you are getting and their cost associated. For instance, the option of having the before and after initialization callback cost you 14% of your CPU time per instantiation, even though you probably almost never use these callbacks. I'm reading that by interpreting the node called ActiveSupport::Callback#run_callbacks, 3rd level from the top. So 14.1% of the CPU time is spent trying to run callbacks. As a quick note, note that 90.1% of the CPU time is spent initializing objects, the rest is spent in the loop and in the garbage collection (because the profiler runs many loops). You can then follow the code and see how the code works, creating a dynamic class callback method on the fly (the one with the long name) and then recreating the name of this callback to call it each time the object is allocated. It sounds like that's a good place for some micro optimizations which could yield up to 14% performance increase in some cases.</p>

<p>Another major part of the CPU time is spent in ActiveModel's sanitization. This is the piece of code that allows you to block some model attributes to be mass assigned. This is useful when you don't want to sanitize your incoming params but want to create or update a model instance by using all the passed user params. To avoid malicious users to modify some specific params that might be in your model but not in your form, you can protect these attributes. A good example would be an admin flag on a User object. That said, if you manually initialize an instance, you don't need this extra protection, that's why in the benchmark above, I tested and without the protection. As you can see, it makes quite a big difference. The profiler graph of the same initialization without the mass assignment protection logically ends up looking quite different:</p>

<p> </p>

<p><a href="https://github.com/mattetti/benchmarks/blob/master/ar_init_no_protection.pdf?raw=true">
</a><a href="https://github.com/mattetti/benchmarks/blob/master/ar_init_no_protection.pdf?raw=true"><img src="http://merbist.com/wp-content/uploads/2012/02/AR-model-instantiation-without-mass-assignment-by-Matt-Aimonetti.jpg" alt="Matt Aimonetti shows the stack trace generated by the instantiation of an Active Record model" /></a></p>

<p> </p>

<p><strong>Update:</strong> My colleague <a href="https://twitter.com/#!/glv">Glenn Vanderburg</a> pointed out that some people might assuming that the shown code path is called for each record loaded from the database. This isn't correct, the graph represents instances allocated by calling #new. See the addition at the bottom of the post for more details about what's going on when you fetch data from the DB.</p>

<p>I then decided to look at the graphs for the two other popular Ruby ORMs:</p>

<p><a href="http://datamapper.org/">Datamapper</a></p>

<p><a href="https://github.com/mattetti/benchmarks/blob/master/dm_init_profile.pdf?raw=true"><img src="http://img.skitch.com/20120223-txs4wa7b5rdpg45aj6354xg1wt.jpg" alt="" /></a></p>

<p> </p>

<p>and <a href="http://sequel.rubyforge.org/">Sequel</a></p>

<p><a href="https://github.com/mattetti/benchmarks/blob/master/sequel_init_profile.pdf?raw=true"><img src="http://img.skitch.com/20120223-p2jx6ypk35ucsgtx7p1tcabpes.jpg" alt="" /></a></p>

<p> </p>

<p> </p>

<p>While I didn't give you much insight in ORM code, I hope that this post will motivate you to sometimes take a look under the cover and profile your code to see what's going on and why it might be slow. <strong>Never assume, always measure</strong>. Tools such as perftools are a great way to get a visual feedback and get a better understanding of how the Ruby interpreter is handling your code.</p>

<h2>UPDATE:</h2>

<p>I heard you liked graphs so I added some more, here is what's going on when you do Model.first:</p>

<p><a href="https://github.com/mattetti/benchmarks/blob/master/ar_first_profile.pdf?raw=true"><img src="http://img.skitch.com/20120224-f23s8xctghi8mj6ax3cdw9aq25.jpg" alt="" /></a></p>

<p> </p>

<p>Model.all</p>

<p><a href="https://github.com/mattetti/benchmarks/blob/master/ar_all_profile.pdf?raw=true"><img src="https://img.skitch.com/20120224-q29q4n7bj3i96erk1enxdqxb5e.jpg" alt="" /></a></p>

<p> </p>

<p>And finally this is the code graph for a call to Model.instantiate which is called after a record was retrieved from the database to convert into an Object. (You can see the #instantiate call referenced in the graph above).</p>

<p> </p>

<p><a href="https://github.com/mattetti/benchmarks/blob/master/ar_instantiate_profile.pdf?raw=true"><img src="http://img.skitch.com/20120224-8scmun9n1c9ufdnxa8rq2961bq.jpg" alt="" /></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Books to read in 2012 - recommended to me by Twitter]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/12/30/books-to-read-in-2012-recommended-to-me-by-twitter/"/>
    <updated>2011-12-30T15:28:13-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/12/30/books-to-read-in-2012-recommended-to-me-by-twitter</id>
    <content type="html"><![CDATA[<p>Today, I asked on Twitter what non-technical books I should read in 2012.</p>

<p>I was nicely surprised to see so many of my followers send recommendations. Here is a list of 25 books that like-minded people suggested I read. Hopefully you will find a book or two to read too. Feel free to send more recommendations via the comments.</p>

<p> </p>

<p><a href="http://www.amazon.com/gp/product/0307593312/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0307593312"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0307593312&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0307593312" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0307593312/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0307593312">1Q84 by Haruki Murakami</a></p>

<p>suggested by <a href="https://twitter.com/#!/mrb_bk">@mrb_bk</a> and <a href="https://twitter.com/#!/chadfowler">@chadfowler</a></p>

<p><a href="http://www.amazon.com/gp/product/0385240899/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0385240899"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0385240899&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0385240899" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0385240899/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0385240899">The Floating Opera and The End of the Road by John Barth</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0385240899" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/chadfowler">@chadfowler</a></p>

<p><a href="http://www.amazon.com/gp/product/0613663616/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0613663616"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0613663616&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0613663616" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0613663616/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0613663616">Into Thin Air by Jon Krakauer</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0613663616" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/bradly">@bradly</a></p>

<p><a href="http://www.amazon.com/gp/product/0375714367/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0375714367"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0375714367&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0375714367" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0375714367/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0375714367">Cutting for Stone by Abraham Verghese</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0375714367" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/bradly">@bradly</a></p>

<p><a href="http://www.amazon.com/gp/product/0452011876/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0452011876"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0452011876&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0452011876" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0452011876/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0452011876">Atlas Shrugged by Ayn Rand</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0452011876" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/bradly">@bradly</a></p>

<p><a href="http://www.amazon.com/gp/product/0307474720/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0307474720"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0307474720&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0307474720" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0307474720/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0307474720">Cien años de soledad by Gabriel Garcia Marquez</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0307474720" alt="" /> (es)</p>

<p>suggested by <a href="https://twitter.com/#!/romanandreg">@romanandreg</a> &amp; <a href="https://twitter.com/#!/jrfernandez">@jrfernandez</a> &amp; <a href="https://twitter.com/#!/edgarschmidt">@edgarschmidt</a></p>

<p><a href="http://www.amazon.com/gp/product/0060883286/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0060883286"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0060883286&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0060883286" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0060883286/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0060883286">One Hundred Years of Solitude by Gabriel García Marquez</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0060883286" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/romanandreg">@romanandreg</a> &amp; <a href="https://twitter.com/#!/jrfernandez">@jrfernandez</a> &amp; <a href="https://twitter.com/#!/edgarschmidt">@edgarschmidt</a></p>

<p><a href="http://www.amazon.com/gp/product/0553348981/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0553348981"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0553348981&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0553348981" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0553348981/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0553348981">Jitterbug Perfume by Tom Robbins</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0553348981" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/supaspoida">@supaspoida</a></p>

<p><a href="http://www.amazon.com/gp/product/0062041266/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0062041266"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0062041266&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0062041266" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0062041266/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0062041266">The Sisters Brothers by Patrick deWitt</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0062041266" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/dennismajor1">@dennismajor1</a></p>

<p><a href="http://www.amazon.com/gp/product/0312278497/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0312278497"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0312278497&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0312278497" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0312278497/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0312278497">The Glass Bead Game by Hermann Hesse</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0312278497" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/dj2sincl">@dj2sincl</a></p>

<p><a href="http://www.amazon.com/gp/product/0679775439/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0679775439"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0679775439&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0679775439" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0679775439/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0679775439">The Wind-Up Bird Chronicle by Haruki Murakami</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0679775439" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/chadfowler">@chadfowler</a></p>

<p><a href="http://www.amazon.com/gp/product/0983873100/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0983873100"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0983873100&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0983873100" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0983873100/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0983873100">Mindfire by Scott Berkun</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0983873100" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/lucasdicioccio">@lucasdicioccio</a></p>

<p><a href="http://www.amazon.com/gp/product/2226052577/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=2226052577"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=2226052577&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=2226052577" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/2226052577/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=2226052577">Les Fourmis by Bernard Werber</a> (fr)</p>

<p>suggested by <a href="https://twitter.com/#!/twitty_tim">@twitty_tim</a></p>

<p><a href="http://www.amazon.com/gp/product/0375725849/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0375725849"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0375725849&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0375725849" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0375725849/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0375725849">Perfume: The Story of a Murderer by Patrick Suskind</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0375725849" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/twitty_tim">@twitty_tim</a></p>

<p><a href="http://www.amazon.com/gp/product/1613820259/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1613820259"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=1613820259&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=1613820259" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/1613820259/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1613820259">Les Miserables by Victor Hugo</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=1613820259" alt="" /> (en, free ebook)</p>

<p>suggested by <a href="https://twitter.com/#!/tutec">@tutec</a></p>

<p><a href="http://www.amazon.com/gp/product/0307292134/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0307292134"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0307292134&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0307292134" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0307292134/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0307292134">Song Of Ice and Fire by George R.R. Martin</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0307292134" alt="" /> (Game of Thrones saga)</p>

<p>suggested by <a href="https://twitter.com/#!/eeppa">@eeppa</a> &amp; <a href="http://twitter.com/jarin">@jarin</a></p>

<p><a href="http://www.amazon.com/gp/product/0765329468/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0765329468"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0765329468&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0765329468" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0765329468/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0765329468">Clockwork Century by Cherie Priest</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0765329468" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/eeppa">@eeppa</a></p>

<p><a href="http://www.amazon.com/gp/product/1590201183/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1590201183"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=1590201183&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=1590201183" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/1590201183/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1590201183">The Darkness that Comes Before by R. Scott Bakker</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=1590201183" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/eeppa">@eeppa</a></p>

<p><a href="http://www.amazon.com/gp/product/B003GAN3VE/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B003GAN3VE"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=B003GAN3VE&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=B003GAN3VE" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/B003GAN3VE/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B003GAN3VE">Drood by Dan Simmons</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=B003GAN3VE" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/eeppa">@eeppa</a></p>

<p><a href="http://www.amazon.com/gp/product/0316068225/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0316068225"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0316068225&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0316068225" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0316068225/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0316068225">This Is Water by David Foster Wallace</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0316068225" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/atduskgreg">@atduskgreg</a></p>

<p><a href="http://www.amazon.com/gp/product/B005DI71QA/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B005DI71QA"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=B005DI71QA&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=B005DI71QA" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/B005DI71QA/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B005DI71QA">Anathem by Neal Stephenson</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=B005DI71QA" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/jarin">@jarin</a></p>

<p><a href="http://www.amazon.com/gp/product/0812550706/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0812550706"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0812550706&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0812550706" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0812550706/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0812550706">Ender's Game by Orson Scott Card</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0812550706" alt="" /> (entire saga)</p>

<p>suggested by <a href="https://twitter.com/#!/jarin">@jarin</a> &amp; <a href="https://twitter.com/#!/edgarschmidt">@edgarschmidt</a></p>

<p><a href="http://www.amazon.com/gp/product/344245302X/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=344245302X"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=344245302X&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=344245302X" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/344245302X/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=344245302X">Snow Crash by Neal Stephenson</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=344245302X" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/jarin">@jarin</a></p>

<p><a href="http://www.amazon.com/gp/product/1422171647/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1422171647"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=1422171647&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=1422171647" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/1422171647/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1422171647">Fixing the Game by Roger L. Martin</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=1422171647" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/jarkko">@jarkko</a></p>

<p><a href="http://www.amazon.com/gp/product/0307387895/ref=as_li_ss_il?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0307387895"><img src="http://ws.assoc-amazon.com/widgets/q?_encoding=UTF8&amp;Format=_SL110_&amp;ASIN=0307387895&amp;MarketPlace=US&amp;ID=AsinImage&amp;WS=1&amp;tag=merbist-20&amp;ServiceVersion=20070822" alt="" /></a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0307387895" alt="" /></p>

<p><a href="http://www.amazon.com/gp/product/0307387895/ref=as_li_ss_tl?ie=UTF8&amp;tag=merbist-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0307387895">The Road by Cormac McCarthy</a><img src="http://www.assoc-amazon.com/e/ir?t=merbist-20&amp;l=as2&amp;o=1&amp;a=0307387895" alt="" /></p>

<p>suggested by <a href="https://twitter.com/#!/mrreynolds">@mrreynolds</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Developing a Curriculum]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/12/21/developing-a-curriculum/"/>
    <updated>2011-12-21T06:57:27-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/12/21/developing-a-curriculum</id>
    <content type="html"><![CDATA[<p>Recently I asked a friend of mine to give me pointers on how to develop a curriculum (he used to teach an education PHD program), after discussing his response on Twitter, people asked me to put it somewhere, so here it is:</p>

<p>Process to develop a curriculum:</p>

<p><strong>Purpose</strong>. <em>Know why you're doing what you're doing.</em></p>

<ul>
<li>You know how to do this.</li>
</ul>


<p><strong>Product</strong>. <em>Start with the end in mind.</em></p>

<ul>
<li><p>What does the student look like when they walk out the door at the end of the training.</p></li>
<li><p>Usually, we break these down into <strong>Knowledge</strong>, <strong>Skills</strong>, or <strong>Attitudes</strong>.</p></li>
<li><p>Sometimes it's helpful to see a photograph or drawing of a someone who finished the program and just talk about what they can do that makes them successful.</p></li>
<li><p>This "product" should be connected and help you accomplish your mission</p></li>
</ul>


<p><strong>Practices</strong>. <em>Then ask yourself, "How do people become like this?"</em></p>

<ul>
<li><p>If you can break down your Product into 3-5 bit-sized chunks, then see how people learn each one of those skills, gain each one of those knowledge points, and how to they gain the attitudes you want them to have.</p></li>
<li><p>This one is much easier the more experience you have in seeing people develop the "Product."</p></li>
<li><p>This is also easier to determine when you understand <a href="http://en.wikipedia.org/wiki/Learning_theory_(education">Learning Theory</a>).</p></li>
<li><p>The results from this section will result in a list of:</p>

<ul>
<li><p>       Activities or experiences</p></li>
<li><p>       Resources. What books, website, teachers, software, etc. will help them learn more effectively and efficiently</p></li>
<li><p>       Assessments. How you would know if the activity was helpful?</p></li>
</ul>
</li>
</ul>


<p><strong>Plans</strong>. <em>Make your plans based on the practices you've determined you've needed.</em></p>

<p> </p>

<p>On a related topic, Chad Fowler posted an interesting <a href="http://chadfowler.com/2011/12/21/re-thinking-software-development-education">blog post about what LivingSocial is doing to change the software development education</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Data safety and GIL removal]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/10/18/data-safety-and-gil-removal/"/>
    <updated>2011-10-18T15:19:17-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/10/18/data-safety-and-gil-removal</id>
    <content type="html"><![CDATA[<p>After my recent <a href="http://rubyconf11.merbist.com">RubyConf talk</a> and <a href="http://merbist.com/2011/10/03/about-concurrency-and-the-gil/">follow up post addressing the Ruby &amp; Python's Global Interpreter Lock</a> (aka GVL/Global VM Lock). a lot of people asked me to explain what I meant by "data safety". While my point isn't to defend one approach or the other, I spent a lot of time explaining why C Ruby and C Python use a GIL and where it matters and where it matters less. As a reminder and as mentioned by Matz himself, the main reason why C Ruby still has a GIL is data safety. But if this point isn't clear to you, you might be missing the main argument supporting the use of a GIL.</p>

<p>Showing obvious concrete examples of data corruption due to unsafe threaded code isn't actually as easy at it sounds. First of all, even with a GIL, developers can write unsafe threaded code. So we need to focus only on the safety problems raised by removing the GIL. To demonstrate what I mean, I will try to create some race conditions and show you the unexpected results you might get. Again, before you go crazy on the comments, remember that threaded code is indeterministic and the code below might potentially work on your machine and that's exactly why it is hard to demonstrate. Race conditions depend on many things, but in this case I will focus on race conditions affecting basic data structures since it might be the most surprising.</p>

<h2>Example:</h2>

<p><code>ruby
@array, threads = [], []
4.times do
  threads &lt;&lt; Thread.new { (1..100_000).each {|n| @array &lt;&lt; n} }
end
threads.each{|t| t.join }
puts @array.size
</code></p>

<p>In the above example, I'm creating an instance variable of Array type and I start 4 threads. Each of these threads adds 100,000 items to the array. We then wait for all the threads to be done and check the size of the array.</p>

<p>If you run this code in C Ruby the end result will be as expected:</p>

<pre><code>400000
</code></pre>

<p>Now if you switch to JRuby you might be surprised by the output. If you are lucky you will see the following:</p>

<pre><code>ConcurrencyError: Detected invalid array contents due to unsynchronized modifications with concurrent users
        &lt;&lt; at org/jruby/RubyArray.java:1147
  __file__ at demo.rb:3
      each at org/jruby/RubyRange.java:407
  __file__ at demo.rb:3
      call at org/jruby/RubyProc.java:274
      call at org/jruby/RubyProc.java:233
</code></pre>

<p>This is actually a good thing. JRuby detects that you are unsafely modifying an instance variable across threads and that data corruption will occur. However, the exception doesn't always get raised and you will potentially see results such as:</p>

<pre><code>335467
342397
341080
</code></pre>

<p>This is a sign that the data was corrupted but that JRuby didn't catch the unsynchronized modification. On the other hand MacRuby and Rubinius 2 (dev) won't raise any exceptions and will just corrupt the data, outputting something like:</p>

<pre><code>294278
285755
280704
279865
</code></pre>

<p>In other words, if not manually synchronized, shared data can easily be corrupted. You might have two threads modifying the value of the same variable and one of the two threads will step on top of the other leaving you with a race condition. You only need 2 threads accessing the same instance variable at the same time to get a race condition. My example uses more threads and more mutations to make the problem more obvious. Note that TDD wouldn't catch such an issue and even extensive testing will provide very little guarantee that your code is thread safe.</p>

<p> </p>

<h2>So what? Thread safety isn't a new problem.</h2>

<p>That's absolutely correct, ask any decent Java developer out there, he/she will tell how locks are used to "easily" synchronize objects to make your code thread safe. They might also mention the deadlocks and other issues related to that, but that's a different story. One might also argue that when you write web apps, there is very little shared data and the chances of corrupting data across concurrent requests is very small since most of the data is kept in a shared data store outside of the process.</p>

<p>All these arguments are absolutely valid, the challenge is that you have a large community and a large amount of code out there that expects a certain behavior. And removing the GIL does change this behavior. It might not be a big deal for you because you know how to deal with thread safety, but it might be a big deal for others and C Ruby is by far the most used Ruby implementation. It's basically like saying that automatic cars shouldn't be made and sold, and everybody has to switch to stick shifts. They have better gas mileage, I personally enjoy driving then and they are cheaper to build. Removing the GIL is a bit like that. There is a cost associated with this decision and while this cost isn't insane, the people in charge prefer to not pay it.</p>

<p> </p>

<h2>Screw that, I'll switch to Node.js</h2>

<p>I heard a lot of people telling me they were looking into using Node.js because it has a better design and no GIL. While I like Node.js and if I were to implement a chat room or an app keeping connections for a long time, I would certainly compare it closely to EventMachine, I also think that this argument related to the GIL is absurd. First, you have other Ruby implementations which don't have a GIL and are really stable (i.e: JRuby) but then Node basically works the same as Ruby with a GIL. Yes, Node is evented and single threaded but when you think about it, it behaves the same as Ruby 1.9 with its GIL. Many requests come in and they are handled one after the other and because IO requests are non-blocking, multiple requests can be processed concurrently but not in parallel. Well folks, that's exactly how C Ruby works too, and unlike popular believe, most if not all the popular libraries making IO requests are non blocking (when using 1.9). So, next time you try to justify you wanting to toy with Node, please don't use the GIL argument.</p>

<p> </p>

<h2>What should I do?</h2>

<p>As always, evaluate your needs and see what makes sense for your project. Start by making sure you are using Ruby 1.9 and your code makes good use of threading. Then look at your app and how it behaves, is it CPU-bound or IO-bound. Most web apps out there are IO-bound (waiting for the DB, redis or API calls), and when doing an IO call, Ruby's GIL is released allowing another thread to do its work. In that case, not having a GIL in your Ruby implementation won't help you. However, if your app is CPU-bound, then switching to JRuby or Rubinius might be beneficial. However, don't assume anything until you proved it and remember that making such a change will more than likely require some architectural redesign, especially if using JRuby.  But, hey, it might totally be worth it as many proved it in the past.</p>

<p> </p>

<p>I hope I was able to clarify things a bit further. If you wish to dig further, I would highly recommend you read the many discussions the Python community had in the last few years.</p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[About management]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/10/11/about-management/"/>
    <updated>2011-10-11T22:53:40-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/10/11/about-management</id>
    <content type="html"><![CDATA[<p>I decided to save myself a session to the shrink and instead just write down my reflection on management. Who knows, some of you might help me and/or challenge my thought process.</p>

<p>I recently read a great management book called the <a href="https://www.amazon.com/dp/B000UCUX0K/ref=as_li_ss_til?tag=merbist-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=B000UCUX0K&amp;adid=0BP6N5GHZD0EW2N7QVZR&amp;">five dysfunctions of a team by Patrick Lencioni</a> . Instead of telling you what to do, the author highlights behavior patterns that are related to each other and when aggregated result in dysfunctional teams. I really liked the book because instead of a being a cookbook/playbook, this is more a fail book, in other words, it illustrates what you don't want to do and explains why. It highlights very well the relation between various behaviors and nicely illustrates why teams of brilliant people can fail. The <a href="https://www.amazon.com/dp/B000UCUX0K/ref=as_li_ss_til?tag=merbist-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=B000UCUX0K&amp;adid=0BP6N5GHZD0EW2N7QVZR&amp;">Kindle version is at less than $5, go get it</a> and read it on your iPhone/iPad/computer/browser…</p>

<p>So this book somewhat changed my perception of management and leadership. Interesting enough, at Sony, my previous employer, they make a distinction between management and leadership. While they hope managers can be leaders, they don't require them to be and to be honest very few are. I'm not sure that's a good or a bad things, but I, for sure, was under different expectations. Finally, I spent a large amount of my life on the internet working on/with projects where meritocracy, respect and honor were key. The "ranking" is purely based on what your peers think of you and not based on your age/sex/origin/diploma/bank account. I do realize that this model has many pros but also some pretty major cons. My only point is that it did affect my worldview. In my world, seniority, a killer  job title or a fancy suit won't buy you my automatic respect. On the other hand, job well done, great vision, honesty, over achievement will!</p>

<p>Taking these few trains of thoughts in consideration, I started thinking about my own expectations for a good manager/leader. I figured that if I were able to do that, I could possibly be able to define a work environment where I could thrive and maybe one day become a good "manager/leader".</p>

<p>I've always questioned my ability to be a good leader. While most of the time, I have an opinion and can easily decide what I think should be done, I have a hard time relating to people who can't see the "big picture". While I usually can get decent results, I'm aware that it can unfortunately sometime be at the cost of a few bruised egos. I also know I have high expectations for myself and for others and I have a hard time understanding how some people can be ok with the "status-quo". I'm a perfectionist who is only happy when he outperforms his previous achievement. I was raised to challenge and always push myself further, focusing on concrete end-results and achieved goals. And to be honest, that's what I enjoy. But I also know for a fact, that many people are not like that and I can't blame them for looking at things from a different angle and not sharing the same motivations. Furthermore, I know that most people actually don't have the same driven temperament and that's why I've questioned my abilities to lead others.</p>

<p>However, different temperaments can work together as long as there is respect. And by respect, I mean that everyone feel that they were being heard and know that their input was considered and addressed even though the outcome might not be as hoped for. But for respect to happen, you first need trust. And when people trust each other, Lencioni explains that <em>"people don't hold back one with another. They are unafraid to air their dirty laundry. They admit their mistakes, their weaknesses, and their concerns without fear of reprisal"</em>. I think that as simple as it seems, it is the key to a successful team. A good leader should be able to create such an atmosphere where people can trust each other. In fact, I think that if a manger/leader/executive can manage to build trust as defined earlier, his technical skills or lack of vision don't matter as much. He/she will be able to rely on people he trusts to help him make the right decisions. Of course, there is much more than to be a good leader, but I think that with this base, great things can be built, and without it, a much greater effort is required to get some good results.</p>

<p>Based on my findings, I think that I need to work on my communication so others don't feel that they have to hold back and make sure everyone feels that their opinions were considered and addressed. To do that a key element is to admit my mistakes and weaknesses and asking others to help me improve. That's it, sorry for the boring, not technical post. I promise the next one will have at least a code sample.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[About concurrency and the GIL]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/10/03/about-concurrency-and-the-gil/"/>
    <updated>2011-10-03T21:23:54-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/10/03/about-concurrency-and-the-gil</id>
    <content type="html"><![CDATA[<p>During RubyConf 2011, concurrency was a really hot topic. This is not a new issue, and the JRuby team has been talking about true concurrency for quite a while . The Global Interpreter Lock has also been in a subject a<a href="http://wiki.python.org/moin/GlobalInterpreterLock"> lot of discussions in the Python community</a> and it's not surprising that the Ruby community experiences the same debates since the evolution of their implementations are somewhat similar. (There might also be some tension between <a href="http://engineyard.com">EngineYard</a> hiring the JRuby and Rubinius teams and <a href="http://heroku.com">Heroku</a> which <a href="http://blog.heroku.com/archives/2011/7/12/matz_joins_heroku/">recently hired Matz</a> (Ruby's creator) and <a href="https://github.com/nobu">Nobu</a>, the #1 C Ruby contributor)</p>

<p>The GIL was probably even more of a hot topic now that <a href="http://rubini.us/">Rubinius</a> is about the join <a href="http://jruby.org">JRuby</a> and <a href="http://macruby.org">MacRuby</a> in the realm of GIL-less Ruby implementations.</p>

<p>During my RubyConf talk (<a href="http://rubyconf11.merbist.com/">slides here</a>), I tried to explain how C Ruby works and why some decisions like having a GIL were made and why the Ruby core team isn't planning on removing this GIL anytime soon. The GIL is something a lot of Rubyists love to hate, but a lot of people don't seem to question why it's here and why Matz doesn't want to remove it. Defending the C Ruby decision isn't quite easy for me since I spend my free time working on an alternative Ruby implementation which doesn't use a GIL (MacRuby). However, I think it's important that people understand why the MRI team (C Ruby team) and some Pythonistas feels so strongly about the GIL.</p>

<p><strong>What is the GIL?</strong></p>

<p>Here is a quote from the <a href="http://wiki.python.org/moin/GlobalInterpreterLock">Python wiki</a>:</p>

<blockquote><p>In CPython, the <strong>global interpreter lock</strong>, or <strong>GIL</strong>, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython's memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.) [...] The GIL is controversial because it prevents multithreaded CPython programs from taking full advantage of multiprocessor systems in certain situations. Note that potentially blocking or long-running operations, such as I/O, image processing, and <a href="http://wiki.python.org/moin/NumPy">NumPy</a> number crunching, happen <em>outside</em> the GIL. Therefore it is only in multithreaded programs that spend a lot of time inside the GIL, interpreting CPython bytecode, that the GIL becomes a bottleneck.</p></blockquote>

<p>The same basically applies to C Ruby. To illustrate the quote above, here is a diagram representing two threads being executed by C Ruby:</p>

<p><a href="http://rubyconf11.merbist.com/#44"><img src="http://rubyconf11.merbist.com/images/thread_scheduling.023.jpg" alt="Fair thread scheduling in Ruby by Matt Aimonetti" /></a></p>

<p>Such a scheduling isn't a problem at all when you only have 1 cpu, since a cpu can only execute a piece of code at a time and context switching happens all the time to allow the machine to run multiple processes/threads in parallel. The problem is when you have more than 1 CPU because in that case, if you were to only run 1 Ruby process, then you would most of the time only use 1 cpu at a time. If you are running on a 8 cpu box, that's not cool at all! A lot of people stop at this explanation and imagine that their server can only handle one request at a time and they they rush to sign Greenpeace petitions asking Matz to make Ruby greener by optimizing Ruby and saving CPU cycles. Well, the reality is slightly different, I'll get back to that in a minute. Before I explain "ways to achieve true concurrency with CRuby, let me explain why C Ruby uses a GIL and why each implementation has to make an important choice and in this case both CPython and C Ruby chose to keep their GIL.</p>

<p> </p>

<h3>Why a GIL in the first place?</h3>

<ul>
<li><p>It makes developer's lives easier (it's harder to corrupt data)</p></li>
<li><p>It avoids race conditions within C extensions</p></li>
<li><p>It makes C extensions development easier (no write barriers..)</p></li>
<li><p>Most of the C libraries which are wrapped are not thread safe</p></li>
<li><p>Parts of Ruby's implementation aren't threadsafe (Hash for instance)</p></li>
</ul>


<p>As you can see the arguments can be organized in two main categories: data safety and C extensions/implementation. An implementation which doesn't rely too much on C extensions (because they run a bit slow, or because code written in a different language is preferred) is only faced with one argument: data safety.</p>

<p> </p>

<h3></h3>

<h3>Should C Ruby remove its GIL?</h3>

<ul>
<li><p>No: it potentially makes Ruby code unsafe(r)</p></li>
<li><p>No: it would break existing C extensions</p></li>
<li><p>No: it would make writing C extensions harder</p></li>
<li><p>No: it's a lot of work to change make C Ruby threadsafe</p></li>
<li><p>No: Ruby is fast enough in most cases</p></li>
<li><p>No: Memory optimization and GC is more important to tackle first</p></li>
<li><p>No: C Ruby code would run slower</p></li>
<li><p>Yes: we really need better/real concurrency</p></li>
<li><p>Yes: <a href="https://plus.google.com/107994348420168435683/posts/993U42yVbfk">Rubber boots analogy (Gustavo Niemeyer)</a></p></li>
</ul>


<p>Don't count the amount of pros/cons to jump to the conclusion that removing the GIL is a bad idea. A lot of the arguments for removing the GIL are related. At the end of the day it boils down to data safety. During the Q&amp;A section of my RubyConf talk, Matz came up on stage and said data safety was the main reason why C Ruby still has a GIL. Again, this is a topic which was discussed at length in the Python community and I'd encourage you to read arguments from the <a href="http://www.jython.org/">Jython</a> (the equivalent of JRuby for Python) developers, <a href="http://codespeak.net/pypy/dist/pypy/doc/faq.html#does-pypy-have-a-gil-why">the PyPy</a> (the equivalent of Rubinius in the Python community) and CPython developers. (a good collection of arguments are actually available in the comments related to the <a href="https://plus.google.com/107994348420168435683/posts/993U42yVbfk">rubber boots post mentioned earlier</a>)</p>

<p> </p>

<h3>How can true concurrency be achieved using CRuby?</h3>

<ul>
<li><p>Run multiple processes (which you probably do if you use Thin, Unicorn or Passenger)</p></li>
<li><p>Use event-driven programming with a process per CPU</p></li>
<li><p>MultiVMs in a process. Koichi presented his plan to run multiple VMs within a process.  Each VM would have its own GIL and inter VM communication would be faster than inter process. This approach would solve most of the concurrency issues but at the cost of memory.</p></li>
</ul>


<p>Note:  forking a process only saves memory when using REE since it implements a GC patch that makes the forking process Copy on Write friendly. The Ruby core team worked on a patch for Ruby 1.9 to achieve the same result. <a href="http://twitter.com/#!/nari_en">Nari</a> &amp; <a href="http://twitter.com/#!/yukihiro_matz">Matz</a> are currently working on improving the implementation to make sure overall performance isn't affected.</p>

<p>Finally, when developing web applications, each thread spend quite a lot of time in IOs which, as mentioned above won't block the thread scheduler. So if you receive two quasi-concurrent requests you might not even be affected by the GIL as illustrated in <a href="http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/">this diagram from Yehuda Katz</a>:</p>

<p><img src="http://yehudakatz.com/wp-content/uploads/2010/08/Untitled.002.png" alt="" /></p>

<p>This is a simplified diagram but you can see that a good chunk of the request life cycle in a Ruby app doesn't require the Ruby thread to be active (CPU Idle blocks) and therefore these 2 requests would be processed almost concurrently.</p>

<p>To boil it down to something simplified, when it comes to the GIL, an implementor has to chose between data safety and memory usage. But it is important to note that context switching between threads is faster than context switching between processes and data safety can and is often achieved in environments without a GIL, but it requires more knowledge and work on the developer side.</p>

<p> </p>

<h3>Conclusion</h3>

<p>The decision to keep or remove the GIL is a bit less simple that it is often described. I respect Matz' decision to keep the GIL even though, I would personally prefer to push the data safety responsibility to the developers. However, I do know that many Ruby developers would end up shooting themselves in the foot and I understand that Matz prefers to avoid that and work on other ways to achieve true concurrency without removing the GIL. What is great with our ecosystem is that we have some diversity, and if you think that a GIL less model is what you need, we have some great alternative implementations that will let you make this choice. I hope that this article will help some Ruby developers understand and appreciate C Ruby's decision and what this decision means to them on a daily basis.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to - cross domain ajax to a Ruby app]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/09/14/how-to-cross-domain-ajax-in-a-ruby-app/"/>
    <updated>2011-09-14T16:11:41-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/09/14/how-to-cross-domain-ajax-in-a-ruby-app</id>
    <content type="html"><![CDATA[<p>In some cases, you might have a bunch of apps running on different domains/subdomains and/or ports and you would like to make ajax requests between these services. The problem is that browsers wouldn't let you make such requests because of the Same Origin Policy which only allowed them to make request to resources within the same domain.</p>

<p>However, most browsers (IE 8+, Firefox 3.5+, Safari 4+, Chrome) implement a simple way to allow cross domain requests as defined in this <a href="http://www.w3.org/TR/cors/">w3C document</a>.</p>

<p>Of course, if your users have an old version of their browser, you  might have to look into jsonp or something else such as cheating by using iframes &amp; setting document.domain. Let's pretend for a minute that 100% of your users are on Chrome. The only thing you need to do is set a response header listing the accepted domains or "*" for all. A simple Rack middleware to do that would look like that.</p>

<p> </p>

<pre><code>class XOriginEnabler
  ORIGIN_HEADER = "Access-Control-Allow-Origin"

  def initialize(app, accepted_domain="*")
    @app = app
    @accepted_domain = accepted_domain
  end

  def call(env)
    status, header, body = @app.call(env)
    header[ORIGIN_HEADER] = @accepted_domain
    [status, header, body]
  end
end
</code></pre>

<p>And to use the middleware you would need to set it for use:</p>

<pre><code>use XOriginEnabler
</code></pre>

<p>To enable all requests from whatever origin, or pass the white listed domain(s) as shown below.</p>

<pre><code>use XOriginEnabler, "demo.mysite.com demo.mysite.fr demo.techcrunch.com"
</code></pre>

<p>For a full featured middleware, see <a href="https://github.com/cyu/rack-cors">this project</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby optimization example and explanation]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/09/05/ruby-optimization-example-and-explaination/"/>
    <updated>2011-09-05T14:58:21-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/09/05/ruby-optimization-example-and-explaination</id>
    <content type="html"><![CDATA[<p>Recently I wrote a small DSL that allows the user to define some code that then gets executed later on and in different contexts. Imagine something like Sinatra where each route action is defined in a block and then executed in context of an incoming request.</p>

<p>The challenge is that blocks come with their context and you can't execute a block in the context of another one.</p>

<p>Here is a reduction of the challenge I was trying to solve:</p>

<pre><code>class SolutionZero
  def initialize(origin, &amp;block;)
    @origin = origin
    @block = block
  end

  def dispatch
    @block.call
  end
end

SolutionZero.new(42){ @origin + 1 }.dispatch
# undefined method `+' for nil:NilClass (NoMethodError)
</code></pre>

<p>The problem is that the block refers to the @origin instance variable which is not available in its context.
My first workaround was to use instance_eval:</p>

<pre><code>class SolutionOne
  def initialize(origin, &amp;block;)
    @origin = origin
    @block = block
  end

  def dispatch
    self.instance_eval &amp;@block
  end
end

SolutionOne.new(40){ @origin + 2}.dispatch
# 42
</code></pre>

<p>My workaround worked fine, since the block was evaluated in the context of the instance and therefore the @origin ivar is made available to block context. Technically, I was good to go, but I wasn't really pleased with this solution. First using instance_eval often an indication that you are trying to take a shortcut. Then having to convert my block stored as a block back into a proc every single dispatch makes me sad. Finally, I think that this code is probably not performing as well as it could, mainly due to unnecessary object allocations and code evaluation.
I did some benchmarks replacing <a href="https://github.com/ruby/ruby/blob/trunk/vm_eval.c#L1323">instance_eval</a> by <a href="https://github.com/ruby/ruby/blob/trunk/vm_eval.c#L1355">instance_exec</a> since looking at the C code, instance_exec should be slightly faster. Turns out, it is not so I probably missed something when reading the implementation code.</p>

<p>I wrote some more benchmarks and profiled a loop of 2 million dispatches (only the #disptach method call on the same object). The GC profiler report showed that the GC was invoked 287 times and each invocation was blocking the execution for about 0.15ms.
Using Ruby's <a href="http://ruby-doc.org/core/classes/ObjectSpace.html#M001526">ObjectSpace</a> and <a href="http://ruby-doc.org/core/classes/GC.html#M001373">disabling the GC</a> during the benchmark, I could see that each loop allocates an object of type T_NODE which is more than likely our @block ivar converted back into a block. This is quite a waste. Furthermore, having to evaluate our block in a different context every single call surely isn't good for performance.</p>

<p>So instead of doing the work at run time, why not doing it at load time? By that I mean that we can optimize the #dispatch method if we could "precompile" the method body instead of "proxying" the dispatch to an instance_eval call. Here is the code:</p>

<pre><code>class SolutionTwo
  def initialize(origin, &amp;block;)
    @origin = origin
    implementation(block)
  end

  private

  def implementation(block)
    mod = Module.new
    mod.send(:define_method, :dispatch, block)
    self.extend mod
  end
end

SolutionTwo.new(40){ @origin + 2}.dispatch
# 42
</code></pre>

<p>This optimization is based on the fact that the benchmark (and the real life usage) creates the instance once and then calls #dispatch many times. So by making the initialization of our instance a bit slower, we can drastically improve the performance of the method call. We also still need to execute our block in the right context. And finally, each instance might have a different way to dispatch since it is defined dynamically at initialization. To work around all these issues, we create a new module on which we define a new method called dispatch and the body of this method is the passed block. Then we simply our instance using our new module.</p>

<p>Now every time we call #dispatch, a real method is dispatched which is much faster than doing an eval and no objects are allocated. Running the profiler and the benchmarks script used earlier, we can confirm that the GC doesn't run a single time and that the optimized code runs 2X faster!</p>

<p> </p>

<p>Once again, it's yet another example showing that you <a href="http://merbist.com/2010/07/29/object-allocation-why-you-should-care/">should care about object allocation</a> when dealing with code in the critical path. It also shows how to work around the block bindings. Now, it doesn't mean that you have to obsess about object allocation and performance, even if my last implementation is 2X faster than the previous, we are only talking about a few microseconds per dispatch. That said microseconds do add up and creating too many objects will slow down even your faster code since the GC will stop-the-world as its cleaning up your memory. In real life, you probably don't have to worry too much about low level details like that, unless you are working on a framework or sharing your code with others. But at least you can learn and understand why one approach is faster than the other, it might not be useful to you right away, but if you take programming as a craft, it's good to understand how things work under the hood so you can make educated decisions.
 </p>

<h3>Update:</h3>

<p>@apeiros in the comments suggested a solution that works &amp; performs the same as my solution, but is much cleaner:</p>

<pre><code>class SolutionTwo
  def initialize(origin, &amp;block;)
    @origin = origin
    define_singleton_method(:dispatch, block) if block_given?
  end
end
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying a Rails 3.1 app - gotchas]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/08/30/deploying-a-rails-3-1-app-gotchas/"/>
    <updated>2011-08-30T17:20:34-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/08/30/deploying-a-rails-3-1-app-gotchas</id>
    <content type="html"><![CDATA[<p>Recently I had to build a new app as part of my research &amp; development job at <a href="http://livingsocial.com">LivingSocial</a>. My goal was to get the app up and running in just a few weeks, solid application architecture and graphic design included.
When you need to build an app quickly and you want it to have some solid foundations, Rails is quite useful.
I used Rails 3.1RCx so if we would to keep my app and push it to production, the engineering team wouldn't have to update it and the transition should be seamless. I also quite like <a href="http://jashkenas.github.com/coffee-script/">CoffeeScript</a> and the app being quite heavy on JavaScript, the choice was easy. Furthermore, my coworker <a href="http://codefluency.com/">Bruce Williams</a> is a fan of <a href="http://sass-lang.com/">SCSS</a> and he's writing a <a href="http://pragprog.com/">PragProg</a> book called "The Rails View" with other LivingSocialist: <a href="http://www.boboroshi.com/">John Athayde</a>. So you got the point, I'm using Rails3.1, but this post is about the challenges I faced when it was time to deploy and the solutions I found.</p>

<p>I'll skip the intro to Rails 3.1 and how to use the new asset pipeline, refer to the <a href="http://guides.rubyonrails.org/asset_pipeline.html">Rails guide</a> or one of the mainly posts referenced in t<a href="http://jasonrudolph.com/blog/2011/06/06/helpful-resources-for-upgrading-to-rails-3-1/">his post</a> (if I had properly read the <a href="http://guides.rubyonrails.org/asset_pipeline.html">guide</a>, it would have saved me some valuable time, trust me, read it carefuly).</p>

<p>At that point last night, I had my app working great locally, Bruce created some awesome scss code using mixins and nested rules, the HTML was clean and working great, my <a href="http://jashkenas.github.com/coffee-script/">CoffeeScript</a> was brewing nicely, all was great until I tried to deploy to our QA environment.</p>

<h3>JavaScript runtime dependency</h3>

<p>The first thing you will notice is that you need the proper JavaScript runtime so the asset pipeline works properly. Not a big deal, you'll find a lot of documentation about that. The problem is that you need to update your production environment or use depend on gem that will compile the required runtime (sounds dirty to me). So if you are deploying to many machines and you are using an image solution (EC2 AMI or other), you will need to update your image or spin new instances via updated chef/puppet recipes. In this case, the awesome team at LivingSocial had an image ready for me, so that wasn't a big deal, but still, you need to take that in consideration as you are planning to update.</p>

<p>So the asset pipeline optimizes your asset management by processing/compiling asset files for you and optimizing their delivery. Instead of serving static files directly via public/images or public/javascripts you know serve them via the asset pipeline which will take care of compiling your CoffeeScript, grouping and minifying your JS and preprocessing all sorts of format. It also optimizes the caching process by giving a unique filename to each file based on the file metadata and gziping files. This is great, but you really, really, really don't want to have your apps take care of that in production. Why wasting precious resources to serve assets when they can be prepared ahead of time. (by making Rails serve static assets, you are seriously reducing the throughput of  your app, please think of the children (or the dolphins/trees if you don't like children))</p>

<h3>Capistrano</h3>

<p>Rails obviously has a preprocessor available as a rake task and you should update your deployment recipe to use that new feature. Here is my Capistrano code:</p>

<pre><code>after 'deploy:update_code', 'deploy:compile_assets'
namespace :deploy do
  task :compile_assets do
    run "cd #{release_path}; RAILS_ENV=production rake assets:precompile"
  end
end
</code></pre>

<p>Well, my real code doesn't hardcode the RAILS_ENV constant value, it's in fact set in each env file, but I simplified it since most people only use 1 env outside of dev &amp; test.</p>

<p>What that will do is compile all the files and dump them in public/assets/. But the file I had called bubble.png now becomes bubble-27543c671a3ab45141ee0d3216085009.png which means that my app is totally broken because images use in Bruce SCSS don't load, my js files don't load and the app is totally broken. Now this is least fun part, that I wish I had known before. This is where you go back and change your code so it uses magic to get the right file names.</p>

<h3>Images</h3>

<p>Fixing images was actually quite simple, in all my views, I just had to make sure I was using the image_tag helper everywhere.</p>

<h3>CSS</h3>

<p>SCSS files were a bit more tricky, I had to use the new scss preprocessor helpers you will find in the <a href="http://guides.rubyonrails.org/asset_pipeline.html">Rails guide</a> (image_path and image_url). I first looked into using erb, but turned out it wasn't needed and the end result is much cleaner.</p>

<h3>Javascript/CoffeeScript</h3>

<p>For the CoffeeScript files, I was referring to image assets in the code and of course all the links were broken. So I had to use ERB in my coffee which looked funky but it worked.</p>

<p>But to get that to work, you need to rename your coffee script and append erb at the end. For instance my feature.js.coffee script had to be renamed feature.js.coffee.erb. That made me cry a little inside, but oh well, at least its not a XML config file. Maybe soon we will start seeing code in filenames or filenames called my_feature.js.compressed.minified.coffee.erb.from_rails.mattetti.org
Also, be careful about the order of the file extensions, otherwise it won't work. I thought I was done, ready to deploy my apps and this time the assets will show up properly. Turns out I was wrong :(</p>

<h3>Rails asset precompilation env specific configuration.</h3>

<p>My css looked good, the precompiling task had run fine but I was missing some js files. I scratched my head as I could only see some of my js files. I then realized that all my JS files were there but some of my CoffeeScript files were missing. The answer was given to me by Bruce who asked me if I had updated my "config.assets.precompile" setting. Sometimes I feel that Rails is trying to compete with Struts and here I was really surprised that by default Rails, in production mode only precompiles all static JS and application.js files, but none of the other dynamic js files. Now it does precompile all the scss files, but for a reason I just don't understand, it's not the case for the JS files. So, you have to go edit production.rb in the config/environments folder and add the other js files you would like Rails to precompile for you.</p>

<p>After making all these changes, I was able to redeploy my app and everything was working again. (you might want to tweak your apache/nginx config as explained in the <a href="http://guides.rubyonrails.org/asset_pipeline.html">Rails guide</a>)</p>

<p> </p>

<h3>Conclusion</h3>

<p>Don't be fooled like me and expect that because you have an app running locally, deployment will work right away. Make sure to read about the new features and what's needed. Overall, I think that the asset pipeline is a nice addon to Rails and if you don't feel like using it, just can put/leave all your files in the public folder and everything will work just like before. I do have to say that I was surprised to see that even in a brand new Rails 3.1 project, Rails isn't running in threaded mode by default. But that's a different (old) story and I guess people still get more excited about asset management than framework raw performance ;)</p>

<p> </p>

<p> </p>

<p> </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First step in scaling a web site: HTTP caching]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/07/11/first-step-in-scaling-a-web-site-http-caching/"/>
    <updated>2011-07-11T10:21:02-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/07/11/first-step-in-scaling-a-web-site-http-caching</id>
    <content type="html"><![CDATA[<p>Today my friend <a href="http://twitter.com/mokolabs">Patrick Crowley</a> and I were talking about scaling his website: <a href="http://cinematreasures.org/">http://cinematreasures.org</a> since an article covering his work will soon be published in a very popular newspaper. Patrick's site is hosted on <a href="http://www.heroku.com/">Heroku</a> which comes by default with <a href="https://www.varnish-cache.org/">Varnish caching</a> enabled.</p>

<p>The challenge is that a lot of people using the Rails framework are used to doing page caching instead of relying on HTTP caching, even though this feature was added a long time ago. The major problem with page caching is that it doesn't scale that well as soon as you run more than one server. Indeed you would need to store the page content to a shared drive between your servers or use memcached and do some work to avoid hitting your app every single time. On the other hand, HTTP caching is extremely easy to handle at the application level and it will dramatically reduce the amount of requests hitting your app. Let me explain a little more about HTTP caching.</p>

<p>Ryan Tomako wrote an <a href="http://tomayko.com/writings/things-caches-do">excellent post</a> about the details of caching, I strongly recommend you <a href="http://tomayko.com/writings/things-caches-do">read it</a>. In a nutshell, the HTTP caching layer (usually) seats before your application layer and allows you, the developer to store some responses that can be send back to the users based on optional conditions. That might still seem vague, let's take a concrete example. If you look at <a href="http://cinematreasures.org">http://cinematreasures.org</a>'s home page you can see that it's an agglomerate of various information:</p>

<p><a href="http://cinematreasures.org"><img src="https://img.skitch.com/20110709-dnxjhikxr14tdr7e35n97madhn.jpg" alt="CinemaTreasures homepage" /></a></p>

<p>And the bottom of the page contains even more dynamic data such as the popular movie theater photos, latest movie theater videos and latest tweets. One might look at that and say that this page can't really be cached and that the caching should be done at the model layer (i.e. cache the data coming from the database). I would certainly agree that caching the data layer is probably a good idea, but you shouldn't start by that. In fact without caching, this page renders fast enough. The problem is when someone like <a href="http://rogerebert.suntimes.com/">Roger Ebert</a> tweets about <a href="http://twitter.com/#!/ebertchicago/status/85912164648497152">CinemaTreasures</a> the load on the app peaks significantly. At the point, the amount of concurrent connections your app can handle gets put to the challenge. Even though your page load is "fast enough", requests will queue up and some will eventually time out. That's actually a perfect case of HTTP caching.</p>

<p>What we want to do in that case is to cache a version of the home page in Varnish for 60 seconds. During that time, all requests coming to the site, will be served by Varnish and will all get the same cached content. That allows our servers to handle the non cached requests and therefore increase our throughput. What's even better, is that if a user refreshes the home page in his/her browser during the first 60 seconds the requests won't even make it all the way to our servers. All of that thanks to conditions set on the response. The first user hitting the HTTP cache layer (Varnish in this case) won't find a fresh cached response, so varnish will forward the request to our application layer which will send back the homepage to varnish and tell Varnish that this content is good for a full minute so please don't ask for it again until a minute from now. Varnish serves this response to the users' browser and let the browser know that the server said that the response was good enough for a minute so don't bother asking for it again. But now, if during these 60 seconds another user comes in, he will hit Varnish and Varnish will have the cached response from the first user and because the cache is still fresh (it's not been 60 seconds since the first request) and the cache is public, then the same response will be sent to the second user.</p>

<p>As you can see, the real strength of HTTP caching is the fact that it's a conditional caching. It's based on the request's URL and some "flags" set in the request/response headers.</p>

<p>Setting these conditions in your app is actually very simple since you just need to set the response's headers. If you are using a Ruby framework you will more than likely have access to the request object via the "request" method and you can set the headers directly like that: "response.headers['Cache-Control'] = 'public, max-age=60'".
In Rails, you can actually use a helper method instead: expires_in 1.minute, :public => true.</p>

<p>You might have a case where you HAVE TO serve fresh content if available and can't serve stale cached content even for a few seconds. In this case, you can rely on the Etag header value. The Etag is meant to validate the freshness of a cached response. Think of it as a signature (unique ID) that is set on the response and used by the client (or cache layer) to see if the server response has changed or not. The way it works is that the client keeps track of the Etag received for each request (attached to the cached response) and then sends it with the next requests. The HTTP layer or application sees the Etag in the request and can check if it is still valid and the content didn't change. If that's the case, an empty response can be sent with a special HTTP status code (304) to let know the client that the old cached value is still good to be used.  Rails has a helper called "stale?" that helps you do the Etag/last modified check and allows you to not fetch all the objects from the database by doing a cheap check on an attribute (For instance you can check the updated_at value and use that as a condition to pull an object and its relationships).</p>

<p>So I explain HTTP caching, I often hear people telling me: "that's great Matt, but you know what, that won't work for us because we have custom content that we display specifically to our users". So in that case, you can always set the Cache-Control header to private which will only cache the response in the client's browser and not the cache layer. That's good to some extent, but it can definitely be improved by rethinking a bit your view layer. In most web apps, the page content is rendered by server side code (Rails, Django, node.js, PHP..) and sent to the user all prepared for him. There are a few challenges with this approach, the biggest one is that the server has to wait until everything is ready (all data fetched, view rendered etc...) before sending back a response and before the client's browser can start rendering (there are ways to chunk the response but that's besides the scope of this post). The other is that the same expensive content has to be calculated/rendered for two different users because you might be inserting the username of the current user at the top of the page for instance. A classic way to deal with that is often to use fragment caching, where the expensive rendering is cached and reused by different requests. That's good but if the only reason to do that is because we are displaying some user specific data, there is a simpler way: async page rendering. The concept is extremely simple: remove all user specific content from the rendered page and then inject the user content in a second step once the page is displayed. The advantage is that now the full page can be cached in Varnish (or Squid or whatever you use for HTTP caching). To inject the user content, the easiest way is to use JavaScript.</p>

<p>Let's stay on CinemaTreasures, when you're logged in, the username is shown on the top of each page:</p>

<p>[caption id="" align="aligncenter" width="574" caption="Once logged in, the username is displayed on all pages"]<img src="https://img.skitch.com/20110710-mh5tqxuw1txf9kppn1smkkarrs.jpg" alt="" />[/caption]</p>

<p>The only things that differs from the page rendered when the user is not logged in and when he is, are these 2 links and an avatar. So let's write some code to inject that after rendering the page.</p>

<p>In Rails, in the sessions controller or whatever code logs you in, you need to create a new cookie containing the username:</p>

<p>``` ruby
cookies[:username] = {</p>

<pre><code>     :value =&gt; session[:username],
     :expires =&gt; 2.days.from_now,
     :domain =&gt; ".cinematreasures.org"
   }
</code></pre>

<p>```</p>

<p>As you can see, we don't store the data in the session cookie and the data won't be encrypted. You need to be careful that someone changing his cookie value can't access data he/should shouldn't. But that's a different discussion. Now that the cookie is set, we can read it from JavaScript when the page is loaded.</p>

<p>``` javascript
document.observe("dom:loaded", function() {
  displayLoggedinUserLinks();
});</p>

<p>function readCookie(name) {</p>

<pre><code> var nameEQ = name + "=";
 var ca = document.cookie.split(';');
 for(var i=0;i &lt; ca.length;i++) {
      var c = ca[i];
      while (c.charAt(0)==' ') c = c.substring(1,c.length);
      if (c.indexOf(nameEQ) == 0) return c.substring(nameEQ.length,c.length);
 }
 return null;
</code></pre>

<p>}</p>

<p>function displayLoggedinUserLinks() {
  var username            = readCookie('username');
  var loginLink           = $('login');
  var logout              = $('logout');
  if (username == null){</p>

<pre><code>loginLink.show();
logout.hide();
</code></pre>

<p>  }else{</p>

<pre><code>// user is logged in and we have his/her username
loginLink.hide();
if(userGreetings){ userGreetings.update("&lt;span id="username"&gt;username&lt;/span&gt;"); }
logout.show();
showAvatar(username);
</code></pre>

<p>  };
  return true;
}
```</p>

<p>The code above doesn't do much, once the DOM is loaded, the displayLoggedinUserLinks() function gets trigger. This function reads the cookie via the readCookie() function and if a username is found, the login link is hidden, the user name is displayed, as well as the logout link and the avatar. (You can also use a jQuery cookie plugin to handle the cookie, but this is an old example using Prototype, replace the code accordingly)
When the user logs out, we just need to delete the username cookie and the cached page will be rendered properly. In Rails, you would do delete the cookie like that: cookies.delete('username').
Quite often you might even want to make an Ajax call to get some information such as the number of user messages or notifications. Using jQuery or whatever JS framework you fancy you can do that once the page is rendered. Here is an example, on this page, you can see the learderboards for MLB The Show. The leaderboards don't change that often, especially the overall leaderboards so they can be cached for a little while, however the player's presence can change anytime. The smart way to deal with that, would be to cache the  leaderboards for a few seconds/minutes and make an ajax call to a presence service passing it a list of user ids collected from the DOM. The service called via Ajax could also be cached  depending on the requirements.</p>

<p>Now there is one more problem that people using might encouter: flash notices. For those of you not familiar with Rails, flash notices are messages set in the controller and passed to the view via the session (at least last time I checked). The problem happens if I'm the home page isn't cached anymore and I logged in which redirects me to the home page with a flash message like so:</p>

<p><img src="https://img.skitch.com/20110710-1u6dn8rrc6r62rsg6niphhd2pi.jpg" alt="" /></p>

<p>The problem is that the message is part of the rendered page and now for 60 seconds, all people hitting the home page will get the same message. This is why you would want to write a helper that would put this message in a custom cookie that you'd pull JS and then delete once displayed. You could use a helper like that to set the cookie:</p>

<p>``` ruby
def flash_notice_cookie(msg, expiration=nil)
  cookies[:flash_notice] = {</p>

<pre><code>:value =&gt; msg,
:expires =&gt; expiration || 1.minutes.from_now,
:domain =&gt; ".cinematreasures.com"
</code></pre>

<p>   }
end
```</p>

<p>And then add a function called when the DOM is ready which loads the message and injects it in the DOM. Once the cookie read, delete it so the message isn't displayed again.</p>

<p> </p>

<p>So there you have it, if you follow these few steps, you should be able to handle easily 10x more traffic without increasing hardware or making any type of crazy code change. Before you start looking into memcached, redis, cdns or whatever, consider HTTP caching and async DOM manipulation. Finally, note that if you can't use Varnish or Squid, you can very easily setup <a href="http://rtomayko.github.com/rack-cache/">Rack-Cache</a> locally and share the cache via memcached. It's also a great way to test locally.</p>

<hr />

<p><strong>Update:</strong> CinemaTreasures was updated to use HTTP caching as described above. The hosting cost is now half of what it used to be and the throughput is actually higher which offers a better protection against peak traffic.</p>

<hr />

<p> </p>

<p>External resources:</p>

<ul>
<li><p><a href="http://tomayko.com/writings/things-caches-do">http://tomayko.com/writings/things-caches-do</a></p></li>
<li><p><a href="http://devcenter.heroku.com/articles/http-caching">HTTP Caching at Heroku</a></p></li>
<li><p><a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html">W3 caching protocol </a></p></li>
<li><p><a href="http://rtomayko.github.com/rack-cache/">Rack-Cache middleware</a></p></li>
<li><p><a href="http://www.nolanevans.com/2011/03/optimizing-your-rails-site-with-http.html">Blog post covering HTTP Caching/Varnish/Rails</a></p></li>
<li><p><a href="http://plugins.jquery.com/project/Cookie">jQuery cookie plugin</a></p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Go's reflection example]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/06/27/golang-reflection-exampl/"/>
    <updated>2011-06-27T12:12:32-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/06/27/golang-reflection-exampl</id>
    <content type="html"><![CDATA[<p>The <a href="http://golang.org/">Go Programming language</a> is really cool language by Google. According to the sales pitch, it's a <strong><em>"fast, statically typed, compiled language that feels like a dynamically typed, interpreted language"</em></strong>. Well, if you are like me, you don't trust sales pitches because you know that people writing them don't care about you, they care about their product. However cynical you are, you still have to check the facts. So here is a quick demonstration showing how to use Go's reflection feature.</p>

<p>Installing Go is actually really straight forward on a Mac, and slightly harder on Linux, check <a href="http://golang.org/doc/install.html">this guide </a>to see how to build Go in a few minutes.</p>

<p>Once all setup, you might want to read the documentation to see how to code in Go. Go is actually a kind of nice version of C with a<a href="http://golang.org/doc/go_spec.html"> simplified syntax</a>, no header files, really fast compilation time, a garbage collector and a <a href="http://golang.org/doc/effective_go.html?#interfaces_and_types">simple way to approach object inheritance</a> without turning in the complicated mess C++ is. The language is designed around the concept of <a href="http://golang.org/doc/effective_go.html?h=goroutines#concurrency">goroutines, a very nice way to handle concurrency</a>. It also has some features that Rubyists, Pythonistas and Javascripters wouldn't want to live without such as closures and some they probably wish they had such as <a href="http://golang.org/doc/effective_go.html?#defer">defer</a>. But of the things we are used to with dynamic languages is the concept of reflection. In a nutshell, at runtime, your code can reflect on the type of a given object and let the developer act accordingly. Depending on your programming background that might be obvious or you might not see the value. To be honest, that's not the question here. What I'm interested in showing you is how it works.</p>

<p>For the sake of this demo, let's pretend we want to have a "Dish" data model, each instance of the "Dish" type will have a few attributes, an id, a name, an origin and a custom query which really is a function that we store as an attribute. Here is how we would represent that model in Go:</p>

<pre><code>// Data Model
type Dish struct {
  Id  int
  Name string
  Origin string
  Query func()
}
</code></pre>

<p>This is more or less the equivalent of the following Ruby code:</p>

<pre><code>class Dish
  attr_accessor :id, :name, :origin, :query
end
</code></pre>

<p>Ruby works slightly differently in the sense that defining attribute accessors create getters and setter methods but doesn't technically create instance variables until they are used. Here is what I mean:</p>

<pre><code>shabushabu = Dish.new
shabushabu.instance_variables # =&gt; []
shabushabu.name = "Shabu-Shabu"
shabushabu.instance_variables # =&gt; ["@name"]
shabushabu.origin = "Japan"
shabushabu.instance_variables # =&gt; ["@name", "@origin"]
</code></pre>

<p>Another way of checking on the accessors is to check the methods defined on the object:</p>

<pre><code>shabushabu.methods - Object.new.methods
=&gt; ["name", "name=", "origin", "origin=", "id=", "query", "query="]
</code></pre>

<p>But anyway, this post isn't about Ruby, it's about Go and what we would like is to reflect on an object of "Dish" type and see its attributes. The good news is that the Go language ships with a <a href="http://golang.org/pkg/reflect/">package to do just that</a>. Here is the full implementation:</p>

<pre><code>package main

import(
  "fmt"
  "reflect"
)

func main(){
  // iterate through the attributes of a Data Model instance
  for name, mtype := range attributes(&amp;Dish;{}) {
    fmt.Printf("Name: %s, Type %s\n", name, mtype.Name())
  }
}

// Data Model
type Dish struct {
  Id  int
  Name string
  Origin string
  Query func()
}

// Example of how to use Go's reflection
// Print the attributes of a Data Model
func attributes(m interface{}) (map[string]reflect.Type) {
  typ := reflect.TypeOf(m)
  // if a pointer to a struct is passed, get the type of the dereferenced object
  if typ.Kind() == reflect.Ptr{
    typ = typ.Elem()
  }

  // create an attribute data structure as a map of types keyed by a string.
  attrs := make(map[string]reflect.Type)
  // Only structs are supported so return an empty result if the passed object
  // isn't a struct
  if typ.Kind() != reflect.Struct {
    fmt.Printf("%v type can't have attributes inspected\n", typ.Kind())
    return attrs
  }

  // loop through the struct's fields and set the map
  for i := 0; i &lt; typ.NumField(); i++ {
    p := typ.Field(i)
      if !p.Anonymous {
        attrs[p.Name] = p.Type
      }
     }

  return attrs
}
</code></pre>

<p>Unfortunately, my code highlighter doesn't support the Go syntax, but GitHub does, so here is a <a href="https://gist.github.com/1009629">pretty version</a>.</p>

<p>There are ways of running Go source code like Ruby or Python scripts but in this case, we'll use the compiler &amp; linker provided with Go. I named my source file "example.go", and here is how I compiled, linked and run it:</p>

<pre><code>$ 6g example.go &amp;&amp; 6l example.6 &amp;&amp; ./6.out
Name: Origin, Type string
Name: Id, Type int
Name: Query, Type 
Name: Name, Type string
</code></pre>

<p>As you can see each attribute is printed out with its name and type. The code might seem a bit odd if you never looked at Go before.
Here is a quick rundown of the code:</p>

<p>In our main function, we create a new instance of type Dish on which we call attributes on. The call returns a map on which we iterate through and print the attribute name (key) and type (value).
The attributes function is defined a bit below and and it takes any type of objects (empty interface) and returns a map, which is like a Hash or a Dictionary. The map has keys of String type and values of "Type" type. The "Type" type is defined in the reflect package. Inside the function, 23 then use the previously mentioned reflect package to check on the type and the name of each attribute and assign it to a map object. (note that I'm explicitly returning the map, but I could have done it in a more implicit way)</p>

<p>So there you go, that's how you use reflection in Go. Pretty nifty and simple.</p>

<p> </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sayonara Sony ]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/06/10/sayonara-sony/"/>
    <updated>2011-06-10T08:49:30-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/06/10/sayonara-sony</id>
    <content type="html"><![CDATA[<p>It's now official, I have resigned from Sony Computer Entertainment America.</p>

<p><a href="http://merbist.com/wp-content/uploads/2011/06/playstation-logo.png"><img src="http://merbist.com/wp-content/uploads/2011/06/playstation-logo-150x150.png" alt="" /></a></p>

<p>I was planning on posting this a bit later but since I was politely escorted out of the building by HR/security, I have more free time to let you know of my decision. Before you ask: No, my decision isn't directly related to the recent PSN/Sony security breach events and no, I don't have your credit card number. More seriously, my decision boils down to something much simpler &amp; concrete: drive and passion.</p>

<p>The concept of drive is very well explained <a href="http://www.youtube.com/watch?v=u6XAPnuFjJc">in this talk</a> by <a href="http://www.danpink.com/">Dan Pink</a> and illustrated by <a href="http://www.thersa.org/">RSA</a>:</p>

<p>As explained, it is proven that when doing cognitive tasks, there are 3 factors that lead to better performance &amp; personal satisfaction:</p>

<ul>
<li><p>Autonomy: engagement vs compliance</p></li>
<li><p>Mastery: get better at stuff</p></li>
<li><p>Purpose: be disruptive but make the world a better place</p></li>
</ul>


<p> </p>

<p>The challenge is that when you work for a big corporation, you rarely see these factors applied. The amount of red tape, management overhead, lack of recognition and accountability result in a low drive by most employees. I think it was the first time in my entire career that I was told by a <a href="http://nateware.com">manager</a> to care less about the quality and end result of our products.</p>

<p>The second important concept that I think is critical when looking at your career is passion. This topic is very well covered in <a href="http://chadfowler.com/">Chad Fowler</a>'s book: <a href="http://pragprog.com/titles/cfcar2/the-passionate-programmer">The Passionate Programmer</a>.</p>

<p><a href="http://pragprog.com/titles/cfcar2/the-passionate-programmer"><img src="http://imagery.pragprog.com/products/137/cfcar2_xlargecover.jpg?1298589825" alt="" /></a>Here is a quote from Chad's book:</p>

<blockquote><p>Fulfillment and happiness don’t (often) come by chance. They require thought, intention, action, and a willingness to change course when you’ve made mistakes. [...] It might be a technology or business domain that gets you excited. Or, on the other hand, it might be a specific technology or business domain that drags you down. Or a type of organization. Maybe you’re meant for small teams or big teams. Or rigid processes. Or agile processes. Whatever the mix, take some time to find yours. You can fake it for a while, but a lack of passion will catch up with you and your work.</p></blockquote>

<p> </p>

<p>It's hard to summarize Chad's book into just a few sentences, but what I got from his book is that if, for whatever reason, you lose your passion for your job, you should move on to another place where you can be passionate and excel. In my case, I'm still very much passionate about video game development but I find my passion seriously affected by an unhealthy work environment, bad communication and a lack of desire to change things in concrete ways. As the saying goes, <a href="http://www.google.com/search?q=people+don't+leave+jobs">"People don't leave jobs..."</a></p>

<p> </p>

<h3>What's next for me?</h3>

<p>If you are in the software industry you know that everybody is hiring and that there is a real shortage of talent out there. You probably also receive half a dozen emails per week from recruiters offering you "the best job ever" with an obscene salary. Well, I receive them too. But in this market, you and I can allow ourselves to be picky and to choose the right job for ourselves. By choosing the right job, we are going to be more passionate, more driven, more efficient and bring a lot more value to our employers, who, in return, will hopefully do everything they can to make sure we grow within the company with a strong desire to do even better. As I was considering what I would want to do if I were to leave Sony, I came up with a few ideas about a job:</p>

<ul>
<li><p>I don't want to live to work, but rather, work to live. (kind of an European cliché sentence)</p></li>
<li><p>It's not about the job title.</p></li>
<li><p>It's not about the pay check.</p></li>
<li><p>It's not about how glamourous an industry  is.</p></li>
<li><p>What matters is :</p>

<ul>
<li><p>the company culture.</p></li>
<li><p>the passion coming from the leaders.</p></li>
<li><p>the company's ambitions.</p></li>
<li><p>how the company rewards and respects its employees.</p></li>
<li><p>the autonomy/trust given to the employees.</p></li>
<li><p>the purpose of the company and its potential to disrupt a market/change the world.</p></li>
<li><p>personal growth within the company.</p></li>
</ul>
</li>
</ul>


<p> </p>

<p>Writing this list helped me realize that I was definitely not in the right place and helped me create a list of criteria to define what kind of job I should be doing instead. As I was thinking about all that, I was reminded of this quote:</p>

<blockquote><p>"One should not pursue goals that are easily achieved. One must develop an instinct for what one can just barely achieve through one's greatest efforts." —Albert Einstein</p></blockquote>

<p>This is probably a personality trait, but I like/need to be at the edge of my confort zone. I need to learn new things, experience new challenges. I need to try to solve unsolved problems. So part of me needs a company with a rich culture, a great a vision and leadership, but another part also needs to be allowed to think creatively, to push the existing boundaries, to challenge myself and to try to achieve things through my greatest efforts.</p>

<p>The challenge is that over the last 5-7 years I have become a Ruby specialist. I have learned to understand and master the language, learning its pros/cons and what goes on "under the hood". I have built small and huge solutions for various domain spaces on top of Ruby. I have shared my knowledge giving talks, books, blog posts. I have also spent a lot of time expanding my own computer science knowledge, looking into other programming languages, frameworks, designs. My job at Sony was interesting due to the fact that Ruby is used in a quite singular way with very specific problems and a lot of C/C++ interaction. So while it is true that I am a Ruby specialist, I don't like that label. I don't like it because it's very limiting. My goal is to solve problems and quite often Ruby is a great tool for that, but for some problems, it is not. So I need a job where my expertise is helpful but would not limit my desire to learn new approaches, languages and skills.</p>

<p>And this is why I will soon start working as a <em>Code Alchemist in the LivingSocial R&amp;D's lab</em>.</p>

<p><a href="http://merbist.com/2011/06/10/sayonara-sony/livingsocial-2/"><img src="http://merbist.com/wp-content/uploads/2011/06/livingsocial1.png" alt="" /></a></p>

<p>That might be a shocker at first glance. Going from working on video games to working for a daily-deal startup? It doesn't seem like a very smart career move. To be honest, that was my first reaction. But LivingSocial's VP of engineering is <a href="http://twitter.com/#!/chadfowler">Chad Fowler</a> (the author of The Passionate Programmer, mentioned earlier) and its VP of R&amp;D is <a href="http://en.wikipedia.org/wiki/Richard_Kilmer_(programmer">Rich Kilmer</a>), InfoEther's cofounder and recognized mad-scientist-coder. I've known Chad and Rich for many years, meeting at tech conferences that they organized or were invited to give talks to, and even getting to hack on some projects with Rich. So when they approached me to join them at LivingSocial, I wanted to know more about their own motivations, why I would be a good fit and how the company/job would rate against my list of criteria. We had long and honest discussions and the result is that I am excited to soon be working with one of the best teams I know of. More concretely, I will be working with <a href="http://twitter.com/#!/rich_kilmer">Rich</a>, <a href="http://twitter.com/#!/wbruce">Bruce</a> and <a href="http://twitter.com/#!/go">Michael</a> in helping LivingSocial revolutionize the local market. LivingSocial is a fast growing and successful company with a strong focus on creating a great experience for both customers and merchants. The company's vision is well defined and the desire to change the world the way we know it is palpable. Most of the founders have a technical background, they value good engineering practices and have created a nice, positive company culture. Chad has some really awesome, passionate and talented engineers on his team (too many to mention), for whom I have a lot of respect and with whom I look forward to working with.  I also value the fact that LivingSocial trusts and values me enough to let me work remotely. This is very important for me because it shows that my new employer really wants to work with me, trusts me but also is willing to embrace the challenges of having a remote team if that's what's needed to create the "right team". After looking more deeply at what I need and what LivingSocial is, I believe that I can assist LivingSocial in making a very positive change to the way small businesses around the world are run. And I am looking forward to this.</p>

<p> </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Video game web framework design]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/04/14/video-game-web-framework-design/"/>
    <updated>2011-04-14T10:28:39-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/04/14/video-game-web-framework-design</id>
    <content type="html"><![CDATA[<p>In this post I will do my best to explain why and how I reinvented the wheel and wrote a custom web framework for some of Sony's <a href="http://www.gameproducer.net/2006/05/26/what-are-aaa-titles/">AAA console titles</a>. My goal is to reflect on my work by walking you through the design process and some of the implementation decisions. This is not about being right or being wrong, it's about designing a technical solution to solve concrete business challenges.</p>

<h2>Problem Domain</h2>

<p>The video game industry is quite special, to say the least. It shares a lot of similarities with the movie industry. The big difference is that  the movie industry hasn't evolved as quickly as the video game  industry has. But the concept is the same, someone comes up with a great  idea, finds a team/studio to develop the game and finds a publisher. The  development length and budget depends on the type of game, but for a AAA  console game, it usually takes a least a <a href="http://www.joystiq.com/2010/03/09/god-of-war-3-has-44-million-dollar-budget/">few million</a> and a minimum of a year of work once the project has received the green light. The creation of such a game involves various teams, designers, artists, animators, audio teams, developers, producers, QA, marketing, management/overhead etc.. Once the game gets released, players purchase the whole game for a one time fee and the studio moves  on to their next game. Of course things are not that simple, with the latest platforms, we now have the option to patch games, add <a href="http://en.wikipedia.org/wiki/Downloadable_content">DLC</a> etc.. But historically, a console game is considered done when it ships, exactly like a movie, and very little work is scheduled post release.</p>

<p>Concretely such an approach exposes a few challenges when trying to implement online features for a <a href="http://www.gameproducer.net/2006/05/26/what-are-aaa-titles/">AAA console title</a>:</p>

<ul>
<li><p>Communication with the game client network team</p></li>
<li><p>Scalability, performance</p></li>
<li><p>Insane deadlines, unstable design (constant change of requirements)</p></li>
<li><p>Can't afford to keep on working on the system once released (time delimited projects)</p></li>
</ul>


<p> </p>

<h2>Communication</h2>

<p>As in most situations, communication is one of the biggest challenges. Communication is even harder in the video game industry since you have so many teams and experts involved. Each team speaks its own jargon, has its own expertise and its own deadlines. But all focus on the same goal: releasing the best game ever. The team I'm part of has implementing online features as its goal. That's the way we bring business value to our titles. Concretely, that means that we provide the game client developers with a C++ SDK which connects to custom web APIs written in Ruby. The API implementations rely on various data stores (<a href="http://www.mysql.com/">MySQL</a>, <a href="http://redis.io/">Redis</a>, <a href="http://memcached.org/">Memcached</a>, memory) to store and retrieve all sorts of game data.</p>

<p>Nobody but our team should care about the implementation details, after all, the whole point of providing an API is to provide a simple interface so others can do their part of the job in the easiest way possible. This is exactly where communication becomes a problem. The design of these APIs should be the result of the work of two teams with two different domains of expertise and different concerns. One team focuses on client performance, memory optimization and making the online resources available to the game engine without affecting the game play. The other, focuses on server performance, latency, scalability, data storage and system contention under load. Both groups have to come together to find a compromise making each other's job doable. Unfortunately, things are not that simple and game designers (who are usually not technical people) have a hard time <em>not</em> changing their designs and requirements every other week (usually for good reasons) making API design challenging and creating tension between the teams.</p>

<p>From this perspective, the API is the most important deliverable for our team and it should communicate the design goal while being very explicit about how it works, why it works the way it does, and how to implement it client side. This is a very good place where we can improve communication by making sure that we focus on making clear, well designed, well documented, flexible APIs.</p>

<p> </p>

<h2>Scalability, performance</h2>

<p>On the server side, the APIs need to perform and scale to handles tends of thousands of concurrent requests. Web developers often rely on aggressive <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html">HTTP caching</a> but in our case, the web client (our SDK) has a limited amount of memory available and 90% of the requests are user specific (can't use full page HTTP cache) and a lot of these are POST/DELETE requests (can't be cached). That means that, to scale, we have to focus on what most developers don't often have to worry too much about: all the small details which, put together with a high load, end up drastically affecting your performance.</p>

<p>While Ruby is a great language, a lot of the libraries and frameworks are not optimized for performance, at least not the type of performance needed for our use case. However, the good news is that this is easily fixable and many alternatives exist (lots of async, non-blocking drivers for i.e). When obsessed with performance, you quickly learn to properly load test, profile, and monitor your code to find the bottlenecks and the places where you should focus your attention. The big, unique challenge though, is that a console game will more than likely see its peak traffic in the first few weeks, not really giving the chance to the online team to iteratively handle the prod issues. The only solution is to do everything possible before going live to ensure that the system will perform as expected. Of course if we were to write the same services in a more performant language, we would need to spend less time optimizing. But we are gaining so much flexibility by using a higher level programming language that, in my mind, the trade off is totally worth it (plus you still need to spend a lot of time optimizing your code path, even if your code is written in a very fast language).</p>

<p> </p>

<h2>Deadlines, requirement changes</h2>

<p>That's just part of the way the industry works. Unless you work for <a href="http://blizzard.com">Blizzard</a> and you can afford to spend a crazy amount of time and money on the development of a title; you will have to deal with sliding deadlines, requirement changes, scope changes etc... The only way I know how to protect myself from such things is to plan for the worst. Being a non-idealistic (read pessimistic) person helps a lot. When you design your software, make sure your design is sound but flexible enough to handle any major change that you know could happen at any time. Pick your battles and make sure your assumptions are properly thought through, communicated and documented so others understand and accept them. In a nutshell, this is a problem we can't avoid, so you need to embrace it.</p>

<p> </p>

<h2>Limited reusability</h2>

<p>This topic has a lot to do with the previous paragraph. Because scopes can change often and because the deadlines are often crazy, a lot of the time, engineers don't take the time to think about reusability. They slap some code together, pray to the <a href="http://en.wikipedia.org/wiki/Lords_of_Kobol">lords of Kobol</a> and hope that they won't have to look at their code ever again (I'm guilty of having done that too). The result is a lot of throw away code. This is actually quite frequent and normal in our industry. But it doesn't mean that it the right thing to do! The assumption/myth is that each game is different and therefore two games can't be using the same tech solution. My take on that is that it's partly true. But some components are the same for 80% of the games I work on. So why not design them well and reuse the common parts? (A lot of games share the same engines, such as <a href="http://www.unrealengine.com/">Unreal</a> for example, and there is no reason why we can't build a core online engine extended for each title)</p>

<p> </p>

<h2>My approach</h2>

<p>When I joined Sony, I had limited experience with the console video game industry and my experience was not even related to online gaming. So even though I had (strong) opinions (and was often quite (perhaps even too) vocal about them), I did my best to improve existing components and work with the existing system. During that time, the team shipped 4 AAA titles on the existing system. As we were going through the game cycles, I did my best to understand the problem domain, the reasons behind some of the design decisions and finally I looked at what could be done differently to improve our business value. After releasing a title with some serious technical difficulties, I spent some time analyzing and listing the problems we had and their root causes. I asked our senior director for a mission statement and we got the team together to define the desiderata/objectives of our base technology. Here is what we came up with:</p>

<ol>
<li><p>Stability</p></li>
<li><p>Performance / Scalability</p></li>
<li><p>Encapsulation / Modularity</p></li>
<li><p>Documentation</p></li>
<li><p>Conventions</p></li>
<li><p>Reusability / Maintainability</p></li>
</ol>


<p>These objectives are meant to help us objectively evaluate two options. The legacy solution was based on Rails, or more accurately: Rails was used in the legacy solution. Rails had been hacked in so many different ways that it was really hard to update anything without breaking random parts of the framework. The way to do basic things kept being changed, there was no consistent design, no entry points, no conventions and each new game would duplicate the source code of the previously released game and make the game specific changes. Patches were hard to back port and older titles were often not patched up. The performance was atrocious under load, mainly due to hacked-up Rails not performing well. (Rails was allocating so many objects per request that the GC was taking a huge amount of the request cycles, the default XML builder also created a ton load of objects etc...) This was your typical <a href="http://en.wikipedia.org/wiki/Broken_windows_theory">broken windows scenario</a>. Engineers were getting frustrated, motivation was fainting, bugs were piling up and nobody felt ownership over the tech.</p>

<p>Now, to be fair, it is important to explain that the legacy system was hacked up together due to lack of time, lack of resources and a lot of pressure to release something ASAP. So, while the end result sounds bad, the context is very important to note. This is quite common in software engineering and when you get there, the goal is not to point fingers but to identify the good and the bad parts of the original solution. You then use this info to decide what to do: fix the existing system or rewrite, porting the good parts.</p>

<p>Our report also came up with a plan. A plan to redesign our technology stack to match the desiderata previously mentioned. To put it simply, the plan was to write a new custom web framework focusing on stability, performance, modularity and documentation. Now, there are frameworks out there which already do that or value these principles. But none of them focus on web APIs and none of them are specific to game development. Finally, the other issue was that we had invested a lot of time on game specific code and we couldn't throw away all that work, so the new framework had to support a good chunk of legacy code but had to make it run much faster.</p>

<h2>Design choices</h2>

<p><strong>Low conversion cost</strong></p>

<p>Using <a href="http://nodejs.org/">node.js</a> &amp; <a href="http://jashkenas.github.com/coffee-script/">coffee script</a>/<a href="http://www.scala-lang.org/">Scala</a>/<a href="http://weblocks.viridian-project.de/">whatever</a> <a href="http://code.google.com/p/v8cgi/">new</a> <a href="https://github.com/tenderlove/phuby">fancy tech</a> was not really an option. We have a bunch of games out there which are running on the old system and some of these games will have a sequel or a game close enough that we could reuse part of the work. We don't want to have to rewrite the existing code. I therefore made sure that we could reuse 90% of the business logic by adding an abstraction layer doing the heavy lifting at boot time and therefore not affecting the runtime performance. Simple conversion scripts were also written to import the core of the existing code over.</p>

<p><em>Lessons learned:</em> It is very tempting to just redo everything and start from scratch. However, the business logic implementation wasn't the main cause of our problems. Even though I wish we could have redesigned that piece of the puzzle, it didn't make sense from a business perspective. A lot of thought had to be put into how to obtain the expected performance level while keeping the optional model/controller/view combos. By having full control of the "web engine", we managed to isolate things properly without breaking the old paradigms. We also got rid of a lot of assumptions allowing us to design new titles a bit differently while being backward compatible and have our code run dramatically faster.</p>

<p><strong>Web API centric</strong></p>

<p>This is probably the most important design element. If I had to summarize what our system does in just a few words, I would say: a game web API. Of course, it's much more than that. We have admin interfaces, producer dashboards, community websites, lobbies, p2p, BI reports, async processing jobs etc... But at the end of the day, the only one piece you can't remove is the game web API. So I really wanted the design to focus on that aspect. When a developer starts implementing a new online game feature, I want him/her to think about the API. But I also want this API to be extremely well documented so the developer working client-side understands the purpose of the API, how to use it, and what the expected response is right away. I also wanted to be able to automatically test our APIs at a very basic level so we could validate that there are discrepancies between what the client expects and what the server provides. To do that, I created a standalone API DSL with everything needed to describe your API but without any implementation details whatsoever. The API DSL lets the developer define a route (url), the HTTP verb expected, if the request should be authenticated or not, SSL or not, the param rules, default values and finally a response description (which was quite a controversial choice). All of these settings can be documented by the developer. This standalone DSL can then be consumed by different tools. For instance we have a tool extracting all the info into nicely formatted HTML doc for the game client developers. This tool doesn't need to load the framework to just render the documentation. We also use this description at boot time to compile the validation rules and routes, allowing for a much faster request dispatch. And we also use these API description to generate some low level data for the client. Finally, we used the service description DSL to help create mocked service responses allowing the client team to test service designs without having to wait for the implementation streamlining the process.</p>

<p><em>Lessons learned:</em> We had a lot of internal discussions about the need to define the response within the service description. Some argued that it's a duplication since we already had a view and we could parse that to get most of what we needed (which is what the old system was doing). We ended up going with the response description DSL for a few critical reasons: testing and implementation simplicity. <em>Testing:</em> we need to have an API expectation reference and to keep this reference sane so we can see if something is changed. If we were to magically parse the response, we couldn't test the view part of the code against a frame of reference. <em>Implementation simplicity</em>: magically parsing a view template is more tricky that it sounds, you would need to render the template with the right data to make it work properly. Furthermore, you can't document a response easily in the view, and if you do, you arguably break the separation of concern between the description and the implementation. Finally, generated documentation isn't enough and that's why we decided to write English documentation, some being close to the code and some being just good old documentation explaining things outside of the code context.</p>

<p><strong>Modularity</strong></p>

<p>In order to make our code reusable we had to isolate each component and limit the dependencies. We wrote a very simple extension layer allowing each extension to registers itself once detected. The extension interface exposes the path of the extension, its type, models, services, controllers, migrations, seed data, dependencies etc.. Each extension is contained in a folder. (The extension location doesn't matter much but as part of the framework boot sequence, we check a few default places.) The second step of the process is to check a manifest/config file that is specific to each title. The manifest file lists the extensions that should be activated for the title. The framework then activates the marked extensions and has access to libs, models, views, migrations, seed data and of course to load services (DSL mentioned earlier) etc...</p>

<p>Even though we designed the core extensions the best we could, there are cases where some titles will need to extend these extensions. To do that, we added a bunch of hooks that could be implemented on the title side if needed (Ruby makes that super easy and clean to do!). A good example of that is the login sequence or the player data.</p>

<p><em>Lessons learned:</em> The challenge with modularity is to keep things simple and highly performing yet flexible. A key element to manage that is to stay as consistent as possible. Don't implement hooks three different ways, try to keep method signatures consistent, keep it simple and organized.</p>

<p> </p>

<h2>Conclusion</h2>

<p>It's a bit early to say if this rewrite is a success or not and there are still lots of optimizations and technology improvements we are looking forward to doing. Only time will give us enough retrospect to evaluate our work. But because we defined the business value (mission statement) and the technical objectives, it is safe to say that the new framework meets the expectations quite well. On an early benchmark we noted a 10X speed improvement and that's before drilling into the performance optimizations such as making all the calls non-blocking, using better connection pools, cache write through layer... However, there is still one thing that we will have to monitor: how much business value will this framework generate. And I guess that's where we failed to define an agreed upon evaluation grid. I presume that if our developers spend more time designing and implementing APIs and less time debugging that could be considered business value. If we spend less time maintaining or fighting with the game engine, that would also be a win. Finally, if the player experience is improved we will be able to definitely say that we made the right choice.</p>

<p>To conclude, I'd like to highlight my main short coming: I failed to define metrics that would help us evaluate the real business value added to our products. What I consider a technical success might not be a business success. How do you, in your own domain, find ways to define clear and objective metrics?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hey Apple, please be nice and share]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/03/07/hey-apple-please-be-nice-and-share/"/>
    <updated>2011-03-07T09:00:56-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/03/07/hey-apple-please-be-nice-and-share</id>
    <content type="html"><![CDATA[<p>My name is Matt Aimonetti, and in my free time I work on Apple's open source <a href="http://www.ruby-lang.org">Ruby</a> implementation named <a href="http://macruby.org">MacRuby</a>. I'm also the author of <a href="http://oreilly.com/catalog/0636920000723">O'Reilly's MacRuby book</a>. As you can imagine, I'm very thankful that Apple initiated the MacRuby project a few years ago and have been an avid supporter. MacRuby is awesome to develop OS X native applications using the Ruby language and even allows you to compile down your apps to machine code. It's a great alternative to Objective-C.</p>

<p><a href="http://www.apple.com/macosx/lion/"><img src="https://img.skitch.com/20111012-kyiy9nhx5n9h9wafucyh8p3knx.jpg" alt="" /></a></p>

<p>MacRuby is so awesome that Apple is even <a href="http://twitter.com/GeorgeBellos/status/41595085179203584">using it in its upcoming OS</a>. The only problem is that Apple apparently decided to not share MacRuby with other OS X developers and put <a href="http://yfrog.com/h8hhlydj">MacRuby in the OS private frameworks</a>. While this doesn't affect the project itself, it does affect OS X developers like myself who can't link to <a href="http://www.apple.com/macosx/lion/">Lion</a>'s private MacRuby framework and are forced to embed MacRuby with their applications.</p>

<p>That's why I have opened a <a href="http://bugreporter.apple.com/">ticket on Apple radar system</a> to ask that MacRuby be made a public framework.</p>

<p>If you also want Apple to make this change, <a href="http://bugreporter.apple.com/">please take a minute and let them know</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby concurrency explained]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/02/22/concurrency-in-ruby-explained/"/>
    <updated>2011-02-22T22:34:30-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/02/22/concurrency-in-ruby-explained</id>
    <content type="html"><![CDATA[<p>Concurrency is certainly <a href="http://en.wikipedia.org/wiki/Petri_Net">not a new problem</a> but it's getting more and more attention as machines start having more than 1 core, that web traffic increases drastically and that some new technologies show up saying that they are better because they handle concurrency better.
If that helps, think of concurrency as multitasking. When people say that they want concurrency, they say that they want their code to do multiple different things at the same time. When you are on your computer, you don't expect to have to choose between browsing the web and listening to some music. You more than likely want to run both concurrently. It's the same thing with your code, if you are running a webserver, you probably don't want it to only process one request at a time.
The aim of this article is to explain as simply as possible the concept of concurrency in Ruby, the reason why it's a complicated topic and finally the different solutions to achieve concurrency.</p>

<p>First off, if you are not really familiar with concurrency, take a minute to <a href="http://en.wikipedia.org/wiki/Concurrency_%28computer_science%29">read the wikipedia article on the topic</a> which is a great recap on the subject. But now, you should have noticed that my above example was more about parallel programming than concurrency, but we'll come back to that in a minute.</p>

<blockquote><p><strong>The real question at the heart of the quest for concurrency is: "how to increase code throughput".</strong></p></blockquote>

<p>We want our code to perform better, and we want it to do more in less time. Let's take two simple and concrete examples to illustrate concurrency. First, let's pretend you are writing a twitter client, you probably want to let the user scroll his/her tweets while the latest updates are  being fetched. In other words, you don't want to block the main loop and interrupt the user interaction while your code is waiting for a response from the Twitter API. To do that, a common solution is to use multiple <strong>threads</strong>. Threads are basically processes that run in the same memory context. We would be using one thread for the main event loop and another thread to process the remote API request. Both threads share the same memory context so once the Twitter API thread is done fetching the data it can update the display. Thankfully, this is usually transparently handled by asynchronous APIs (provided by the OS or the programming language std lib) which avoid blocking the main thread.</p>

<p>The second example is a webserver. Let's say you want to run a Rails application. Because you are awesome, you expect to see a lot of traffic. Probably more than 1 QPS (query/request per second). You benchmarked your application and you know that the average response time is approximately 100ms. Your Rails app can therefore handle 10QPS using a single process (you can do 10 queries at 100ms in a second).</p>

<p>But what happens if your application gets more than 10 requests per second? Well, it's simple, the requests will be backed up and will take longer until some start timing out. This is why you want to improve your concurrency. There are different ways to do that, a lot of people feel really strong about these different solutions but they often forget to explain why they dislike one solution or prefer one over the other. You might have heard people conclusions which are often one of these: <a href="http://canrailsscale.com/">Rails can't scale</a>, you only get concurrency with <a href="http://jruby.org/">JRuby</a>, <a href="http://adam.heroku.com/past/2009/8/13/threads_suck/">threads suck</a>, the only way to concurrency is via threads, we should switch to <a href="http://www.erlang.org/">Erlang</a>/<a href="http://nodejs.org/">Node.js</a>/<a href="http://www.scala-lang.org/">Scala</a>, use<a href="http://www.rubyinside.com/fibers-eventmachine-rack-performance-gains-3395.html"> fibers</a> and you will be fine, add more machines, <a href="http://tomayko.com/writings/unicorn-is-unix">forking > threading</a>.  Depending on who said what and how often you heard it on twitter, conferences, blog posts, you might start believing what others are saying. But do you really understand why people are saying that and are you sure they are right?</p>

<p>The truth is that this is a complicated matter. The good news is that it's not <em>THAT</em> complicated!</p>

<p>The thing to keep in mind is that the concurrency models are often defined by the programming language you use. In the case of Java, <a href="http://download.oracle.com/javase/tutorial/essential/concurrency/index.html">threading is the usual solution</a>, if you want your Java app to be more concurrent, just run every single request in its own thread and you will be fine (kinda). In PHP, you simply don't have threads, instead you will start a new process per request. Both have pros and cons, the advantage of the Java threaded approach is that the memory is shared between the threads so you are saving in memory (and startup time), each thread can easily talk to each other via the shared memory. The advantage of PHP is that you don't have to worry about locks, deadlocks, threadsafe code and all that mess hidden behind threads. Described like that it looks pretty simple, but you might wonder why PHP doesn't have threads and why Java developers don't prefer starting multiple processes. The answer is probably related to the language design decisions. PHP is a language designed for the web and for short lived processes. PHP code should be fast to load and not use too much memory. Java code is slower to boot and to warm up, it usually uses quite a lot of memory. Finally, Java is a general purpose programming language not designed primarily for the internet. Others programming languages like <a href="http://www.erlang.org/">Erlang</a> and <a href="http://www.scala-lang.org/">Scala</a> use a third approach: <a href="http://en.wikipedia.org/wiki/Actor_model">the actor model</a>. The actor model is somewhat a bit of a mix of both solutions, the difference is that actors are a like threads which don't share the same memory context. Communication between actors is done via exchanged messages ensuring that each actor handles its own state and therefore avoiding corrupt data (two threads can modify the same data at the same time, but an actor can't receive two messages at the exact same time). We'll talk about that design pattern later on, so don't worry if you are confused.</p>

<p>What about Ruby? Should Ruby developers use threads, multiple processes, actors, something else? The answer is: <strong>yes</strong>!</p>

<h2>Threads</h2>

<p>Since version 1.9, Ruby has native threads (before that <a href="http://en.wikipedia.org/wiki/Green_threads">green threads</a> were used). So in theory, if we would like to, we should be able to use threads everywhere like most Java developers do. Well, that's almost true, the problem is that Ruby, like Python uses a <a href="http://en.wikipedia.org/wiki/Global_Interpreter_Lock">Global Interpreter Lock</a> (aka GIL). This GIL is a locking mechanism that is meant to protect your data integrity. The GIL only allows data to be modified by one thread at time and therefore doesn't let threads corrupt data but also it doesn't allow them to truly run concurrently. That is why some people say that Ruby and Python are not capable of (true) concurrency.</p>

<p><img src="https://img.skitch.com/20110223-kk58iq5yjdpmyswf7nuya4c4kp.jpg" alt="Global Interpreter Lock by Matt Aimonetti" /></p>

<p>However these people often don't mention that the GIL makes single threaded programs faster, that multi-threaded programs are much easier to develop since the data structures are safe and finally that a lot of C extensions are not thread safe and without the GIL, these C extensions don't behave properly. These arguments don't convince everyone and that's why you will hear some people say you should look at another Ruby implementation without a GIL, such as <a href="http://jruby.org/">JRuby</a>, <a href="http://rubini.us/">Rubinius</a> (hydra branch) or <a href="http://macruby.org">MacRuby</a> (Rubinius &amp; MacRuby also offer other concurrency approaches). If you are using an implementation without a GIL, then using threads in Ruby has exactly the same pros/cons than doing so in Java. However, it means that now you have to deal with the nightmare of threads: making sure your data is safe, doesn't deadlock, check that your code, your libs, plugins and gems are thread safe. Also, running too many threads might affect the performance because your OS doesn't have enough resources to allocate and it ends up spending its time context switching. It's up to you to see if it's worth it for your project.</p>

<h2>Multiple processes &amp; forking</h2>

<p>That's the most commonly used solution to gain concurrency when using Ruby and Python. Because the default language implementation isn't capable of true concurrency or because you want to avoid the challenges of thread programming, you might want to just start more processes. That's really easy as long as you don't want to share states between running processes. If you wanted to do so, you would need to use <a href="http://segment7.net/projects/ruby/drb/introduction.html">DRb</a>, a message bus like <a href="http://www.rabbitmq.com/">RabbitMQ</a>, or a shared data store like memcached or a DB. The caveat is that you now need to use a LOT more memory. If want to run 5 Rails processes and your app uses 100Mb you will now need 500Mb, ouch that's a lot of memory! That is exactly what happens when you use a Rails webserver like Mongrel. Now some other servers like <a href="http://www.modrails.com/">Passenger</a> and <a href="http://unicorn.bogomips.org/">Unicorn</a> found a workaround, they rely on <a href="http://en.wikipedia.org/wiki/Fork_%28operating_system%29">unix forking</a>. The advantage of forking in an unix environment implementing the copy-on-write semantics is that we create a new copy of the main process but they both "share" the same physical memory. However, each process can modify its own memory without affecting the other processes. So now, Passenger can load your 100Mb Rails app in a process, then fork this process 5 times and the total footprint will be just a bit more than 100Mb and you can now handle 5X more concurrent requests. Note that if you are allocating memory in your request processing code (read controller/view) your overall memory will grow but you can still run many more processes before running out of memory. This approach is appealing because really easy and pretty safe. If a forked process acts up or leaks memory, just destroy it and create a new fork from the master process. Note that this approach is also used in <a href="https://github.com/defunkt/resque">Resque</a>, the async job processing solution by <a href="http://github.com">GitHub</a>.</p>

<p>This solution works well if you want to duplicate a full process like a webserver, however it gets less interesting when you just want to execute some code "in the background". Resque took this approach because by nature async jobs can yield weird results, leak memory or hang. Dealing with forks allows for an external control of the processes and the cost of the fork isn't a big deal since we are already in an async processing approach.</p>

<p><img src="http://s3.amazonaws.com/cogit8-org/img/hardcore-forking-action.png" alt="" /></p>

<h2>Actors/Fibers</h2>

<p>Earlier we talked a bit about the <a href="http://en.wikipedia.org/wiki/Actor_model">actor model</a>. Since Ruby 1.9, developers now have access to a new type of "lightweight" threads called <a href="http://www.ruby-doc.org/core-1.9/classes/Fiber.html">Fibers</a>. Fibers are not actors and Ruby doesn't have a native Actor model implementation but some people wrote <a href="http://doc.revactor.org/files/README.html">some actor libs</a> on top of fibers. A fiber is like a simplified thread which isn't scheduled by the VM but by the programmer. Fibers are like blocks which can be paused and resumed from the outside of from within themselves. Fibers are faster and use less memory than threads as demonstrated in <a href="http://oldmoe.blogspot.com/2008/08/ruby-fibers-vs-ruby-threads.html">this blog post</a>. However, because of the GIL, you still cannot truly run more than one concurrent fiber by thread and if you want to use multiple CPU cores, you will need to run fibers within more than one thread. So how do fibers help with concurrency? The answer is that they are part of a bigger solution. Fiber allow developers to manually control the scheduling of "concurrent" code but also to have the code within the fiber to auto schedule itself. That's pretty big because now you can wrap an incoming web request in its own fiber and tell it to send a response back when it's done doing its things. In the meantime, you can move on the to next incoming request. Whenever a request within a fiber is done, it will automatically resume itself and be returned. Sounds great right? Well, the only problem is that if you are doing any type of blocking IO in a fiber, the entire thread is blocked and the other fibers aren't running. Blocking operations are operations like database/memcached queries, http requests... basically things you are probably triggering from your controllers. The good news is that the "only" problem to fix now is to avoid blocking IOs. Let's see how to do that.</p>

<p><img src="https://img.skitch.com/20110223-8wkfs2g12p15ku18rm7aq9negf.jpg" alt="fiber" /></p>

<h2>Non blocking IOs/Reactor pattern.</h2>

<p>The reactor pattern is quite simple to understand really. The heavy work of making blocking IO calls is delegated to an external service (reactor) which can receive concurrent requests. The service handler (reactor) is given callback methods to trigger asynchronously based on the type of response received. Let me take a limited analogy to hopefully explain the design better. It's a bit like if you were asking someone a hard question, the person will take a while to reply but his/her reply will make you decide if you raise a flag or not. You have two options, or you choose to wait for the response and decide to raise the flag based on the response, or your flag logic is already defined and you tell the person what to do based on their answer and move on without having to worry about waiting for the answer. The second approach is exactly what the reactor pattern is. It's obviously slightly more complicated but the key concept is that it allows your code to define methods/blocks to be called based on the response which will come later on.</p>

<p><img src="https://img.skitch.com/20110223-xkit6utnty1sdt84n15w7dgtnh.jpg" alt="Reactor from Matt Aimonetti's blog" /></p>

<p>In the case of a single threaded webserver that's quite important. When a request comes in and your code makes a DB query, you are blocking any other requests from being processed. To avoid that, we could wrap our request in a fiber, trigger an async DB call and pause the fiber so another request can get processed as we are waiting for the DB. Once the DB query comes back, it wakes up the fiber it was trigger from, which then sends the response back to the client. Technically, the server can still only send one response at a time, but now fibers can run in parallel and don't block the main tread by doing blocking IOs (since it's done by the reactor).</p>

<p>This is the approach used by <a href="http://twistedmatrix.com/trac/">Twisted</a>, <a href="http://eventmachine.rubyforge.org/EventMachine/Deferrable.html">EventMachine</a> and <a href="http://nodejs.org/">Node.js</a>. Ruby developers can use EventMachine or an EventMachine based webserver like <a href="http://code.macournoyer.com/thin/">Thin</a> as well as <a href="https://github.com/igrigorik/em-synchrony">EM clients/drivers</a> to make non blocking async calls. Mix that with some Fiber love and you get Ruby concurrency. Be careful though, using Thin, non blocking drivers and Rails in threadsafe mode doesn't mean you are doing concurrent requests. Thin/EM only use one thread and you need to let it know that it's ok to handle the next request as we are waiting. This is done by <a href="http://eventmachine.rubyforge.org/EventMachine/Deferrable.html">deferring the response</a> and let the reactor know about it.</p>

<p>The obvious problem with this approach is that it forces you to change the way you write code. You now need to set a bunch of callbacks, understand the Fiber syntax, and use deferrable responses, I have to admit that this is kind of a pain. If you look at some Node.js code, you will see that it's not always an <a href="http://howtonode.org/control-flow-part-ii/file-write.js">elegant approach</a>. The good news tho, is that this process can be wrapped and your code can be written as it if was processed synchronously while being handled asynchronously under the covers. This is a bit more complex to explain without showing code, so this will be the topic of a future post. But I do believe that things will get much easier soon enough.</p>

<h2>Conclusion</h2>

<p>High concurrency with Ruby is doable and done by many. However, it could made easier. Ruby 1.9 gave us fibers which allow for a more granular control over the concurrency scheduling, combined with non-blocking IO, high concurrency can be achieved. There is also the easy solution of forking a running process to multiply the processing power. However the real question behind this heated debate is what is the future of the Global Interpreter Lock in Ruby, should we remove it to improve concurrency at the cost of dealing with some new major threading issues, unsafe C extensions, etc..? Alternative Ruby implementers seem to believe so, but at the same time Rails still ships with a default mutex lock only allowing requests to be processed one at a time, the reason given being that a lot of people using Rails don't write thread safe code and a lot of plugins are not threadsafe. Is the future of concurrency something more like <a href="http://libdispatch.macosforge.org/">libdispatch</a>/<a href="http://www.macruby.org/documentation/gcd.html">GCD</a> where the threads are handled by the kernel and the developer only deals with a simpler/safer API?</p>

<p>Further reading:</p>

<ul>
<li><p><a href="http://www.igvita.com/2008/11/13/concurrency-is-a-myth-in-ruby/">Concurrency is a myth in Ruby</a></p></li>
<li><p><a href="http://oldmoe.blogspot.com/2008/08/ruby-fibers-vs-ruby-threads.html">Ruby fibers vs Ruby threads</a></p></li>
<li><p><a href="http://www.igvita.com/2010/08/18/multi-core-threads-message-passing/">Multi-core, threads, passing messages</a></p></li>
<li><p><a href="http://adam.heroku.com/past/2009/8/13/threads_suck/">Threads suck</a></p></li>
<li><p><a href="http://www.igvita.com/2010/04/15/non-blocking-activerecord-rails/">Non blocking Active Record and Rails</a></p></li>
<li><p><a href="http://www.mikeperham.com/2010/01/27/scalable-ruby-processing-with-eventmachine/">Scalable Ruby processing with EventMachine</a></p></li>
<li><p><a href="http://on-ruby.blogspot.com/2008/01/ruby-concurrency-with-actors.html">Ruby concurrency with actors</a></p></li>
<li><p><a href="http://www.engineyard.com/blog/2010/concurrency-real-and-imagined-in-mri-threads/">Concurrency in MRI; threads</a></p></li>
<li><p><a href="http://www.infoq.com/news/2007/08/ruby-1-9-fibers">Ruby 1.9 adds fibers for lightweight concurrency</a></p></li>
<li><p><a href="http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/">Threads in Ruby, enough already</a></p></li>
<li><p><a href="http://www.igvita.com/2010/03/22/untangling-evented-code-with-ruby-fibers">Untangling Evented Code with Ruby Fibers</a></p></li>
<li><p><a href="http://www.slideshare.net/ehuard/concurrency-5615029">Elise Huard's RubyConf Concurrency talk slides</a></p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Automatically generating BridgeSupport files]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/02/19/bridgesupport-build/"/>
    <updated>2011-02-19T16:29:07-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/02/19/bridgesupport-build</id>
    <content type="html"><![CDATA[<p>Today I was helping someone write an Objective-C framework around <a href="http://cocos2d.org/">cocos2d</a>.</p>

<p>C/Objective-C code can be called directly from MacRuby. However the Obj-C code you would like to use might be using some ANSI C symbols that are non-object-oriented items such as constants, enumerations, structures, and functions. To make these items available to our MacRuby code, you need to generate a <a href="http://ofps.oreilly.com/titles/9781449380373/ch03.html#_using_objective_c_or_c_code">BridgeSupport file as explained in this section of my book</a>.</p>

<p>In our case, we were working on the framework and I didn't feel like manually having to regenerate the BridgeSupport file every single time I would compile our code. So instead I added a new build phase in our target.</p>

<p>[caption id="" align="aligncenter" width="741" caption="Adding a new step to our build"]<a href="https://img.skitch.com/20110220-b685ag2cef8qm69uwn73e3equ4.png"><img src="https://img.skitch.com/20110220-b685ag2cef8qm69uwn73e3equ4.png" alt="" /></a>[/caption]</p>

<p>And I added the following script to run at the end of the build:</p>

<p>`</p>

<h1>This step generated the bridgesupport file for the framework</h1>

<p>PATH="$PATH:/usr/local/bin"
mkdir -p $TARGET_BUILD_DIR/$PROJECT_NAME.framework/Resources/BridgeSupport/
gen_bridge_metadata --64-bit -f $TARGET_BUILD_DIR/$PROJECT_NAME.framework/ -o $TARGET_BUILD_DIR/$PROJECT_NAME.framework/Resources/BridgeSupport/$PROJECT_NAME.bridgesupport
`</p>

<p>Th<code>e script just executes the steps required to add the BridgeSupport file to your framework. I can now rebuild my framework without having to worry about BridgeSupport.
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Designing for scalability]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/01/31/designing-for-scalability/"/>
    <updated>2011-01-31T13:30:55-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/01/31/designing-for-scalability</id>
    <content type="html"><![CDATA[<p>Designing beautiful and scalable software is hard. Really hard.</p>

<p>It's hard for many reasons. But what makes it even harder is that software scalability is a relatively new challenge, something only really done in big companies, companies that are not really keen on sharing their knowledge. The amount of academic work done on software design is quite limited compared to other types of design, but shared knowledge about scalable design is almost nonexistent <em>(Don't expect to find detailed information about scaling online video games either, the industry is super secretive. And even if this is a niche market where finding skilled/experienced developers is really challenging, information is not shared outside a game project).</em></p>

<p>I don't pretend to have the required knowledge to cover this topic at length. However, I do have some exposure and figured I should share what I learned so others can benefit from my experience and push the discussion further.</p>

<p>Designing scalable software is just like any other type of software design, with a few unique constraints. If I had to define the key requirements of a great design I would have to quote Frederick P. Brooks:</p>

<blockquote><p>"Great designs have conceptual integrity - unity, economy, clarity"</p></blockquote>

<p>This is true for any type of design and one should always start by that.
Don't just jump on your keyboard and start writing tests/code right away. Take a minute to think about your design.
That will save you hours of refactoring and headaches.</p>

<h2>You're a designer and might not even know it</h2>

<p>You might not be designing the next NASA engine but you are more than likely designing an API that you and others will use. As a matter of fact, unless you write code that will never be seen again, you are writing an Application Programming Interface (API). Every single class, method, function you write is an API that you and others will use. Remember that every time you write code, you are the implementer of a design, and therefore you are a designer.</p>

<p>[caption id="attachment_916" align="alignright" width="150" caption="Giana and I, discussing design patterns"]<a href="http://merbist.com/2011/01/31/designing-for-scalability/giana_and_moi_lowres/"><img src="http://merbist.com/wp-content/uploads/2011/01/giana_and_moi_lowres-150x150.jpg" alt="Giana and Matt Aimonetti" /></a>[/caption]</p>

<p>When thinking about your design, focus on design concepts instead of implementation details. A design concept must be clear, simple to both explain with words and draw on a whiteboard. If you can't draw and explain your design on a whiteboard, you have failed one of the great design requirement: clarity. If you work alone, or your coworkers are tired of hearing you, try rubber ducking your design ideas. It's the same concept as rubber ducking debugging, where a programmer would force himself to explain his code, line-by-line, to a rubber duck on his desk but instead of talking about the code, explain your design and why it's awesome (I've recently done this with my baby girl and it's been really helpful).</p>

<h2>Keeping the design integrity</h2>

<p>One of the challenges of designing scalable software is that your constraints are often very unique to your product. Off the shelf solutions don't work for you, and the specific solution used by another project can't be transposed to your project because the cause and the effect of what you need to scale are different. The problem is that you really quickly lose design integrity.</p>

<p>Let's take a look at a concrete example to see how the design integrity can be lost or even not defined at all.
Let's pretend we want to write a suite of web APIs for video games.</p>

<p>We can look at this task from different perspectives:<a href="http://merbist.com/2011/01/31/designing-for-scalability/the-shout-2/"><img src="http://merbist.com/wp-content/uploads/2011/01/the-shout1-150x150.jpg" alt="the shout posted by Matt Aimonetti" /></a></p>

<ul>
<li><p>Video game deadlines are crazy, let's find a way to release as many APIs ASAP.</p></li>
<li><p>We're going to get a huge amount of traffic, let's make sure we don't crash and burn.</p></li>
<li><p>We need to make sure our APIs are simple to use for the dev teams integrating them.</p></li>
</ul>


<p>Each of these perspectives reflects a facet of the challenge. Other facets exist that I didn't mention but that a business person might have listed right away, one of which being: How can we do that for the least amount of money?</p>

<p>To design our API suite, we first need to understand the different perspectives. Gaining this understanding will help us design something better but it will also help us communicate better with the different stakeholders. Once we have a decent understanding of the constraints and expectations, someone needs to explicitly define the design values and their priorities. This is a crucial step in the design process. Systems nowadays are too complicated to be handled by only one person and keeping design integrity requires clear communication.</p>

<h2>Design goal and values</h2>

<p>The best way to communicate the design is to write a simple sentence defining the primary goal:
"Build a robust, efficient and flexible middleware solution leveraged by external teams to develop online video game features."</p>

<p>This is a bit like the mission statement of your project, or the elevator pitch you give someone that asks you what you are working on.</p>

<p>Associated with the primary goal are a host of desiderata, or secondary objectives. These are the key objectives used to weigh technical decisions. It's important for the design to highlight a scale of values so one can refer to them to decide if his/her idea fits the design or not. Here is an example:</p>

<ol>
<li><p>Stability</p></li>
<li><p>Performance / Scalability</p></li>
<li><p>Encapsulation / Modularity</p></li>
<li><p>Conventions</p></li>
<li><p>Documentation</p></li>
<li><p>Reusability / Maintainability</p></li>
</ol>


<p>Often these desiderata are applied to most of your projects and reflect your team/company's technical values. The list might seem simple and unnecessary but, believe me, it will reduce the arguments where John tells Jane that her idea sucks but his is better because he "knows better". Having an objective reference to refer to when trying to decide which is the best way to go is greatly valuable and will reduce the amount of office drama.</p>

<h2>Constraints</h2>

<p>Finally, make sure to explicitly define all the major constraints and to acknowledge the team's concerns. Here is a small example of what could be listed (which also reflect the previously mentioned perspectives):</p>

<ul>
<li><p>hard deadlines</p></li>
<li><p>external teams involved</p></li>
<li><p>huge load expected</p></li>
<li><p>limited support available</p></li>
<li><p>requirements changing quickly</p></li>
<li><p>limited budget</p></li>
<li><p>unknown hosting architecture/constraints</p></li>
<li><p>...</p></li>
</ul>


<p>Remember that design is always iterative because the constraints keep changing. That's just the way it is and a lot of technical constraints only appear as you implement or test your design. That's also why the design needs to be clear but the implementation needs to be flexible.</p>

<h2>Reads vs writes</h2>

<p>Most of the web apps out there are read heavy, meaning that the stored data gets more accessed than modified. Scaling these type of systems is easier as one can introduce a cache layer, an intermediary storage, which acts as a fast buffer that avoids putting load on the backends. The cost reduction is huge because if you architected your app properly, the data is read from the data store only once (or once every X minutes) after being created/modified.</p>

<p>Caching is so important that it's even built into the HTTP protocol, making caching trivial.
Speaking of HTTP, a common problem I often see when serving http content to a browser is that even though the backend calls are the same, some information needs to be customized for the current visitor. This prevents it from caching the entire page. An easy solution in this case is to still cache the entire page but to use javascript to fetch the custom data from the backend and to modify the cached http at the client's browser level directly. As part of your design, you will more than likely need to implement multiple layers of caching and use technologies such as query caching, Varnish, Squid, Memcached, memoization, etc...</p>

<p>The problem is that, as your system gets more traffic, you will notice that the volume of DB/network writes becomes your bottleneck. You will also notice a reduction of your cache/hit ratio because only a small part of your cached data is often retrieved by many clients. At this point, you will need to denormalize to avoid contention, shard your data in silos, or write to cache and flush from cache when the data store is available and not overwhelmed.</p>

<h2>Asynchronous processing</h2>

<p>One way to avoid write contention is to use async processing. The concept is simple. Instead of directly writing to your datastore after your backend receives a request, you put a message in a queue with all the information needed to run the operation later. On the other side, you have a set number of workers receiving messages and operating on them one after the other.</p>

<p>The advantage of such an approach is that you control the amount of workers and therefore the amount of maximum concurrent writes to your datastore. You can also process the queue before it gets worked and and maybe coalesce some messages or remove outdated/duplicated message. Finally, you can assign more workers to some message types, making sure the important messages get processed first.</p>

<p>Another advantage of this design includes not letting the client hang while you're processing the data and potentially timeout. You can also process a long queue faster by starting more workers to catch up and retire them later.
You app is more resilient to errors and failed async jobs can be restarted.</p>

<h2>Load test, monitor and be proactive</h2>

<p>Even the best designs have weak spots and will have to be improved once they are released. Don't wait for your system to fall apart before looking for solutions. Monitor your app. Every single part of your app. Look for patterns showing signs of potential problems and imagine what you could do to resolve them if they would start manifesting.</p>

<p>Of course before getting there, you will need to understand each part of your system and benchmark/load test/profile your app so you can be ready to face the storm.</p>

<p>Benchmarks and load tests are both super important and, too often, not reflective of what you will really face later on. They are usually great at identifying major problems that should be resolved right away, but fail to show the one big problem you will see on day one when you have to deal with 20k concurrent requests. Use them as indicators, rely on your experience and learn about problems other have faced. This will help you build a knowledge of scalability challenges, their root causes, and their potential solutions.</p>

<p>For benchmarking Ruby code, I use the<a href="http://ruby-doc.org/stdlib/libdoc/benchmark/rdoc/classes/Benchmark.html"> built-in benchmark tool available in the standard lib</a>.
For simple load testing, I use <a href="http://www.hpl.hp.com/research/linux/httperf/">httperf</a>/<a href="http://www.xenoclast.org/autobench/">autobench</a> and <a href="http://freshmeat.net/projects/siege/">siege</a>.
For anything more complicated, I use <a href="http://jakarta.apache.org/jmeter/">JMeter</a>.
In the video game industry, we also often use sims using the client's code to create load.</p>

<p>Benchmarking without profiling is often useless. Unlike other programming languages, Ruby doesn't yet have awesome profiling tools easy to use, but things are evolving quickly. Here are some tools I use regularly.</p>

<p>The <a href="https://github.com/tmm1/perftools.rb">Ruby wrapper</a> around <a href="http://code.google.com/p/google-perftools/">google perftools</a> is really good.
Before using perftools as often as I do now, I frequently used <a href="http://ruby-prof.rubyforge.org/">ruby-prof</a> with <a href="http://kcachegrind.sourceforge.net/html/Home.html">kcachegrind</a>.
Ruby 1.9 lets you inspect its garbage collector as explained in a <a href="http://merbist.com/2010/07/29/object-allocation-why-you-should-care/">previous post</a>.
And when using <a href="http://macruby.org">MacRuby</a>, I often use <a href="http://en.wikipedia.org/wiki/DTrace">DTrace</a>.</p>

<h2>Other misc. things I learned</h2>

<h3>Documentation</h3>

<p>Documentation is critical. It doesn't matter how you do it but you need to make sure you document what you want to build, how you build it, and why you build it. Documenting will help you and the others working on the project, and will keep you in check. I have started documenting an API and then realized that the design was flawed. Maybe it's just the way you name a method, or a class, or it can be a weird method signature or even the entire workflow being wrong, but when you document things, design errors appear more obviously.</p>

<p>To document Ruby code, I use <a href="http://yardoc.org/">yard</a> which is quite similar to <a href="http://en.wikipedia.org/wiki/Javadoc">javadoc</a>. Code documentation, when writing <a href="http://en.wikipedia.org/wiki/Duck_typing">duck typed language</a>, is, for me, very important since it makes the API designer's expectations much clearer. I also often add English documentation, written in markdown files and compiled by yard. If you say that your code is simple and that it doesn't require documentation because anyone can just read it and understand ... then you have totally miss the point. Yes, it's more work to keep documentation and code in sync. But people using web APIs don't have access to the implementation details. The people distributing compiled APIs don't give access to their implementation. And honestly, the API should be decoupled from the implementation. I shouldn't have to guess how to use your API based on how you implemented the code underneath, otherwise my assumptions might be totally wrong.</p>

<h3>Simplicity</h3>

<p>With great power comes great responsibility. The law of system entropy says that systems become more disorganized over time, so don't start with complicated code if you can avoid it! It's not because your programming language lets you do crazy stuff that you have to use it. In 90+% of the time, your code can be written without voodoo and be easier to read, easier to understand, easier to maintain and faster to execute.</p>

<p>If you can't figure out how to <strong><em>not</em></strong> use metaprogramming or weird patterns, take a step back and look at your design, did you miss something?
Also, don't reinvent the wheel. Use the language the way it was designed to be used. Keep your APIs as small as possible, don't expose too much as it will be virtually impossible to remove it later on.</p>

<p>As an example, look to what extent Rails modified the Ruby language:</p>

<p>In Rails' console (Rails 2, Ruby 1.8.7)</p>

<pre><code>&gt;&gt; Array.ancestors
=&gt; [Array, ActiveSupport::CoreExtensions::Array::RandomAccess,
 ActiveSupport::CoreExtensions::Array::Grouping, ActiveSupport::CoreExtensions::Array::ExtractOptions,
 ActiveSupport::CoreExtensions::Array::Conversions, ActiveSupport::CoreExtensions::Array::Access,
 Enumerable, Object, ERB::Util, ActiveSupport::Dependencies::Loadable, Base64::Deprecated, Base64,
 Kernel]
&gt;&gt; [].methods.size
=&gt; 233
</code></pre>

<p>In irb:</p>

<pre><code>&gt;&gt; Array.ancestors
=&gt; [Array, Enumerable, Object, Kernel]
&gt;&gt; [].methods.size
=&gt; 149
</code></pre>

<p>Removing any of these added methods is virtually impossible since some piece of code somewhere might rely on it.</p>

<h3>Abstraction &amp; its dangers</h3>

<p>Often when designing an API, it's preferable to offer a well defined  public API which will delegate the work to a private implementation shared between  multiple public APIs. This approach avoids duplication, makes maintenance easy, and  allows for more flexibility. As an example, we can have a public  matchmaking API which will delegate most of the work to a private  matchmaking interface. If required, swapping the private interface would be  totally transparent to the public API. This approach has a downside, however. Having a shared private implementation does create a duplication of APIs. It leaves us with both a public and a private API because we need an API for public access and a private API for the public API to connect to. But when we weigh the  benefits and look at what is duplicated, we realize that this trade off  is worth it.</p>

<p>Keeping a certain level of abstraction is important to maintaining the separation of concerns as clear as possible. You want to layer your design so that each  layer is responsible for itself, only knows about itself, and has limited  interactions with other layers. By factoring/isolating the different  modules, you can keep a simple, elegant, easy to maintain system. This  is a key element of design but one needs to be careful not to obfuscate  the design by over abstracting his/her code. This is particularly important when designing a scalable app because you will often need to be able to easily swap parts  to optimize each part of your system.</p>

<p>That said, a lot of code out there is unnecessarily complicated. I sometime wonder if the authors of such code try to show that they know some cool language tricks. Or maybe this is due to the fact that, too often, people are impressed by code they don't understand. The problem with overly complicated or magical code is that it creates yet another abstraction layer between the end user and API. It makes the API more opaque, and that's a cost you have to take into consideration. Every time you abstract something you have a cost associated with the abstraction. This cost can be calculated in terms of performance loss, clarity loss and maintainability cost.</p>

<p>This is exactly the same problem encountered when trying to normalize data in a database.
Normalizing is a great concept which makes a lot of sense ... until you realize that the cost of keeping your data normalized is too great and it becomes a major bottleneck, not letting you scale your application.
At this moment (and probably only then) that you need to denormalize your data.</p>

<p>It's the same thing with code abstraction. It's fine to abstract, unless the abstraction is such that it requires too much work to understand what is going on. A bit of duplication is often worth it, but be careful to not abuse it.</p>

<h3>Debugging</h3>

<p>Ruby has a decent debugger called <a href="http://bashdb.sourceforge.net/ruby-debug.html">ruby-debug</a> and I'm amazed by the amount of people who haven't heard about it.
I don't know what I would do if I couldn't use breakpoints and get an interactive shell to debug Ruby code.
Please people! This is 2011, stop using print statement as a means of debugging!</p>

<h2>Conclusion</h2>

<p>That's is for this post. It was longer than expected and I feel I didn't really cover anything in depth, but hopefully you learned something new or at least read something that piqued your interest. I look forward to reading your comments and, hopefully, your blog posts sharing your experience in designing scalable software.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Causality of scalability]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/01/18/causality-of-scalability/"/>
    <updated>2011-01-18T08:00:42-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/01/18/causality-of-scalability</id>
    <content type="html"><![CDATA[<p>Part of my job at <a href="http://us.playstation.com/">Sony PlayStation</a> is to architect scalable systems which can handle a horde of excited players eager to be the first to play the latest awesome game and who would play for 14-24 hours straight. In other words, I need to make sure a system can "scale". In my case, a scalable system is a system that can go from a few hundred concurrent users/players to hundreds of thousands of concurrent users/players and stay stable for months.</p>

<p>One can achieve scalability in many ways, and if you expect me to provide you with a magical formula you will be disappointed. I actually believe that you can scale almost anything if you have the adequate resources. So saying that X or Y doesn't scale is for me a sign that people are taking shortcuts in their explanations (X or Y are really hard to scale so they don't scale) or that they don't understand the causality of scaling. However what I am exploring in this post is the relationship between cause and effect when trying to make a system scalable. We will see that the scalability challenge is not new and not exclusive to the tech world. We will study the traditional approach to scaling and as well as the challenge of scaling in relation to the web and what to be aware of when planning to make a solution scalable.</p>

<h2>Scaling outside of the tech world</h2>

<p>Trying to scale isn't new. It goes back to well before technology was invented. Scaling something up or increasing something in size or number is a goal businesses have aimed for ever since the oldest profession in the world was invented. <img src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/49/EN_BESKYTTERINDE_AF_INDUSTRIEN.gif/180px-EN_BESKYTTERINDE_AF_INDUSTRIEN.gif" alt="" />A prostitute wanting to scale up her business was limited by her own time and body. She would reach a point where she couldn't take more clients. (Independent contractors surely know what I am talking about!) So a prostitute wanting to scale up would usually become a madam/Mama-san and scale the business by having girls work for her.</p>

<p>Another simple example would be a restaurant. A restaurant can handle up to a certain amount of covers/clients at once, after that, customers have to wait in line. The restaurant example is interesting because you can clearly see that opening a huge restaurant with a capacity of 1,000 covers might not be a good idea. First because the cost of running such a restaurant might be much more than the income generated. But also because even though the restaurant does 1,000 covers at peak time, it doesn't mean that the restaurant will stay that busy during the entire time it's open. So now you have to deal with waiter/waitresses, busboys and other staff who won't have anything to do. As you probably have understood already, scaling a restaurant means that the scaling has to be done in a cost effective manner.  And what's even more interesting is that what we could have thought was the bottleneck (the amount of concurrent covers) can be easily scaled up but it wouldn't provide real scalability. In fact this choice would cascade into other areas of management like staffing and the building size. Often, the scaling solution for restaurants is to open new locations which can result in keeping the lines shorter, targeting new markets and reducing risks since one failing branch won't dramatically affect the others.</p>

<p><img src="http://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Nighthawks.jpg/400px-Nighthawks.jpg" alt="posted by Matt Aimonetti" /></p>

<h2>Scaling in the traditional tech world</h2>

<p>If you've ever done console development or worked on embedded devices, you know that they are restricted by some key elements. <img src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/PS3Versions.png/220px-PS3Versions.png" alt="posted by Matt Aimonetti" />It can be memory, CPU, hard drive space etc... You have to "cram" as many features as you can into the device, working around the fixed limitations of the hardware. In the console industry, what's interesting to note is that the hardware doesn't change often but people expect than a new game on the same platform will do things better than the previous game, even though the limitations are exactly the same. This is quite a challenging problem because you have to fight against the hardware limitations by optimizing your code to be super efficient. That's exactly the reason why console video game developers manage memory manually instead of relying on a garbage collector. This way they can squeeze every resource they can from the console.</p>

<p>The great advantage of this type of development is that you can reproduce and accurately anticipate issues. The bottlenecks/limitations are well known and immutable! If you find a way around in your lab, you know that the solution will work for everyone. Console video game developers (and to some extent, iOS developers) don't have to wonder how their game will behave if the player has an old graphic card or not enough RAM.</p>

<p>But ever since we started distributing the processing power, scaling technology has become more challenging.</p>

<h2>Scaling on the web</h2>

<p>Scaling a web based solution might actually seem quite like scaling a restaurant, except that you can't easily open multiple locations since the concept of proximity in web browsing isn't really as concrete as in real life. So the solution can't be directly transposed. Most people will only have to scale up by optimizing their code running on one server, or maybe two. That's because their service/app is not, and won't be, generating high traffic. Scaling such systems is common and one can rely on work done in the past decades for good examples of solutions.</p>

<p>However some web apps/games are or will become high traffic. But because every single entrepreneur I've met believes that their solution will be high traffic, they think they need to be able to scale and therefore should be engineered like that from the beginning. (This is, by the way, the reason scalability is a buzzword and you can sell almost anything technical saying that it scales.) The problem with this approach is that people want scalability but don't understand its causality. In other words, they don't understand the relationship between cause and effect related to making a solution scalable.</p>

<p>Basically we can reduce the concept of causality of scalability to something like this: you change a piece of the architecture to handle more traffic, but this part has an effect on other parts that also need to change and the pursuit of scalability almost never ends (just ask Google). <strong>Making a system scalable needs to have well a defined cause and expected effect, otherwise it's a waste</strong>. In other words, the effect of scaling engenders the need for solutions which themselves have complex effects on a lot of aspects of a system. Let's make it clearer by looking at a simple example:</p>

<p><a href="http://merbist.com/2011/01/18/causality-of-scalability/simplestarchitecture/"><img src="http://merbist.com/wp-content/uploads/2011/01/simplestarchitecture-300x269.png" alt="Simple Architecture by Matt Aimonetti" /></a>We have an e-commerce website and this website uses a web application with a database to store products and transactions. Your system is made of 1 webserver handling the requests and one database storing the data. Everything goes well until Black Friday, Christmas or Mother's Day arrives and now some customers are complaining that they can't access your website or that it's too slow. This is also sometimes referred to as the digg/slashdot/reddit effect. All of a sudden you have a peak of traffic and your website can't handle it. This is actually a very simple use case, but that's also the only use case most people on the web need to worry about.</p>

<p>The causality of wanting this solution to scale is simple, you want to scale so you can sell more and have happy customers. The effect is that the system needs to become more complex.</p>

<p>To scale such a system, you need to find the root cause of the problem. You might have a few issues, but start by focusing on the main one. In this case, it's more than likely that your webserver (frontend) cannot handle more than x requests/second. Interestingly enough, the amount of reqs/s might not match the result of your load tests. That's probably because you didn't expect the usage pattern that you are seeing, but that's a whole different topic. At this point you need to understand why you can't go above the x reqs/s limit you're hitting. Where is the bottleneck? Is it that your application code is too slow? Is it the database has been brought to its knees? Or maybe the webserver serves as many requests as technically possible but it's still not enough based on the traffic you are getting.</p>

<p>If we stop right here, we can see that the reasons why the solution doesn't scale can be multiple. But what's even more interesting is that the root cause this time depends on the usage pattern and that it is really hard to anticipate all patterns. If we wanted to make this system scale we could do it different ways.</p>

<p>To give you some canned answers, if the bottleneck is that your code is too slow, you should check if the code is slow because of the DB queries made (too many, slow queries etc..). Is it slow because you are doing something complex that can't be easily improved or is it because you are relying on solutions that are known to not support concurrent traffic easily? More than likely, you will end up going for the easy caching approach. By caching some data (full responses, chunk of data, partial responses etc..) you avoid hitting your application layer and therefore can handle more traffic.</p>

<p>[caption id="attachment_879" align="aligncenter" width="300" caption="Caching avoids data processing &amp; DB access "]<a href="http://merbist.com/2011/01/18/causality-of-scalability/simplestarchitecture3/"><img src="http://merbist.com/wp-content/uploads/2011/01/simplestarchitecture3-300x201.png" alt="More complex Architecture by Matt Aimonetti" /></a>[/caption]</p>

<p>If your code is as fast as it can be, then a solution is to add more application servers or to async some processes. But now that means that you need to change the topology of your system, the way you deploy code and the way you route traffic. You will also increase the load on the database by opening more connections and maybe the database will now becoming the new bottleneck. You might also start seeing race conditions and you are certainly increasing the maintenance and complexity aka cost of your system (caching might end up having the same effect depending on the caching solution chosen).</p>

<p>[caption id="attachment_876" align="aligncenter" width="297" caption="One way of scaling it to load balance the traffic"]<a href="http://merbist.com/2011/01/18/causality-of-scalability/simplestarchitecture2/"><img src="http://merbist.com/wp-content/uploads/2011/01/simplestarchitecture2-297x300.png" alt="load balanced approach by Matt Aimonetti" /></a>[/caption]</p>

<p>Just looking at these possible causes and the various solutions (we didn't even mention DB replication, sharding, NoSQL etc..), we can clearly see that making a system scalable has some concrete effects on system complexity/maintenance which directly translate in cost increase.</p>

<p>If you are an engineer, you obviously want your system to be super scalable and handle millions of requests per second. But if you are a business person, you want to be realistic and evaluate the causality of not scaling after a certain point and convert that as loss. Then you weigh the cost of not scaling with the cost of "maybe" scaling and you make a decision.</p>

<p>The problem here though is that scaling is a bit like another buzzword: SEO (Search Engine Optimization). A lot of people/solutions will promise scaling capabilities without really understanding the big picture. Simple systems can easily scale up using simple solutions but only up to a certain level. After that, what you need to do to scale becomes so complex than anyone promising you the moon probably doesn't know what they are talking about. If there was a one-size-fits-all, easy solution for scaling, we would all be using it, from your brother for his blog, to Google without forgetting Amazon.</p>

<p><img src="http://awsmedia.s3.amazonaws.com/logo_aws.gif" alt="AWS logo posted by Matt Aimonetti" />Speaking of Amazon, I hear a lot of people saying that Amazon AWS services is "THE WAY" (i.e: the only way) to scale your applications. I agree that it's a compelling solution for a lot of cases but it's far from being a silver bullet. Remember that the cause and effect of why you need to scale are probably different than anyone else.</p>

<h2>Amazon Web Services</h2>

<p>Let me give you a very concrete example of where <a href="http://aws.amazon.com/">AWS services</a> might<em> not</em> be a good idea: high traffic sites with lots of database writes and low latency.</p>

<p><a href="http://zynga.com">Zynga</a>, the famous social game company behind Farmville, Mafia Wars etc., is using AWS and it seems that they might have found themselves in the same scenario as above<img src="http://www.zynga.com/img/logo.png" alt="" />. And that would be almost correct. Zynga games have huge traffic and they do a ton of DB writes. However I don't think they need low latency since their game clients are browsers and Flash clients and that their games are mainly async so they just need to be able to handle unstable latency. We'll see in a second how they manage to perform on the AWS cloud.</p>

<p>The major problem with AWS when you have a high traffic site is IO: IO reliability, IO latency, IO availability. By IO, I'm referring to network connection (internal/external) and disk access. Put differently, when you design your system and you know you are going to run on AWS, you need to take into consideration that your solution should survive with zero or limited IO because you will more than likely be IO bound. This means that your traditional design won't work because your database hard drive won't be available for 30s or will be totally saturated. You also need to have a super redundant system because you are going to randomly lose machines. Point number one, moving your existing application from a dedicated hosting solution to AWS might not help you scale if you didn't architect to be resilient to bad IO. Simply put, and to only pick one example: if you were expecting your database to be able to always properly write to disk you will have problems.</p>

<p>[caption id="" align="alignleft" width="184" caption="Octocat, the GitHub mascot"]<img src="http://tctechcrunch.files.wordpress.com/2010/07/github-logo.png" alt="" />[/caption]</p>

<p>The solution depends on how you want to look at it and where you are at in your project. You can go the <a href="http://highscalability.com/blog/2010/2/8/how-farmville-scales-to-harvest-75-million-players-a-month.html">Zynga route and design/redesign your entire architecture to be highly redundant, not rely on disk access</a> (everything is kept in memory and flushed to disk when available) and tolerate a certain % of data loss. Or you can go with the<a href="https://github.com/blog/493-github-is-moving-to-rackspace"> GitHub approach</a><a href="https://github.com/blog/493-github-is-moving-to-rackspace"> and mix dedicated hardware for IO and "cloud" front end servers all on the same network</a>. One solution isn't better than the other, they are just different and depend on your needs. <a href="http://github.com">GitHub</a> and <a href="http://www.zynga.com/">Zynga</a> both need to scale but they have different requirements.</p>

<p>When it comes to scaling, things are not black or white. To stay on the AWS topic, let's take another example: Amazon Relational Database Service (RDS). Earlier today, I was complaining on Twitter that RDS doesn't and probably won't let you use the <a href="http://yoshinorimatsunobu.blogspot.com/2010/10/using-mysql-as-nosql-story-for.html">MySQL HandlerSocket plugin</a> any time soon, even though it's been released for almost 6 months and used in prod by many. Then someone asked me if using this plugin would offset the scalability cost-saving. The quick and wrong answer  is yes. By using the plugin, you can potentially get rid of your Memcached servers, probably your Redis/MongoDB/CouchDB servers or whatever NoSQL solution you write and just keep the database servers you currently have. You might have to beef up your DB servers a bit but it would certainly be a huge cost reduction and your system would be simpler, easier to maintain and the data would be more consistent. Sounds good right? After all the biggest online social game company designed it and uses it.</p>

<p>The only problem is that RDS is an AWS service and like every AWS service, it suffers from poor IO. So, if you were deciding to not use RDS and run your own MySQL servers with the HandlerSocket plugin, it wouldn't bring you much improvement <em>(1)</em>. Actually, if you are already IO bound, it would make things worse, because you are centralizing your system around the most unreliable part of your architecture. Based on that premise, RDS won't support HandlerSocket because RDS runs on the same AWS architecture and has to deal with the same IO constraints. What's the solution, you might ask? Amazon already went through these scaling problems and they offer a custom, non-relational, data storage solution working around their own issues called SimpleDB. But why would they improve RDS and fix a really hard problem when they already offer an alternative solution? Easy. SimpleDB forces you to redesign your architecture to work with their custom solution and, guess what? You are now locked-in to that vendor!</p>

<p>So the answer is yes, you can offset scalability costs if you don't use AWS or any other providers with bad IO. Now you should look at the cost of moving away from AWS and see if it's worth it. How much of your code and of your system is vendor specific? Is that something you can easily change? The <a href="https://github.com/geemus/fog">fog library</a>, for instance, supports multiple cloud providers. Are you using something similar? Can you transition to that?  Can you easily deploy to another hosting company? (<a href="http://opscode.com/chef">Opscode chef</a> makes that task much easier) But if, for one reason or another, you have to stick with AWS/<other cloud provider>, make sure that the business people in charge understand the consequences and the cost related to that choice.</p>

<h2>Conclusion</h2>

<p>My point is not to tell you to not design a scalable solution, or not to use AWS, or that RDS sucks. My point is to show that making a system scale is hard and has some drastic effects that are not always obvious. There aren't any silver bullet solutions and you need to be really careful about the consequences (and costs) involved with trying to scale. Make sure it's worth it and you have a plan. Define measurable goals for your scalability even though it's really hard, don't try to scale to infinity and beyond, that won't work. Having to redesign later on to handle even more traffic, is a good problem to have, don't over engineer.</p>

<p>Finally, be careful to understand the consequences of your decisions. What seems to be an almost trivial scaling move such as moving your app from dedicated hosting to a specific cloud provider might end up getting you in a vendor lock in situation!</p>

<hr />

<p><em>1: I assume that you are IO bound. If you are not and your DB data fits in memory/cache, then HS on AWS is fine but if that's the case what's your bottleneck? ;)</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MacRuby book update]]></title>
    <link href="http://matt.aimonetti.net/posts/2011/01/15/macruby-book-update/"/>
    <updated>2011-01-15T11:48:05-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2011/01/15/macruby-book-update</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RubyConf 2010 - MacRuby: Why and How]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/11/12/rubyconf-2010-macruby-talk/"/>
    <updated>2010-11-12T16:00:51-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/11/12/rubyconf-2010-macruby-talk</id>
    <content type="html"><![CDATA[<h2>Description of the talk:</h2>

<p>This year I gave the traditional Apple's MacRuby talk at RubyConf.
My presentation focused on 2 axis:</p>

<ul>
<li>What's new since last RubyConf</li>
<li>Show some examples of how fun it is to hack with MacRuby</li>
</ul>


<h2>Video</h2>

<p><video width='640' height='360' preload='none' controls poster=' /images/matt_aimonetti_rubyconf2010.jpeg'><source src='http://cdn.confreaks.com/system/assets/datas/768/original/448-rubyconf2010-macruby-why-and-how-small.mp4' type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/></video></p>

<p>Other video formats are available <a href="http://www.confreaks.com/videos/448-rubyconf2010-macruby-why-and-how">here</a></p>

<h2>Slides</h2>

<script async class="speakerdeck-embed" data-id="4f90697149bc25001f023143" data-ratio="1.299492385786802" src="http://speakerdeck.com/assets/embed.js"></script>


<p><strong><a href="http://speakerdeck.com/u/matt_aimonetti/p/rubyconf-2010-macruby-why-and-how">Presentation slides available on Speakerdeck</a></strong></p>

<h2>Details of the talk content</h2>

<p>MacRuby is currently at version 0.7.1 and version 0.8 is in preparation.
Since last new a lot of things happened, here is a quick summary:</p>

<ul>
<li><p>Cocoa dev is now considered stable.  Apple gave its seal of approval, most of the bugs are fixed and it's currently used on production projects and some apps were even submitted to the Mac App Store.</p></li>
<li><p>Ahead of Time compilation. This is quite a major improvement with many repercussions. Being to compile your Ruby source code means faster boot time and source obfuscation. Two major things to consider when you want to ship a desktop app.</p></li>
<li><p>Debugger. MacRuby now ships with its own debugger. Of course you can still use GDB and DTrace, but MacRuby's debugger is really easy to use and very powerful.</p></li>
<li><p>Grand Central Dispatch support and wrapper API. Having to manage threads can be hard for both developers and for the machines having to run the developer code. GCD is an abstraction layer allowing developers to only focus on business logic without having to worry about the underlying details if you don't want to. The end result is an optimum use of all the cores available on a machine and truly concurrent code. Two important notions when writing desktop apps.</p></li>
<li><p>ControlTower - A webserver for Rack apps written in MacRuby and using GCD for concurrency.</p></li>
<li><p>New rewritten and more efficient dispatcher. Practically that means that the dispatcher is now thread safe with a per thread cache.</p></li>
<li><p>RegExp lib switch from Oniguruma to ICU. This was quite a big change and it was required because Oniguruma isn't thread safe and while C Ruby uses a Global Interpreter Lock. MacRuby on the other hand uses native POSIX threads running on their own non-locking, reentrant VM making thread safety critical.</p></li>
<li><p>More solid foundations - Some key classes we rewritten to improve performance and flexibility.</p></li>
<li><p>Support for C blocks - Objective-C has been supporting C blocks for a while and some Cocoa APIs require the use of blocks. MacRuby now allows you to use Ruby blocks and to pass them as C blocks. (new BridgeSupport required)</p></li>
<li><p>Sandboxing - For safety reasons, MacRuby allows you to now sandbox your applications. You can restrict your app from doing some potential dangerous things such as writing to disk, calling the system, accessing internet etc...</p></li>
<li><p>Mac App Store - This is not something done by the MacRuby team. But it directly affects MacRuby developers wanting to distribute their applications. Think about the exposure that you can app can have. Even if you have a web app, you can use WebKit to wrap it up, hook up a notification, add to that a local backup solution and geo location. Brilliant way to provide an even better user experience and better product exposure. All that really easily if you already know Ruby.</p></li>
</ul>


<p>To give an idea of what can be done I showed some code samples hopefully showing the cool hacking things one can play with:</p>

<ul>
<li><p>The first demo shows how to use the speech recognizer. The example is really sample you speak the name of someone and his/her picture shows up on screen. Just a few lines of code and you can start screaming commands to your TV to get it to change channel.</p></li>
<li><p>The second demo is an extremely simple Gowala client using CoreLocation. Yes, Mac desktop and laptops support geo location.</p></li>
<li><p>Another example of what you do is a sample letting you import all your twitter followers to your address book.</p></li>
<li><p>You can also use some of the low level OS features such as the Tokenizer. The next example showed how to extend Ruby and use a C function to detect the language of a string.</p></li>
<li><p>Finally, the last demo shows how to integrate a bluetooth device to control a HTML view via MacRuby and Javascript. All that in just a few lines of code!</p></li>
</ul>


<p>Basically, MacRuby is now mature and it's time for hackers and people trying to get exposure to give it a try.</p>

<h2>Presentation's website</h2>

<p>A page was setup on the confreaks website and available <a href="http://www.confreaks.com/videos/448-rubyconf2010-macruby-why-and-how">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MacRuby, WebKit and JS]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/10/19/macruby-webkit-and-js/"/>
    <updated>2010-10-19T00:05:37-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/10/19/macruby-webkit-and-js</id>
    <content type="html"><![CDATA[<p>I was working on a piece of code using MacRuby, Webkit and JavaScript. Calling JS from MacRuby is really straight forward but calling Ruby from JS is a but tricky. There is actually a known bug in MacRuby which was giving me a hard time. The bug should be fixed in 0.8 if everything goes according to plan. In the mean time here is a quick run down:</p>

<p>The JS bridge only works when using WebKit so we need to create a tiny browser to test our code. What we are going to do is to make an object available via JS and also trigger some JS to test the bridge both ways. Here is the full code:</p>

<p>On the object we want to make available via JS (instance of Cat), we have to make the methods available by defining def self.isSelectorExcludedFromWebScript(sel); false end</p>

<p>To trigger JS from Ruby, we use #evaluateWebScript on windowScriptObject. In our example we are using JQuery since it's already loaded in the DOM. We also go full loop by printing out the result of JS calling a method on our Ruby object.</p>

<p>Here is the thing, MacRuby doesn't have the age method compiled/registered yet so JS can't call it. To fix this problem we force the registration of the method by doing: @kitty.respondsToSelector("age").  Note that if #age was taking arguments, we would have to use @kitty.respondsToSelector("age:") and then evaluate the JS like that: @js_engine.evaluateWebScript('animal.age_(12)')</p>

<p>Hopefully by the time you need to do something like that, MacRuby 0.8 will be released and you won't have to worry about that :)</p>

<p>For more information about calling Obj-C/Ruby from JavaScript, <a href="http://developer.apple.com/library/mac/#documentation/AppleApplications/Conceptual/SafariJSProgTopics/Tasks/ObjCFromJavaScript.html#//apple_ref/doc/uid/30001215-BBCBFJCD">read this doc</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Ruby movement - art & programming]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/09/27/the-ruby-movement-art-programming/"/>
    <updated>2010-09-27T19:12:51-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/09/27/the-ruby-movement-art-programming</id>
    <content type="html"><![CDATA[<p>I wrote a guest blog post for <a href="http://rubylearning.com/blog/about/">Satish Talim</a> over at <a href="http://rubylearning.com/blog/">RubyLearning.org</a></p>

<p>You can read it <a href="http://rubylearning.com/blog/2010/09/28/the-ruby-movement/">there</a>.</p>

<p><a href="http://rubylearning.com/blog/2010/09/28/the-ruby-movement/"><img src="/images/posts/the-ruby-movement.jpg" title="The Ruby Movement by Matt Aimonetti" alt="The Ruby Movement by Matt Aimonetti" /></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Discussion with a Java switcher]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/08/22/discussion-with-a-java-switcher/"/>
    <updated>2010-08-22T17:18:55-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/08/22/discussion-with-a-java-switcher</id>
    <content type="html"><![CDATA[<p>For the past 6 months, I have had regular discussions with an experienced Java developers who switched to Ruby a couple years ago. Names have been changed to protect the guilty but to help you understand my friend 'Duke' better, you need to know that he has been a developer for 10 years and lead many complicated, high traffic projects. He recently released two Ruby on Rails projects and he has been fighting with performance issues and scalability challenges.</p>

<p>Duke is a happy Ruby developer but he sometimes has a hard time understanding why things are done in a certain way in the Ruby community. Here are some extracts from our conversations. My answers are only based on my own experience and limited knowledge. They are probably not shared by the entire  community, feel free to use the comment section if you want to add more or share your own answers.</p>

<h2>Threads / Concurrency</h2>

<p><strong>Duke:</strong> Why does the Ruby community hate threads so much. It seems to be a taboo discussion and the only answer I hear is that threads are hard to deal with and that Ruby does not have a good threading implementation. What's the deal there? If you want concurrent processing, threads are important!</p>

<p><strong>Me:</strong> This is a very good question and I think there are two main reasons why threads and thread safety are not hot topics in the Ruby world. First, look at Ruby's main implementation itself. If you are using an old version of Ruby (pre Ruby 1.9) you don't use native threads but green threads mapping to only 1 native thread. Ilya has a great (yet a bit old) <a href="http://www.igvita.com/2008/11/13/concurrency-is-a-myth-in-ruby/">blog post explaining the difference</a>, why it matters and also the role and effect of the Global Interpreter Lock (GIL). Also, even though Rubyists like to say that they live in the edge, most of them still use Ruby 1.8 and therefore don't really see the improvements in Ruby 1.9 nor yet understand the potential of <a href="http://ruby-doc.org/core-1.9/classes/Fiber.html">fibers</a>.</p>

<p>The other part of the explanation is that the Rails community never really cared until recently. Yehuda Katz recently wrote a <a href="http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/">good article on thread safety</a> in Ruby and if you read his post and <a href="http://dpaste.de/5xyG/raw/">Zed Shaw's comment</a> you will understand a bit better the historical background. As a matter of fact, the current version of Rails is not multi-threaded by default and developers interested in handling concurrent requests in one process should <a href="http://api.rubyonrails.org/classes/Rails/Configuration.html#M002069">turn on this option</a>. Thread safety appeared for the first time in Rails 2.2 but from what I saw, most people still don't enable this option. There are many reasons for that. First, enabling thread safety disables some Rails features like automatic dependency loading after boot and code reloading. A lot of Rails developers take these two features for granted and don't understand that they are technically "hacks" to make their lives easier. I do believe a lot of Rails developers don't understand how threads, thread safety, concurrency, blocking IO and dependencies work. They care about getting their app done and meet their deadlines. They usually use and know Rails without paying too much attention to how Rails extends Ruby. Imagine what would happen if their code wasn't thread safe and Rails wasn't not using a global lock by default. Now you see why things are not exactly as you expect and also why some Rubyists are getting excited about new projects like <a href="http://nodejs.org/">node.js</a> which takes a different approach.</p>

<p>The other thing to keep in mind is that at least 90 to 95% of the Rails apps out there don't get more than a dozen requests/second (a million requests/day). You can scale that kind of load pretty easily using simple approaches like caching,  optimize your DB queries, load balancing to a couple servers. As a matter of fact, compared to the amount of people using Rails on a daily basis, only a very little amount of people are struggling with performance and scalability like you do. This is not an excuse but that explains why these people don't care about the things you care about.</p>

<h2>Rails is slow</h2>

<p><strong>Duke:</strong> I don't understand why Rails developers are not more concerned about the speed/performance penalty induced by Rails.</p>

<p><strong>Me:</strong> Again, Rails is fast enough for the large majority of developers out there. As you know, as a developer you have to always make compromises. The Rails team always said that development time is more expensive than servers and therefore the focus is on making development easier, faster and more enjoyable. However to get there, they have to somewhat sacrifice some performance. What can be totally unacceptable for you is totally fine for others and your contribution is always welcome. This is probably the root cause of the things you don't like in Rails. Rails was built for startups, by startup developers and you don't fall in this category. People contributing new features and fixes are the people using Rails for what it is designed to do. There is no real 'Enterprise' support behind Rails and that might be why you feel the way you feel. Since you find yourself questioning some key Rails conventions and you are struggling with missing features, it looks  to me that you chose the wrong tool for the job since you don't even use 70% of the Rails features and are dreaming of things such 3 tier architecture. <a href="http://sinatrarb.com">Sinatra</a> might be a better fit for you if you want lower level control, less conventions and less built-in features.</p>

<h2>Object allocation / Garbage Collection</h2>

<p><strong>Duke:</strong> I recently read that Twitter was spending <a href="http://blog.evanweaver.com/articles/2009/10/21/object-allocations-on-the-web/">20% of its request cycles in the GC</a>, am I the only finding that concerning?</p>

<p><strong>Me:</strong> Most people don't realize how the GC works and what it means to allocate objects since Ruby does that automatically. But at the same time, most of these people don't really see the affect of the Garbage Collection since they don't have that much traffic or they scale in ways that just skips their Ruby stack entirely. (Or they just blame Ruby for being slow)</p>

<p>If you are app deals with mainly reads/GET requests, using HTTP caching (Rails has that built-in) and something like Varnish/<a href="http://rtomayko.github.com/rack-cache/">Rack-cache</a> will dramatically reduce the load on your server apps. Others don't investigate their issues and just add more servers. As mentioned in a <a href="http://merbist.com/2010/07/29/object-allocation-why-you-should-care/">previous post</a>, some libraries like Builder are allocating LOTS more objects than others (Nokogiri), use the existing debugging tools to see where your object allocations occur and try to fix/workaround these. In other words, Ruby's GC isn't great but by ignoring its limitations, we made things even worse. My guess is that the GC is going to improve (other implementations already have better GCs) and that people will realize that Ruby is not magic and critical elements need to be improved.</p>

<h2>Tools</h2>

<p><strong>Duke:</strong> I really have a hard time finding good tools to help scale my apps better and understand where I should optimize my code.</p>

<p><strong>Me: </strong>It is true that we area lacking tools but things are changing. On top of the built-in tools like <a href="http://ruby-doc.org/core-1.9/classes/ObjectSpace.html">ObjectSpace</a>, <a href="http://ruby-doc.org/core-1.9/classes/GC/Profiler.html">GC::Profiler</a>, people interested in performance/debugging are working to provide the Ruby community with their expertise, look at <a href="http://memprof.com/">memprof</a> and <a href="http://rubyforge.org/projects/ruby-debug/">ruby-debug</a> for instance. Of course you can also use tools such as <a href="http://ruby-prof.rubyforge.org/">Ruby-prof</a>, <a href="http://kcachegrind.sourceforge.net/html/Home.html">Kcachegrind</a>, <a href="http://valgrind.org/">Valgrind</a> and <a href="http://www.gnu.org/software/gdb/">GDB</a>. (1.9.2 was <a href="http://github.com/yugui/ruby/tree/feature/dtrace">scheduled to have DTrace support</a> but I did not check yet). Maybe you should be more explicit about what tools you miss and how we could solve the gap.</p>

<h2>ActiveRecord</h2>

<p><strong>Duke:</strong> ActiveRecord doesn't do what I need. How come there is no native support for master/slave DBs, sharding, DB view support is buggy,  suggested indexes on queries is not built-in and errors are not handled properly (server is gone, out of sync etc..)?</p>

<p><strong>Me:</strong> You don't have to use ActiveRecord, you could use any ORM such as <a href="http://sequel.rubyforge.org/">Sequel</a>, <a href="http://datamapper.org/">DataMapper</a> or your own. But to answer your question, I think that AR doesn't do everything you want because nobody contributed these features to the project and the people maintaining ActiveRecord don't have the need for these features.</p>

<h2>What can we do?</h2>

<p>We, as a community, need to realize that we have to learn from other communities and other programming languages, this kind of humorous graph is unfortunately not too far from reality.</p>

<p><img src="http://i.imgur.com/G7WyP.gif" alt="" /></p>

<p>Bringing your expertise and knowledge to the Ruby community is important. Looking further than just our own little will push us to improve and fulfill the gaps. Let the community know what tools you are missing, the good practices you think we should be following etc...</p>

<p>Take for instance <a href="http://nodejs.org/">Node.js</a>, it's a port of <a href="http://wiki.github.com/eventmachine/eventmachine/">Ruby's EventMachine</a> / <a href="http://twistedmatrix.com/trac/">Python's twisted</a>. There is no reasons why the Ruby or Python versions could not do what the Javascript version does. However people are getting excited and are jumping ship. What do we do about that? One way would be to identify what makes node more attractive than EventMachine and what needs to be done so we can offer what people are looking for. I asked this question a few weeks ago and the response was that a lot of the Ruby libraries are blocking and having to check is too bothersome. Maybe that's something that the community should be addressing. Node doesn't have that many libraries and people will have to write them, in the mean time we can make our libs non-blocking. Also, let's not forget that this is not a competition and people should choose the best tool for their projects.</p>

<p>Finally, things don't change overnight, as more people encounter the issues you are facing, as we learn from others, part of the community will focus on the problems you are seeing and things will get better. Hopefully, <strong>you</strong> will also be able to contribute and influence the community to build an even better Ruby world.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ruby object allocation & why you should care]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/07/29/object-allocation-why-you-should-care/"/>
    <updated>2010-07-29T23:47:50-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/07/29/object-allocation-why-you-should-care</id>
    <content type="html"><![CDATA[<p>Recently I was tasked with finding how to optimize a web application with heavy traffic. The application (a Rails 2.3.x app) gets about 3 million requests per hour and most of these requests cannot really be easily cached so they go through the entire stack.</p>

<p>This is probably not the case of most web apps out there. None the less, my findings my help you understand Ruby better and maybe think differently about memory management.</p>

<p>This is certainly not an advanced GC blog post, I will try to keep it as simple as possible. My goal is to show you how Ruby memory allocation works and why it can affect your app performance and finally, how can you avoid to allocate to many objects.</p>

<h2>Ruby memory management.</h2>

<p>Rubyists are quite lucky since they don't have to manage the memory themselves. Because developers are lazy and Matz developed his language for people and not machine, memory is managed "magically". Programming should be fun and managing memory isn't really considered fun (ask video game developers or iOS programmers ;)).</p>

<p>So in Ruby, the magical memory management is done by a Garbage Collector. The GC's job is to run and free objects that were previously allocated but not used anymore. Without a GC we would saturate the memory available on the host running the program or would have to deallocate the memory manually. Ruby's GC uses a conservative, stop the world, mark-and-sweep collection mechanism.  More simply, the garbage collection runs when the allocated memory for the process is maxed out. The GC runs and blocks all code from being executed and will free unused objects so new objects can be allocated.</p>

<p>Joe Damato did a great talk on that matter during last RailsConf</p>

<p><a href="http://www.scribd.com/doc/32718051/Garbage-Collection-and-the-Ruby-Heap">Garbage Collection and the Ruby Heap</a></p>

<p>The problem is that Ruby's GC was not designed to support hundred thousand objects allocation per second. Unfortunately, that's exactly what frameworks like Ruby on Rails do, and you might contribute to the problem too without even knowing it.</p>

<h2>Does it really matter?</h2>

<p>I believe it does. In my case improving the object allocation means much better response time, less servers, less support and less headaches. You might think that servers are cheaper than developers. But more servers mean more developer time spent fixing bugs and more IT support. That's why I think, memory management is something Ruby developers should be aware of and should take in consideration, especially the ones writing frameworks, libraries or shared code.</p>

<p>I am using Ruby 1.9 so I could not profile my Rails 2.x app using <a href="http://memprof.com/">memprof</a>, instead I wrote a <a href="http://github.com/mattetti/GC-stats-middleware">simple and basic middleware</a> that keeps track of the memory allocation/deallocation and GC cycles during a web request (Ruby1.9 only). One of my simple Rails2 actions (1 DB call, simple view) is allocating 170,000 objects per requests. Yes, you read right: 170k objects every single request. At 3 million requests/hour, you can imagine that we are spending a LOT of time waiting for the GC. This is obviously not 100% Rails fault as I am sure our code is contributing to the problem. I heard from the memprof guys that Rails was allocating 40k objects. I decided to check Rails3.</p>

<p>After warming up, a basic Rails3 'hello world' app clocks at about <strong>8,500 objects allocated per request</strong>, forcing the GC to run more or less every 6 requests. On my machine (mac pro) the GC takes about 20ms to free the objects. A Rack 'hello world' app clocks at <strong>7 objects</strong> per request and a Sinatra app at <strong>181 objects</strong>. Of course you can't really compare these different libraries/frameworks but that gives you an idea of the price you pay to get more features.</p>

<p>One thing to remember is that the more objects you allocate, the more time you "lose" at code execution. For more developers, it probably doesn't matter much, but if you should still understand that concept especially if you decide to contribute to the OSS community and offer patches, libraries, plugins etc...</p>

<h1>What can I do?</h1>

<p>Be aware that you are allocating  objects, for instance something as simple as 100.times{ 'foo' } allocates 100 string objects (strings are mutable and therefore each version requires its own memory allocation).</p>

<p>Make sure to evaluate the libraries you use, for instance switching a Sinatra XML rendering action from Builder to Nokogiri XML Builder saved us about 12k object allocations (Thanks Aaron Patterson). Make sure that <strong>if </strong>you are using a library allocating a LOT of objects, that other alternatives are not available and your choice is worth paying the GC cost. (you might not have a lot of requests/s or might not care for a few dozen ms per requests). You can use memprof or one of the many existing tools to check on the GC cycles using load tests or in dev mode. Also, be careful to analyze the data properly and to not only look at the first request. <a href="http://twitter.com/akeem">Someone</a> sent me <a href="http://memprof.com/dump/4c52503c7fdeb62cff000001">this memory dump</a> from a Rails3 'hello world' with Ruby 1.8.7 and it shows that Rails is using <a href="http://memprof.com/dump/4c52503c7fdeb62cff000001/detail?where=%7B%7D">331973 objects</a>.  While this is totally true, it doesn't mean that 330k objects are created per request. Instead that means that 330k objects are currently in memory. Rubygems loading already allocate a lot of objects, Rails even more but these objects won't be GC'd and don't matter as much as the ones allocated every single request. The total amount of memory used by a Ruby process isn't that important, however the fluctuation forcing the GC to run often is. This is why my middleware only cares about the allocation change during a request. (The GC should still traverse the entire memory so, smaller is better)</p>

<p>The more object allocation you do at runtime/per request, the more the GC will need to run, the slower your code will be. So this is not a question of memory space, but more of performance. If your framework/ORM/library/plugin allocates too many objects per request maybe you should start by reporting the problem and if you can, offer some patches.</p>

<p>Here are some hints about memory allocation:</p>

<p>Creating a hash object really allocates more than an object, for instance {'joe' => 'male', 'jane' => 'female'} doesn't allocate 1 object but 7. (one hash, 4 strings + 2 key strings) If you can use symbol keys as they won't be garbage collected. However because they won't be GC'd you want to make sure to not use totally dynamic keys like converting the username to a symbol, otherwise you will 'leak' memory.</p>

<p>Looking at a GC cycle in the Rails3 hello world example shows what objects get deallocated:</p>

<blockquote><p>GC run, previous cycle was 6 requests ago.</p></blockquote>

<p>GC 203 invokes. (amount of cycles since the program was started)
Index   1</p>

<p>Invoke Time(sec)   25.268</p>

<p>Use Size(byte)   4702440</p>

<p>Total Size(byte)   7307264</p>

<p>Total Object   182414</p>

<p>GC Time(ms) 22.35600000000204090611</p>

<h2>56322 freed objects.</h2>

<p><strong>[78%] 44334 freed strings.</strong>
<strong>[7%] 4325 freed arrays.</strong>
[0%] 504 freed bignums.
[1%] 613 freed hashes.
[0%] 289 freed objects.
<strong>[5%] 3030 freed parser nodes (eval usage).</strong></p>

<p>I did not list all the object types but it's pretty obvious that the main issue in the case of Rails is string allocation. To a certain extend the allocated arrays and the runtime use of eval are not helping either. (what is being eval'd at runtime anyway?)</p>

<p>If you use the same string in various place of you code, you can "cache" them using a local var, instance variable, class variable or constant. Sometimes you can just replaced them by a symbol and save a few allocations/deallocations per request. Whatever you do tho, make sure there is a real need for it. My rule of thumb is that if some code gets exercised by 80% of the requests, it should be really optimized and avoid extra allocations so the GC won't slow us down.</p>

<h2>What about a better GC?</h2>

<p>That's the easy answer. When I mentioned this problem with Rails, a lot of people told me that I should use JRuby or Rubinius because their GC were much better. Unfortunately, that's not that simple and choosing an alternative implementation requires much further research and tests.</p>

<p>But what annoys me with this solution is that using it is not solving the issue, it's just working around it. Yes, Ruby's GC isn't that great but that's the not the key issue, <strong>the key issue is that some libraries/frameworks allocate way too many objects</strong> and that nobody seems to care (or to even know it). I know that the Ruby Core Team is working on some optimizations and I am sure Ruby will eventually get an improved GC. In the meantime, it's easy to blame Matz, Koichi and the rest of the core team but again, it's ignoring that the root cause, totally uncontrolled memory allocation.</p>

<p><strong>Maybe it's time for us, Rubyists, to think a bit more about our memory usage.</strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Au Revoir Rails community]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/06/04/au-revoir-rails-community/"/>
    <updated>2010-06-04T17:45:20-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/06/04/au-revoir-rails-community</id>
    <content type="html"><![CDATA[<p>Time really flies!</p>

<p>Back in December 2005, Ruby on Rails 1.0 was released to the masses. I remember that was when I first got interested in Rails. Six months later, I was doing Rails development full time.</p>

<p>Rails pushed me to contribute to the project, to write plugins, to improve my Ruby knowledge, to release gems and to become a better engineer overall. I then joined the <a href="http://merbivore.com">Merb project</a>, focusing on problems I was facing in the various client projects I had back then.</p>

<p>The competition between Rails and Merb turned into a constant confrontation, splitting the Ruby community into two camps. A resolution was later achieved by merging the two teams and focusing our energy on Rails 3. This is how I became a part of the Activism team with <a href="http://blog.envylabs.com/">Gregg</a> and <a href="http://railscasts.com/">Ryan</a>. In this new role I was given the opportunity to meet lots of different people from various backgrounds and different communities. I really had a lot of fun.</p>

<p>However, things have changed for me. I won't be at Rails Conf 2010 because in a few weeks I will become a father for the first time. And with that, an obvious priority shift. My day job working on <a href="http://community.modnation.com/">Playstation games</a> is also quite time consuming and the little free time I manage to get to work on my own projects is spent on my <a href="http://macruby.labs.oreilly.com/">MacRuby book</a>. The disconnect between the Rails community and myself is probably more evident now than ever. The challenges encountered by most Railists are so different from the ones I face daily that I think others would do a much better job than I at advocating for Rails. So this is why I believe it's time for me to step away from the Rails community, kick back and relax (and get ready to change a lot of diapers).</p>

<p>This is an "<a href="http://www.merriam-webster.com/dictionary/au+revoir">au revoir</a>", not an "<a href="http://www.merriam-webster.com/dictionary/adieu">Adieu</a>". I will continue to keep an eye on Rails 3 and the fast growing ecosystem.</p>

<p>I will still be writing Ruby for a living and will hopefully keep contributing to the projects I use. And I plan to keep on attending to Ruby conferences around the world just as soon as my kid is old enough to travel with me ;)</p>

<p>Finally, with the imminent release of Rails 3, I hope to see even more people stand up and advocate for Ruby on Rails the way Gregg Pollack, Ryan Bates and many others have done so far.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Writing an open licensed book]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/05/09/writing-an-open-licensed-book/"/>
    <updated>2010-05-09T22:40:06-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/05/09/writing-an-open-licensed-book</id>
    <content type="html"><![CDATA[<p>To celebrate last week's release of <a href="http://www.macruby.org/blog/2010/04/30/macruby06.html">MacRuby 0.6</a>, O'Reilly and I started publishing the draft of my MacRuby book online: <a href="http://macruby.labs.oreilly.com/">http://macruby.labs.oreilly.com/</a></p>

<p>I started thinking about working on "<a href="http://macruby.labs.oreilly.com/">MacRuby: The Definitive Guide</a>" last year when I realized that the project had a great future but there was a serious lack of documentation. With the support of the MacRuby team, I worked on a table of contents and a pitch. The next step was to decide what we wanted to do with the book.</p>

<p>I know a lot of technical book authors and most of them will tell you the same thing: if you think that you are going to make money writing a book, you are wrong. Even if your book sells well, because of the time invested in writing the book, you are probably better off doing consulting work and charging by the hour.</p>

<p>So since day one, I knew that this project would not make me rich. The goal was to share knowledge not to reimburse my mortgage or save California from bankruptcy. While publishing a web book is great, distribution is quite limited, especially if you try to reach people outside of your network. That's why I decided to start talking to a few publishers. Most publishers I talked to were interested in working on the book, however they were not really keen on publishing a <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/us/">Creative Commons Attribution-Noncommercial-No Derivative</a> licensed book.</p>

<p>Let me explain why I think releasing technical books under a CC license is important. As you might know (or have figured out by now), I am not a native English speaker. I actually learned my first English words thanks to the computer my dad had at home. The problem when you don't live in an English speaking country and you want to learn about the cutting edge technology is that you have to understand English.  Thanks to the Internet, learning and practicing English is now much easier that it used to be. However, if you want to have access to books, most of the time you have to wait until someone translates the book and publishes it in your country or you have to manage to get an English version delivered to your country. This is often a pain because of national credit card limitations, international delivery restrictions etc... If you manage to find a way to get a copy, the book ends up costing a lot of money.</p>

<p>What does that mean in practice? Most of the technical books are first available in the English speaking western world, then slowly translated and/or distributed around the world. By the time you get a legal copy in Bolivia, Algeria or Vietnam, a new edition is probably out in the US probably because the technology evolved. Maybe that explains some of the book piracy worldwide?</p>

<p>Think about it for a minute: knowledge is power and time is money. And what do we do? We delay knowledge distribution. This is why I am a big fan of the <a href="http://khanacademy.org/">Khan Academy</a> and its awesome free online courses.</p>

<p>Turns out <a href="http://oreilly.com/">O'Reilly</a> shares my vision and has already published a lot of books under various open licenses: <a href="http://oreilly.com/openbook/">http://oreilly.com/openbook/</a> I was also interested in publishing the content of my book ASAP so people could access it right away even though there would be lots of typos and missing content. This is also something O'Reilly has already done with the <a href="http://books.couchdb.org/relax/">CouchDB</a> and the <a href="http://labs.oreilly.com/ofps.html">Scala</a> books.</p>

<p>Talking with <a href="http://twitter.com/janl">Jan Lehnardt</a> about his experience working with O'Reilly on the <a href="http://books.couchdb.org/relax/">'CouchDB: The definitive guide'</a> book, I realized that we seem to have some shared interests. I contacted Jan's editor and we decided to start working on the MacRuby book. The book will be available later on in all the usual commercial formats and I hope people will show their support so O'Reilly will be encouraged in their choice to continue publishing CC licensed book. At the end of the day, purchasing a CC licensed book helps supporting the authors, the publishers but also all the people who can't have access to the latest technical books.</p>

<p>Finally, working on a book is not an easy thing, especially when you have to write it in a language that's not yours. But I have to say that the community support has been amazing. Even <a href="http://daringfireball.net/linked/2010/05/03/macruby-aimonetti">John Gruber sent a fireball my way</a>. And since the announcement was made, I have received a lot of <a href="http://macruby.labs.oreilly.com/comments/feed?id=book">comments</a>, tweets, emails etc... It is very encouraging and it gives me the motivation needed to work on the book after a long work day.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[I did it wrong]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/03/15/i-did-it-wrong/"/>
    <updated>2010-03-15T23:50:49-07:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/03/15/i-did-it-wrong</id>
    <content type="html"><![CDATA[<p>The Ruby community is a well known for at least two things: <strong>being </strong><a href="http://pragprog.com/press_releases/the-passionate-programmer">passionate</a><strong> and being </strong><a href="http://www.bruisin-ales.com/beerblog/wp-content/uploads/2008/09/stoneintro.gif">arrogant</a> .
Two characteristics that often go together but I am not going to defend or justify anything in this post, instead I will try to reflect on my own experience and will share with you my own view point.</p>

<p><a href="http://merbist.com/wp-content/uploads/2010/03/doing_wrong_coaster_2.jpg"><img src="http://merbist.com/wp-content/uploads/2010/03/doing_wrong_coaster_2-225x300.jpg" alt="" /></a></p>

<p>Very much like the Ruby community, I am also quite passionate and can be arrogant at times. A few months back I was in Brazil for <a href="http://www.railssummit.com.br/en/pages/home">RailsSummit</a> and I was chatting with <a href="http://twitter.com/dchelimsky">David Chelimsky</a> after a nice evening with the <a href="http://www.railssummit.com.br/en/pages/home">RailsSummit</a> attendees. I was thinking about how cool it was to have people from various non-Ruby communities to come to a Ruby community and share their experience and knowledge while observing the ways we do things with Ruby.</p>

<p>David and I got to talk about technical evangelism, how <a href="http://rspec.info/">RSpec</a> became very popular, the whole <a href="http://en.wikipedia.org/wiki/Merb">Merb</a> vs <a href="http://rubyonrails.org/">Rails</a> situation which turned into Rails3, as well as <a href="http://www.macruby.org/">MacRuby</a> and <a href="http://www.apple.com/">Apple</a>. I was interested by the fact that I couldn't remember David ever saying something bad about test/unit or trying to tell others they were doing it wrong. Instead, he has always tried showing why people might be potentially interested by <a href="http://en.wikipedia.org/wiki/RSpec">RSpec</a>.</p>

<p>As an early RSpec adopter, I often thought that people were wrong not to use the solution that <em><strong>I</strong></em> thought was the best. As part of the Merb 'propaganda', we spent a lot of time comparing Merb with Rails and showing why Merb might be better for you and why you were doing it wrong if you would fit in Merb's target and still use Rails.</p>

<p>Even before that, I remember thinking that if you were not using Ruby, you were doing it wrong. PHP &amp; Java developers were, for me, just developers who did not know any better (and I thought that Python-ers were just too lazy to learn a "better" language that takes OOP seriously ;)).</p>

<p><a href="http://merbist.com/wp-content/uploads/2010/03/doing_it_wrong_coaster.jpg"><img src="http://merbist.com/wp-content/uploads/2010/03/doing_it_wrong_coaster-300x218.jpg" alt="" /></a></p>

<p>Since then, things have changed. I have gotten involved with other projects, met different people and maybe, just maybe, matured a little bit. Going back to the discussion I had with David, he pointed out to me how often people talk about a piece of technology or an idea to just quickly conclude: <strong>"it sucks"</strong> and it has got even worse lately with the '<a href="http://www.doingitwrong.com/">you're doing it wrong</a> ' meme.</p>

<p>Basically, we judge people's actions without knowing them or even having a clue about the problem they are facing and we just tell them that if they don't do like us, they are wrong. If they are not using this plugin or this gem, they are doing it wrong, and if they are using this other one that sucks, they are also doing it wrong. Also, be careful, something that's hot today will probably turn out to be 'the suck' soon enough, keep up with what the cool kids tweet about ;)</p>

<p>But of course, this is something human and much bigger than the Ruby community. Look at the whole SQL/NoSQL <a href="http://news.ycombinator.com/item?id=1163039">pseudo fight</a> and you will notice the same attitude. Look at the editors war, look at the OS war or even look at the TV with shows like '<a href="http://en.wikipedia.org/wiki/The%20Marriage%20Ref">Marriage Ref</a>' making money off of people wanting to prove their partner that he/she is doing it wrong. But that's also the root problem of most religion wars and even the motivation for some people to go 'invade/colonize' other countries to eventually force their world vision upon them.</p>

<p>I realize the irony of writing of blog post to tell my readers that telling others that they are doing it wrong is, in itself, fundamental wrong, but maybe next time you think something sucks or is totally wrong, you might want to try to understand the motivation behind why some people decided to go this way. I know I will personally try harder.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Speed up your Rails XML responses]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/02/22/speed-up-your-rails-xml-responses/"/>
    <updated>2010-02-22T23:25:09-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/02/22/speed-up-your-rails-xml-responses</id>
    <content type="html"><![CDATA[<p>At <a href="http://www.us.playstation.com/">work</a>, we have an XML API that gets quite a lot of traffic. Last week I looked into improving its performance since we are expecting more traffic soon and want to make sure our response time is optimized.</p>

<p>My first thought was to make sure we had  an optimized <a href="http://api.rubyonrails.org/classes/ActiveSupport/XmlMini.html">ActiveSupport's xmlmini backend</a>. Rails 2.3.5 fixed some issues when using <a href="http://nokogiri.org/">Nokogiri</a> as a xmlmini so I switched to my favorite Ruby XML lib:</p>

<pre><code>ActiveSupport::XmlMini.backend = 'Nokogiri'
</code></pre>

<p>I run some benchmarks using ab, httperf and jmeter but the results were not that great. I was so sure that switching from <a href="http://ruby-doc.org/stdlib/libdoc/rexml/rdoc/index.html">rexml</a> to <a href="http://nokogiri.org/">nokogiri</a> would give me awesome results that I was very disappointed.</p>

<p>I was about to call <a href="http://tenderlovemaking.com/">Aaron Patterson</a> (Nokogiri's author) to insult him, blame him for _why's disappearance and tell him that all his pro bono efforts were useless since my own app was not running much faster when switched to his library. As I was about to dial his number on my iPhone I had a crazy thought... maybe it was not Aaron's fault, maybe it was mine.</p>

<p>So I took a break went to play some fuzzball and as I was being ridiculed by Italian coworker, Emanuele, I realized that most of our API calls were just simple HTTP requests with no XML payload, just some query params. However, we were generating a lot of XML to send back to the client and AS::XmlMini only takes care of the XML parsing, not the rendering.</p>

<p>The XML rendering is done by <a href="http://onestepback.org/">Jim Weirich</a>'s pure Ruby <a href="http://builder.rubyforge.org/">builder library</a> which is vendored in Rails. Builder does a good job, but I thought that maybe a C based library might improve the speed. A coworker of mine (James Bunch) recommended to look into <a href="http://github.com/codahale/faster-builder">faster-builder</a>, a drop-in Builder replacement based on libxml. Unfortunately, the project doesn't seem to be maintained and I decided to look into using <a href="http://nokogiri.org/">Nokogiri</a> XML builder instead. (Also, faster-builder's author doesn't like me very much while Aaron knows he's one of my Ruby heroes so asking for help could be easier)</p>

<p>Some people reported having tried using <a href="http://nokogiri.org/">Nokogiri</a> as a XML builder but didn't see much speed improvement. Because of the amount of magic required to render a rxml template, I was not really surprised but I decided to contact Aaron and ask him if he tried using his lib instead of builder in a Rails app. <a href="http://www.flickr.com/photos/aaronp/57241193/">Aaron</a> told me he gave it a try a while back and he helped me get my Rails app setup to render xml templates using <a href="http://nokogiri.org/">Nokogiri</a>.</p>

<p>The next step was simple, create a <a href="http://github.com/mattetti/noko-vs-builder-benchmark">benchmark app</a> and benchmark Builder vs Nokogiri using various templates. Here are the results I got using Ruby 1.9.1 (the Ruby version we use in production) and two sets of templates:</p>

<p><strong>Builder</strong> small template, <strong>time per request: 15.507 [ms]</strong> (mean)</p>

<pre><code>$ ab -c 1 -n 200 http://127.0.0.1:3000/benchmarks/builder_small
This is ApacheBench, Version 2.3 &lt;$Revision: 655654 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 127.0.0.1 (be patient)
Completed 100 requests
Completed 200 requests
Finished 200 requests

Server Software:        nginx/0.7.65
Server Hostname:        127.0.0.1
Server Port:            3000

Document Path:          /benchmarks/builder_small
Document Length:        216 bytes

Concurrency Level:      1
Time taken for tests:   3.101 seconds
Complete requests:      200
Failed requests:        0
Write errors:           0
Total transferred:      114326 bytes
HTML transferred:       43200 bytes
Requests per second:    64.49 [#/sec] (mean)
Time per request:       15.507 [ms] (mean)
Time per request:       15.507 [ms] (mean, across all concurrent requests)
Transfer rate:          36.00 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:    11   15   8.8     12      47
Waiting:        3   15   8.9     12      47
Total:         11   15   8.8     12      47

Percentage of the requests served within a certain time (ms)
  50%     12
  66%     12
  75%     13
  80%     13
  90%     35
  95%     36
  98%     38
  99%     41
 100%     47 (longest request)
</code></pre>

<p><strong>Nokogiri</strong> small template, <strong>time per request: 15.354 [ms] (mean)</strong></p>

<pre><code>$ ab -c 1 -n 200 http://127.0.0.1:3000/benchmarks/noko_small
This is ApacheBench, Version 2.3 &lt;$Revision: 655654 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 127.0.0.1 (be patient)
Completed 100 requests
Completed 200 requests
Finished 200 requests

Server Software:        nginx/0.7.65
Server Hostname:        127.0.0.1
Server Port:            3000

Document Path:          /benchmarks/noko_small
Document Length:        238 bytes

Concurrency Level:      1
Time taken for tests:   3.071 seconds
Complete requests:      200
Failed requests:        0
Write errors:           0
Total transferred:      118717 bytes
HTML transferred:       47600 bytes
Requests per second:    65.13 [#/sec] (mean)
Time per request:       15.354 [ms] (mean)
Time per request:       15.354 [ms] (mean, across all concurrent requests)
Transfer rate:          37.75 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:    11   15   8.6     12      39
Waiting:       11   15   8.6     12      39
Total:         11   15   8.6     12      39

Percentage of the requests served within a certain time (ms)
  50%     12
  66%     12
  75%     12
  80%     13
  90%     35
  95%     36
  98%     37
  99%     38
 100%     39 (longest request)
</code></pre>

<p>Running the benchmarks many times showed that Nokogiri and Builder were taking more or less the same amount of time to builder a small template.</p>

<p>I then decided to try a bigger template, closer to what we have in production, here are the results:</p>

<p><strong>Nokogiri</strong> longer template, <strong>time per request: 31.252 [ms] (mean)</strong></p>

<pre><code>$ ab -c 1 -n 200 http://127.0.0.1:3000/benchmarks/noko
This is ApacheBench, Version 2.3 &lt;$Revision: 655654 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 127.0.0.1 (be patient)
Completed 100 requests
Completed 200 requests
Finished 200 requests

Server Software:        nginx/0.7.65
Server Hostname:        127.0.0.1
Server Port:            3000

Document Path:          /benchmarks/noko
Document Length:        54398 bytes

Concurrency Level:      1
Time taken for tests:   6.250 seconds
Complete requests:      200
Failed requests:        0
Write errors:           0
Total transferred:      10951200 bytes
HTML transferred:       10879600 bytes
Requests per second:    32.00 [#/sec] (mean)
Time per request:       31.252 [ms] (mean)
Time per request:       31.252 [ms] (mean, across all concurrent requests)
Transfer rate:          1711.00 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:    24   31  11.3     26      62
Waiting:       23   30  11.3     24      61
Total:         24   31  11.3     26      62

Percentage of the requests served within a certain time (ms)
  50%     26
  66%     27
  75%     27
  80%     29
  90%     54
  95%     55
  98%     58
  99%     59
 100%     62 (longest request)
</code></pre>

<p><strong>Builder</strong>, longer template, <strong>Time per request: 140.725 [ms] (mean)</strong></p>

<pre><code>$ ab -c 1 -n 200 http://127.0.0.1:3000/benchmarks/builder
This is ApacheBench, Version 2.3 &lt;$Revision: 655654 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 127.0.0.1 (be patient)
Completed 100 requests
Completed 200 requests
Finished 200 requests

Server Software:        nginx/0.7.65
Server Hostname:        127.0.0.1
Server Port:            3000

Document Path:          /benchmarks/builder
Document Length:        54376 bytes

Concurrency Level:      1
Time taken for tests:   28.145 seconds
Complete requests:      200
Failed requests:        0
Write errors:           0
Total transferred:      10947000 bytes
HTML transferred:       10875200 bytes
Requests per second:    7.11 [#/sec] (mean)
Time per request:       140.725 [ms] (mean)
Time per request:       140.725 [ms] (mean, across all concurrent requests)
Transfer rate:          379.83 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       1
Processing:   127  141  24.6    132     331
Waiting:      126  139  23.6    130     328
Total:        127  141  24.6    132     331

Percentage of the requests served within a certain time (ms)
  50%    132
  66%    138
  75%    147
  80%    149
  90%    156
  95%    169
  98%    193
  99%    311
 100%    331 (longest request)
</code></pre>

<p>Wow, <a href="http://twitter.com/tenderlove">@tenderlove</a>'s Nokogori just brought us a<strong> 4.5X speed improvement for this specific template</strong>.  100ms per request is probably not a big deal for most people and I have to say that Jim did a great job with Builder. However in my specific case, 100ms on a request being called thousands of times per hour is quite important.</p>

<p>(The <a href="http://github.com/mattetti/noko-vs-builder-benchmark">benchmark app is available on github</a>, feel free to fork it and benchmark your own templates)</p>

<p>Who would have thought that a man like this could save the day?!</p>

<p>[caption id="attachment_1737" align="alignleft" width="150" caption="Aaron 'Tenderlove' Patterson"]<a href="http://railsontherun.com/wp-content/uploads/2010/02/aaron.jpg"><img src="http://railsontherun.com/wp-content/uploads/2010/02/aaron-150x150.jpg" alt="" /></a>[/caption]</p>

<p><a href="http://www.flickr.com/photos/aaronp/3824959062/"><img src="http://farm3.static.flickr.com/2470/3824959062_fb0755e665_m_d.jpg" alt="" /></a></p>

<p><a href="http://www.flickr.com/photos/aaronp/57241193/"><img src="http://farm1.static.flickr.com/29/57241193_8137f2a4af_m_d.jpg" alt="" /></a></p>

<p><a href="http://www.flickr.com/photos/aaronp/3132124227/"><img src="http://farm4.static.flickr.com/3289/3132124227_3ace4ec7ae_m_d.jpg" alt="" /></a></p>

<p><strong><em>The moral of the story is that adding a bit of tenderlove to your Ruby code can make it perform much much better!</em></strong></p>

<p><strong>Thank you Aaron 'Tenderlove' Patterson!</strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Googlecharts 1.5.1]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/02/03/googlecharts-1-5-1/"/>
    <updated>2010-02-03T21:18:23-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/02/03/googlecharts-1-5-1</id>
    <content type="html"><![CDATA[<p>To celebrate the relaunch of this site and since we are waiting for Rails 3.0 beta to be released, I figured I should share with you what I worked on the other night.</p>

<p>I merged patches, refactored and released a new version of googlecharts, my Gem to create graphs using Google Chart API.</p>

<p><code>sudo gem install googlecharts</code></p>

<p>Here is a quick example of how the API works when dealing with a complex graph:</p>

<pre><code>require 'gchart' # or require 'googlecharts' if you prefer to use the Googlecharts constant.
title = "Player Count"
size = "575x300"
data = [85,107,123,131,155,172,173,189,203,222,217,233,250,239,256,267,247,261,275,295,288,305,322,307,325,347,331,346,363,382,343,359,383,352,374,393,358,379,396,416,377,398,419,380,409,426,453,432,452,465,436,460,480,440,457,474,501,457,489,507,347,373,413,402,424,448,475,488,513,475,507,530,440,476,500,518,481,512,531,367,396,423,387,415,446,478,442,469,492,463,489,508,463,491,518,549,503,526,547,493,530,549,493,520,541,564,510,535,564,492,512,537,502,530,548,491,514,538,568,524,548,568,512,533,552,577,520,545,570,516,536,555,514,536,566,521,553,579,604,541,569,595,551,581,602,549,576,606,631,589,615,650,597,624,646,672,605,626,654,584,608,631,574,597,622,559,591,614,644,580,603,629,584,615,631,558,591,618,641,314,356,395,397,429,450,421,454,477,507,458,490,560,593]
Gchart.line(:title =&gt; title, :size =&gt; size, :data =&gt; data, :axis_with_labels =&gt; 'x,y', :line_color =&gt; '1e60cc', :axis_labels =&gt; [(1.upto(24).to_a &lt;&lt; 1)], :max_value =&gt; 700, :custom =&gt; 'chg=10,15,1,0')
</code></pre>

<p>Which provides you with the url or image tag (or downloaded file) that produces the following graph:</p>

<p><img src="http://chart.apis.google.com/chart?chxl=0:|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|1&amp;chxt=x,y&amp;chco=1e60cc&amp;chg=10,15,1,0&amp;chd=s:HJKLNPPQRTTUWVWXVXYaZbcbcedeghefhfhifhjkhjlhklomopmoqmopsorsehkjlnqrtqsumqstqtvgjliknqnprprsprtwsuwruwruvxtvxrtvsuwrtvyuwytvwzuwytvxtvyuwz1vy0wz1wz130250357135z13y03x025z13z23x024bfijlnloqsorx0&amp;chtt=Player+Count&amp;cht=lc&amp;chs=575x300&amp;chxr=1,85,700" alt="Google Chart" /></p>

<p>This release works great with Ruby 1.9 and <a href="http://macruby.org">MacRuby</a>, lots of bugs got fixed and some new features were added. Something a lot of people complained was that the gem was called googlecharts but that the main class was called Gchart. The problem was that I wrote my gem and called it Gchart and when I went to register the rubyforge project page, the name was already taken. In this release, I fixed this problem by allowing users to require and use the constant name they want, Gchart or Googlecharts. I also spent quite a lot of time cleaning up the old code which I was a bit ashamed of. Class variables are now removed and overall, the code should be a bit more sane.</p>

<p>The source code can be found in my <a href="http://github.com/mattetti/googlecharts/">GitHub accout</a> and the documentation <a href="http://mattetti.github.com/googlecharts/">there</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How and why I joined the "suit people"]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/02/02/how-and-why-i-joined-the-suit-people/"/>
    <updated>2010-02-02T11:19:26-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/02/02/how-and-why-i-joined-the-suit-people</id>
    <content type="html"><![CDATA[<p>It is now official: I have traded my freedom &amp; home office for a job title, an Aeron chair in a cubicle and a 401K.</p>

<p>I received my new employee package and, in less than a week, I will officially become a full-time employee at <a href="http://en.wikipedia.org/wiki/Sony_Computer_Entertainment_of_America"> SCEA</a> (Sony Computer Entertainment America).</p>

<p>I'm going to work in the PlayStation department, working on PS3, PS2 and PSP game titles developed by <a href="http://www.naughtydog.com/">various</a> <a href="http://en.wikipedia.org/wiki/SCE_Studio_San_Diego">game</a> <a href="http://en.wikipedia.org/wiki/Sony_Computer_Entertainment_Worldwide_Studios">studios</a>.</p>

<p><a href="http://merbist.com/wp-content/uploads/2010/02/sony_playstation_32.jpg"><img src="http://merbist.com/wp-content/uploads/2010/02/sony_playstation_32-300x206.jpg" alt="" /></a></p>

<h3>Why 'o why?</h3>

<p><em>Why leave behind a happy life of indie contracting to join corporate America?</em></p>

<p>For many reasons actually:</p>

<ul>
<li><strong>A Team</strong></li>
</ul>


<p>Being a consultant I have been working with other independent consultants and existing teams. Nonetheless, I really miss being part of a stable team which grows together and learns from each other as we go through new projects and maintain old ones.</p>

<ul>
<li><strong>Long term plan</strong></li>
</ul>


<p>As a consultant, I usually start projects or "rescue" existing projects. I work on them for a little while and then move on. It's exciting and rewarding but you don't really pay the consequences of your mistakes. You usually don't have to maintain the code you wrote and you rarely deal with the mistakes <em>you</em> made.</p>

<p>It sounds good, nobody likes to maintain the crappy awesome code they wrote 2 years ago and most developers love working on new stuff. But at the same time, to become a better engineer you need to learn from you mistakes and assuming responsibility for your bad decisions is part of the process.</p>

<p>It might sound weird, but I'm actually excited to work on long term projects and feel some sort of ownership over the projects. Having to support games for many years means that I'd better not mess up the implementation. And if I do, I hope I'll quickly learn from my mistakes.</p>

<ul>
<li><strong>Avoiding burn out</strong></li>
</ul>


<p>There is no secret: when you are passionate about what you do, you have a hard time stopping and taking a break. I'm a recovering workaholic and it's really hard for me to say no when I'm presented the possibility to work on interesting projects. I love what I do and I keep writing code even after I'm done with client work.</p>

<p>The problem is that this can start me on the slippery slope to isolating myself from friends, family and people who don't share the same passion. I'm really lucky that my wife is a geek and loves hanging out at conferences, looking at code and playing with my buggy prototypes. But still, I spend too much time "playing" with my computer and I just can't manage my free time wisely.</p>

<p>Having a full time position will hopefully help me put boundaries and will hopefully teach me to disconnect from work.</p>

<ul>
<li><strong>Exciting projects</strong></li>
</ul>


<p>Hey, let's be honest, how many geeks do you know don't want to work in the video game industry? By the way, if you don't have a PS3, they are now at $299 and on top of getting an awesome console you get a blue ray player! (And no, I do not receive any bonuses or commissions for mentioning the console or promoting it in my blog. I had to pay for my own like everyone else.)</p>

<h3>Corporate America? Are you going to write Java now?</h3>

<p><img src="http://farm2.static.flickr.com/1412/1264424156_24f4571b10.jpg" alt="" /></p>

<p>No, I'm mainly going to stick to the language I love: <strong>Ruby</strong>.
From time to time I will probably use other languages here and there, but that usually makes me love Ruby even more. The reality is that Ruby's power and flexibility seem to be appreciated by SCEA, which makes sense when you have tight deadlines and a lot of new technologies to deal with. Ruby is a perfect match!</p>

<p>As you can guess, I can't go into any detail about how and why Sony uses Ruby, but let me just say that while games are still usually written in C++, they are becoming more and more interactive and need to communicate with game servers where some logic operates. Game players also need to interact with other gamers as well as check their gaming progress online, as well as the progress of the players around them etc... Basically, outside of the game engine and the console SDK, there is a lot of potential for Ruby.</p>

<p>Coming back to Corporate America, I have to say that I've known my future manager for a few years now. He's always been a fervent Ruby advocate and has introduced lots of teams to the happiness of Ruby &amp; Rails development. He's also a great developer who's contributing patches to major projects and has a bunch of cool stuff on github. To give you an idea, my job description mentions Rails, Merb, Sinatra, CouchdB, MongoDB, Redis, AWS. All these Ruby technologies are actually already used in production or are being seriously evaluated.</p>

<p>I'm also really looking forward to join the existing team. I know I'm going to love working with a bunch of awesome developers coming from various backgrounds.</p>

<p>Those who know me, know that I'm not a morning person. And while your typical office job is categorized as '9-5', don't feel too bad for me. I will be joining the video game product department, and morning people are rather rare in these kinds of groups ;)</p>

<h3>Conclusion</h3>

<p>I'm really excited about this opportunity. For me, it is proof again that the Ruby revolution took place and that the Enterprise is evolving. Of course, time will tell if I am right, but I am quite confident.</p>

<p>Also, Sony is always looking for new, talented people who want to push the entertainment world to the next level. Feel free to keep in touch with me if you are interested in joining the fun.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Undo/Redo in MacRuby]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/02/02/undoredo-in-macruby/"/>
    <updated>2010-02-02T02:19:44-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/02/02/undoredo-in-macruby</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MacRuby 0.5 final is out]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/01/31/macruby-0-5-final-is-out/"/>
    <updated>2010-01-31T19:13:36-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/01/31/macruby-0-5-final-is-out</id>
    <content type="html"><![CDATA[<p>After going through two betas, MacRuby 0.5 final is now released and can be downloaded by clicking on the icon below:</p>

<p><a href="http://macruby.org/downloads.html"><img src="http://macruby.org/images/zip.png" alt="" />
MacRuby 0.5</a></p>

<p>Don't worry about having MacRuby and Ruby 1.8.x or 1.9 installed, MacRuby is namespaced and won't affect your current Ruby installations, just download and launch the installer. (Note: The build was compiled for SnowLeopard only)</p>

<p>You can read all the <a href="http://www.macruby.org/blog/2010/01/31/macruby05.html">details of the release on the MacRuby website</a>.</p>

<p>So what changed since 0.4? Too many things for me to list them here but basically 0.5 uses LLVM to compile code and make MacRuby faster and integrate better with the Obj-c runtime. However since the last beta, here is what changed:</p>

<ul>
<li><p>HotCocoa is now a separate gem</p></li>
<li><p>improved AOT compilation</p></li>
<li><p>Grand Central Dispatch support - use all your cores without the pain of threads. Read <a href="http://www.macruby.org/documentation/gcd.html">this post</a> for more info.</p></li>
</ul>


<p>0.5 is a solid release which I consider production ready, I personally wrote a few of small Cocoa apps in MacRuby and everything has been working very well. Of course, I'm also excited about the new stuff in 0.6 trunk like the debugger previewed a few weeks ago: <a href="http://merbist.com/2010/01/18/how-to-detect-cylons-with-macruby/">http://merbist.com/2010/01/18/how-to-detect-cylons-with-macruby/</a> but also some drastic changes in the primitive classes that I might cover later on.</p>

<p>Finally, people are asking if the iPad will be able to run apps running in MacRuby. Unfortunately, the current answer is: no. The two issues with the IPhone/iP*d OS are the lack of Garbage Collector and support for BridgeSupport (needed to define CocoaTouch constants available from MacRuby). However, this matter is being discussed on the mailing list and progress is made by contributors (the core team primarily focusing on the desktop).</p>

<p>That is going to be an exciting Ruby week as MacRuby 0.5 is now out and Rails 3 beta/RC0 is expected really soon.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to detect Cylons with MacRuby]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/01/18/how-to-detect-cylons-with-macruby/"/>
    <updated>2010-01-18T16:13:37-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/01/18/how-to-detect-cylons-with-macruby</id>
    <content type="html"><![CDATA[<p>Over the weekend, MacRuby's trunk became version 0.6 and the bug fixing is currently done in both the 0.5 branch and trunk. Based on MacRuby's usual release cycle I would expect a 0.5 beta3 or 0.5 final to be released soon so most of the work can be focused on trunk.</p>

<p>I'll let you check on the <a href="http://svn.macosforge.org/repository/ruby/MacRuby/trunk/TODO">TODO list</a> to see what was done in 0.5 and what is in the plan for 0.6.</p>

<p>However, there is one feature in 0.6 that I know lots of you will just love! The good news is that Laurent already committed a very early version of his work so I figured, I should share the good news with you:</p>

<h3>Introducing MacRuby's debugger!</h3>

<p>If you were expecting to read: "a Cylon detector!", keep on reading.</p>

<p>Again, this feature is in really early development since it's scheduled for 0.6 and 0.5 final is not out yet. But if you install MacRuby using the <a href="http://macruby.icoretech.org/">nightly builds</a> or build from trunk, you can already play with the debugger.</p>

<p>Let me give you a really quick tour of the debugger.</p>

<p><img src="http://img.skitch.com/20100118-qn7yuq9h2ce61yxt6kwag9pnbt.jpg" alt="BSG75Logo posted by Matt Aimonetti" /></p>

<p>Let's imagine that we were given the task to debug the cylon detector written by Gaius Baltar which looks like that:</p>

<pre><code>characters = %w{Adama Apollo Baltar Roslin StarBuck Six}

def cylon?(character)
  false
end

characters.each do |character|
  if cylon?(character)
    puts "#{character} is a Cylon!"
  else
    puts "#{character} is not a cylon."
  end
end
</code></pre>

<p>Here is what happens when I execute the script:</p>

<pre><code>$ macruby cylon_detector.rb 
Adama is not a cylon.
Apollo is not a cylon.
Baltar is not a cylon.
Roslin is not a cylon.
StarBuck is not a cylon.
Six is not a cylon.
</code></pre>

<p>The only problem is that we all know that Six is a Cylon, the detector isn't working right so let's debug it:</p>

<pre><code>$ macrubyd cylon_detector.rb
Starting program.
cylon_detector.rb:1&gt; b cylon_detector.rb:8 if character == 'Six'
Added breakpoint 1.
cylon_detector.rb:1&gt; c
Adama is not a cylon.
Apollo is not a cylon.
Baltar is not a cylon.
Roslin is not a cylon.
StarBuck is not a cylon.
cylon_detector.rb:8&gt; p cylon?(character)
=&gt; false
cylon_detector.rb:8&gt; p "This detector is broken!"
=&gt; "This detector is broken!"
cylon_detector.rb:8&gt; p def cylon?(character); character == 'Six'; end
=&gt; nil
cylon_detector.rb:8&gt; p cylon?(character)
=&gt; true
cylon_detector.rb:8&gt; p cylon?('Matt')
=&gt; false
cylon_detector.rb:8&gt; c
Six is a Cylon!
Program exited.
</code></pre>

<p>The first thing we do is to add a conditional breakpoint:</p>

<pre><code>b cylon_detector.rb:8 if character == 'Six'
</code></pre>

<p>Basically, the debugger will add a breakpoint at line 8 which will only be active when the value of 'character' is equal to 'Six'.
Now that the breakpoint added, we can continue the program execution and just wait until we reach the defined condition.</p>

<pre><code>cylon_detector.rb:1&gt; c
</code></pre>

<p>Once we reach the breakpoint, we evaluate the result of "cylon?(character)" by using the p command. We see that the result is "false" when we know for sure that it should be true since the value of the character variable is 'Six' and she is a cylon. At this point, you might have guessed that somewhat acted as a cylon agent and I pretended to fix the problem by overwriting the "cylon?" method:</p>

<pre><code>cylon_detector.rb:8&gt; p def cylon?(character); character == 'Six'; end
</code></pre>

<p>Now that the method is overwritten, I can check that Six is recognized as being a cylon:</p>

<pre><code>cylon_detector.rb:8&gt; p cylon?(character)
=&gt; true
</code></pre>

<p>and also check that I am not detected a cylon:</p>

<pre><code>cylon_detector.rb:8&gt; p cylon?('Matt')
=&gt; false
</code></pre>

<p>I can now continue the execution of the program and see that Six is detected as a Cylon!</p>

<p>Of course this is just a very early version of the debugger and we will see lots of improvement in the next few weeks. Who knows someone might even create a GUI for the debugger and/or a Xcode integration.</p>

<p>Anyway, the point being that MacRuby developers should expect a lot of awesome stuff coming up their way soon. (also be careful about the skin jobs around you, cylon detectors can't be trusted!)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Controlling iTunes with MacRuby]]></title>
    <link href="http://matt.aimonetti.net/posts/2010/01/17/controlling-itunes-with-macruby/"/>
    <updated>2010-01-17T19:54:19-08:00</updated>
    <id>http://matt.aimonetti.net/posts/2010/01/17/controlling-itunes-with-macruby</id>
    <content type="html"><![CDATA[<p>Since Mac OS X v10.5, Apple added a technology called Scripting Bridge which allows to control and communicate with scriptable applications such as Mail, iChat or iTunes.</p>

<p>A few weeks back, <a href="http://merbist.com/2009/12/31/im-new-year-count-down-with-macruby/">I showed how to control iChat</a> with MacRuby. This time I'm going to show you how to control iTunes.</p>

<p>Here is a small script that I wrote to wake me up in music every morning.</p>

<pre><code>#!/usr/local/bin/macruby
framework 'Foundation'
framework 'ScriptingBridge'

itunes = SBApplication.applicationWithBundleIdentifier("com.apple.itunes")
load_bridge_support_file 'iTunes.bridgesupport'
itunes.run

class SBElementArray
  def [](value)
    self.objectWithName(value)
  end
end

itunes.stop
playlist = itunes.sources["Library"].userPlaylists["morning"]
playlist.playOnce(false) if playlist
</code></pre>

<p>The idea is that I have a Mac Mini streaming music through speakers connected to an AirportExpress in my bedroom.</p>

<p>Let's go through the script quickly.</p>

<p>We start by loading two frameworks, Foundation and ScriptingBridge.
Now that we have ScriptingBridge loaded, we can control iTunes. To do that, we use:
SBApplication.applicationWithBundleIdentifier("com.apple.itunes")
We then load a bridgesupport file that contains the enumerated constants from the iTunes scriptable dictionary.</p>

<p>We make sure iTunes is running by calling #run on the application object.</p>

<p>Before using iTune scriptable interface, we are making the API a bit nicer, it's totally unnecessary but it makes our code look better.</p>

<p>itunes.sources returns an instance of <a href="http://developer.apple.com/mac/library/documentation/cocoa/Reference/SBElementArray_Class/SBElementArray/SBElementArray.html">SBElementArray</a> which is not really an array nor a hash.</p>

<p>The rest of the code is pretty simple, we find the library, find the playlist called 'morning' and play it if found.</p>

<p>So you might wonder two things:</p>

<ul>
<li><p>What is the iTunes.bridgesupport file?</p></li>
<li><p>How do you know what methods are available to control iTunes?</p></li>
</ul>


<h4>bridgesupport file</h4>

<p>The bridgesupport file is important since it defines the required constants.
Apple provides a metadata generator called gen_bridge_metadata which generates a bridgesupport file.</p>

<p>Here is what the documentation says:</p>

<pre><code>$ man gen_bridge_metadata




NAME
gen_bridge_metadata -- Objective-C Bridges Metadata Generator

SYNOPSIS
gen_bridge_metadata [options...] headers...

DESCRIPTION
gen_bridge_metadata is a tool that generates bridging metadata information for a given framework or set of head-
ers. The Objective-C bridges supported in Mac OS X, such as RubyCocoa (Ruby) and PyObjC (Python), read this
information at runtime.

Metadata files describe the parts of an Objective-C framework that the bridges cannot automatically handle. These
are primarily the ANSI C elements of the framework -- functions, constants, enumerations, and so on -- but also
include special cases such as functions or methods that accept pointer-like arguments. These special cases must
be manually specified in separate files called exceptions. The gen_bridge_metadata tool can then read in the
exceptions file when it generates the framework metadata.

The file extension used for metadata files should be .bridgesupport.

Certain elements, such as inline functions, cannot be described in the metadata files. It is therefore required
to generate a dynamic library in order to make the bridges use them. The gen_bridge_metadata tool can take care
of that for you.

The file extension for the dynamic libraries should be .dylib.

You should install metadata files in one of three filesystem locations. For example, for a framework named
MyFramework that is installed as /Library/Frameworks/MyFramework.framework, you can install the
MyFramework.bridgesupport and MyFramework.dylib files in one of the following possible locations, in order of
priority:

o   /Library/Frameworks/MyFramework/Resources/BridgeSupport

o   /Library/BridgeSupport

o   ~/Library/BridgeSupport
</code></pre>

<p>The problem is that we don't have a framework or header file to generate a bridgesupport file for.
So, what we need a header file for iTunes, turns out we have a tool to do that:</p>

<pre><code>$ sdef /Applications/iTunes.app | sdp -fh --basename iTunes
</code></pre>

<p>I won't go in the details of what sdef and sdp do, just check their manual page.
Running the command above will create a iTunes.h which we can use to create a bridgesupport file.
Here is the generated header file: http://gist.github.com/279657</p>

<p>Now, let's create a bidgesupport file:</p>

<pre><code>$ gen_bridge_metadata -c '-I.' iTunes.h &gt; iTunes.bridgesupport
</code></pre>

<p>An that's how we get the bridgesupport file. (see file: <a href="http://gist.github.com/279698">http://gist.github.com/279698</a>)</p>

<h4>iTunes Documentation</h4>

<p>The easiest way to understand what's available to you is to open iTunes' dictionary in the AppleScript Editor.</p>

<p><img src="http://img.skitch.com/20100118-fe5c3224jd8xfhciwqxpy4hptc.jpg" alt="iTunes API by Matt Aimonetti" /></p>

<p>Otherwise you can study the iTunes.h file.</p>

<p>I wrote a very dumb parser to give you an idea of the methods and properties available when controlling iTunes via ScriptingBridge, here is the  output:</p>

<pre><code>Class: iTunesPrintSettings
Properties:
copies (the number of copies of a document to be printed)
collating (Should printed copies be collated?)
startingPage (the first page of the document to be printed)
endingPage (the last page of the document to be printed)
pagesAcross (number of logical pages laid across a physical page)
pagesDown (number of logical pages laid out down a physical page)
errorHandling (how errors are handled)
requestedPrintTime (the time at which the desktop printer should print the document)
printerFeatures (printer specific options)
faxNumber (for fax number)
targetPrinter (for target printer)

Method: printPrintDialog:(BOOL)printDialog withProperties:(iTunesPrintSettings *)withProperties kind:(iTunesEKnd)kind theme:(NSString *)theme
Returned: void
Print the specified object(s)
----
Method: close
Returned: void
Close an object
----
Method: delete
Returned: void
Delete an element from an object
----
Method: duplicateTo:(SBObject *)to
Returned: SBObject
Duplicate one or more object(s)
----
Method: exists
Returned: BOOL
Verify if an object exists
----
Method: open
Returned: void
open the specified object(s)
----
Method: playOnce:(BOOL)once
Returned: void
play the current track or the specified track or file.
----

Class: iTunesApplication
Properties:
currentEncoder (the currently selected encoder (MP3, AIFF, WAV, etc.))
currentEQPreset (the currently selected equalizer preset)
currentPlaylist (the playlist containing the currently targeted track)
currentStreamTitle (the name of the current song in the playing stream (provided by streaming server))
currentStreamURL (the URL of the playing stream or streaming web site (provided by streaming server))
currentTrack (the current targeted track)
currentVisual (the currently selected visual plug-in)
EQEnabled (is the equalizer enabled?)
fixedIndexing (true if all AppleScript track indices should be independent of the play order of the owning playlist.)
frontmost (is iTunes the frontmost application?)
fullScreen (are visuals displayed using the entire screen?)
name (the name of the application)
mute (has the sound output been muted?)
playerPosition (the player’s position within the currently playing track in seconds.)
playerState (is iTunes stopped, paused, or playing?)
selection (the selection visible to the user)
soundVolume (the sound output volume (0 = minimum, 100 = maximum))
version (the version of iTunes)
visualsEnabled (are visuals currently being displayed?)
visualSize (the size of the displayed visual)

Method: browserWindows
Returned: SBElementArray
----
Method: encoders
Returned: SBElementArray
----
Method: EQPresets
Returned: SBElementArray
----
Method: EQWindows
Returned: SBElementArray
----
Method: playlistWindows
Returned: SBElementArray
----
Method: sources
Returned: SBElementArray
----
Method: visuals
Returned: SBElementArray
----
Method: windows
Returned: SBElementArray
----
Method: printPrintDialog:(BOOL)printDialog withProperties:(iTunesPrintSettings *)withProperties kind:(iTunesEKnd)kind theme:(NSString *)theme
Returned: void
Print the specified object(s)
----
Method: run
Returned: void
run iTunes
----
Method: quit
Returned: void
quit iTunes
----
Method: add:(NSArray *)x to:(SBObject *)to
Returned: iTunesTrack
add one or more files to a playlist
----
Method: backTrack
Returned: void
reposition to beginning of current track or go to previous track if already at start of current track
----
Method: convert:(NSArray *)x
Returned: iTunesTrack
convert one or more files or tracks
----
Method: fastForward
Returned: void
skip forward in a playing track
----
Method: nextTrack
Returned: void
advance to the next track in the current playlist
----
Method: pause
Returned: void
pause playback
----
Method: playOnce:(BOOL)once
Returned: void
play the current track or the specified track or file.
----
Method: playpause
Returned: void
toggle the playing/paused state of the current track
----
Method: previousTrack
Returned: void
return to the previous track in the current playlist
----
Method: resume
Returned: void
disable fast forward/rewind and resume playback, if playing.
----
Method: rewind
Returned: void
skip backwards in a playing track
----
Method: stop
Returned: void
stop playback
----
Method: update
Returned: void
update the specified iPod
----
Method: eject
Returned: void
eject the specified iPod
----
Method: subscribe:(NSString *)x
Returned: void
subscribe to a podcast feed
----
Method: updateAllPodcasts
Returned: void
update all subscribed podcast feeds
----
Method: updatePodcast
Returned: void
update podcast feed
----
Method: openLocation:(NSString *)x
Returned: void
Opens a Music Store or audio stream URL
----

Class: iTunesItem
Properties:
container (the container of the item)
index (The index of the item in internal application order.)
name (the name of the item)
persistentID (the id of the item as a hexidecimal string. This id does not change over time.)

Method: id
Returned: NSInteger
the id of the item
----
Method: printPrintDialog:(BOOL)printDialog withProperties:(iTunesPrintSettings *)withProperties kind:(iTunesEKnd)kind theme:(NSString *)theme
Returned: void
Print the specified object(s)
----
Method: close
Returned: void
Close an object
----
Method: delete
Returned: void
Delete an element from an object
----
Method: duplicateTo:(SBObject *)to
Returned: SBObject
Duplicate one or more object(s)
----
Method: exists
Returned: BOOL
Verify if an object exists
----
Method: open
Returned: void
open the specified object(s)
----
Method: playOnce:(BOOL)once
Returned: void
play the current track or the specified track or file.
----
Method: reveal
Returned: void
reveal and select a track or playlist
----

Class: iTunesPlaylist
Properties:
duration (the total length of all songs (in seconds))
name (the name of the playlist)
parent (folder which contains this playlist (if any))
shuffle (play the songs in this playlist in random order?)
size (the total size of all songs (in bytes))
songRepeat (playback repeat mode)
specialKind (special playlist kind)
time (the length of all songs in MM:SS format)
visible (is this playlist visible in the Source list?)

Method: tracks
Returned: SBElementArray
----
Method: moveTo:(SBObject *)to
Returned: void
Move playlist(s) to a new location
----
Method: searchFor:(NSString *)for_ only:(iTunesESrA)only
Returned: iTunesTrack
search a playlist for tracks matching the search string. Identical to entering search text in the Search field in iTunes.
----

Class: iTunesAudioCDPlaylist
Properties:
artist (the artist of the CD)
compilation (is this CD a compilation album?)
composer (the composer of the CD)
discCount (the total number of discs in this CD’s album)
discNumber (the index of this CD disc in the source album)
genre (the genre of the CD)
year (the year the album was recorded/released)

Method: audioCDTracks
Returned: SBElementArray
----

Class: iTunesDevicePlaylist
Method: deviceTracks
Returned: SBElementArray
----

Class: iTunesLibraryPlaylist
Method: fileTracks
Returned: SBElementArray
----
Method: URLTracks
Returned: SBElementArray
----
Method: sharedTracks
Returned: SBElementArray
----

Class: iTunesRadioTunerPlaylist
Method: URLTracks
Returned: SBElementArray
----

Class: iTunesSource
Properties:
capacity (the total size of the source if it has a fixed size)
freeSpace (the free space on the source if it has a fixed size)
kind ()

Method: audioCDPlaylists
Returned: SBElementArray
----
Method: devicePlaylists
Returned: SBElementArray
----
Method: libraryPlaylists
Returned: SBElementArray
----
Method: playlists
Returned: SBElementArray
----
Method: radioTunerPlaylists
Returned: SBElementArray
----
Method: userPlaylists
Returned: SBElementArray
----
Method: update
Returned: void
update the specified iPod
----
Method: eject
Returned: void
eject the specified iPod
----

Class: iTunesTrack
Properties:
album (the album name of the track)
albumArtist (the album artist of the track)
albumRating (the rating of the album for this track (0 to 100))
albumRatingKind (the rating kind of the album rating for this track)
artist (the artist/source of the track)
bitRate (the bit rate of the track (in kbps))
bookmark (the bookmark time of the track in seconds)
bookmarkable (is the playback position for this track remembered?)
bpm (the tempo of this track in beats per minute)
category (the category of the track)
comment (freeform notes about the track)
compilation (is this track from a compilation album?)
composer (the composer of the track)
databaseID (the common, unique ID for this track. If two tracks in different playlists have the same database ID, they are sharing the same data.)
dateAdded (the date the track was added to the playlist)
objectDescription (the description of the track)
discCount (the total number of discs in the source album)
discNumber (the index of the disc containing this track on the source album)
duration (the length of the track in seconds)
enabled (is this track checked for playback?)
episodeID (the episode ID of the track)
episodeNumber (the episode number of the track)
EQ (the name of the EQ preset of the track)
finish (the stop time of the track in seconds)
gapless (is this track from a gapless album?)
genre (the music/audio genre (category) of the track)
grouping (the grouping (piece) of the track. Generally used to denote movements within a classical work.)
kind (a text description of the track)
longDescription ()
lyrics (the lyrics of the track)
modificationDate (the modification date of the content of this track)
playedCount (number of times this track has been played)
playedDate (the date and time this track was last played)
podcast (is this track a podcast episode?)
rating (the rating of this track (0 to 100))
ratingKind (the rating kind of this track)
releaseDate (the release date of this track)
sampleRate (the sample rate of the track (in Hz))
seasonNumber (the season number of the track)
shufflable (is this track included when shuffling?)
skippedCount (number of times this track has been skipped)
skippedDate (the date and time this track was last skipped)
show (the show name of the track)
sortAlbum (override string to use for the track when sorting by album)
sortArtist (override string to use for the track when sorting by artist)
sortAlbumArtist (override string to use for the track when sorting by album artist)
sortName (override string to use for the track when sorting by name)
sortComposer (override string to use for the track when sorting by composer)
sortShow (override string to use for the track when sorting by show name)
size (the size of the track (in bytes))
start (the start time of the track in seconds)
time (the length of the track in MM:SS format)
trackCount (the total number of tracks on the source album)
trackNumber (the index of the track on the source album)
unplayed (is this track unplayed?)
videoKind (kind of video track)
volumeAdjustment (relative volume adjustment of the track (-100% to 100%))
year (the year the track was recorded/released)

Method: artworks
Returned: SBElementArray
----

Class: iTunesFileTrack
Properties:
location (the location of the file represented by this track)

Method: refresh
Returned: void
update file track information from the current information in the track’s file
----

Class: iTunesURLTrack
Properties:
address (the URL for this track)

Method: download
Returned: void
download podcast episode
----

Class: iTunesUserPlaylist
Properties:
shared (is this playlist shared?)
smart (is this a Smart Playlist?)

Method: fileTracks
Returned: SBElementArray
----
Method: URLTracks
Returned: SBElementArray
----
Method: sharedTracks
Returned: SBElementArray
----
</code></pre>
]]></content>
  </entry>
  
</feed>
